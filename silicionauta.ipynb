{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Martoto/BigData_ForecastHackathon/blob/main/silicionauta.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5cbfde9a",
      "metadata": {
        "id": "5cbfde9a"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "559b0055",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/mnt/batch/tasks/shared/LS_root/mounts/clusters/memoryman/code/Users/daniel.sant.salles\n"
          ]
        }
      ],
      "source": [
        "%cd Users/daniel.sant.salles/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4472b044",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in c:\\users\\danie\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.2.3)\n",
            "Requirement already satisfied: pyarrow in c:\\users\\danie\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (21.0.0)\n",
            "Requirement already satisfied: seaborn in c:\\users\\danie\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.13.2)\n",
            "Requirement already satisfied: plotly in c:\\users\\danie\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (5.24.1)\n",
            "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\danie\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\danie\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\danie\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\danie\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\danie\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from seaborn) (3.10.5)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\danie\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from plotly) (9.1.2)\n",
            "Requirement already satisfied: packaging in c:\\users\\danie\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from plotly) (24.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\danie\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\danie\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\danie\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\danie\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\danie\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\danie\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.3)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\danie\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install pandas pyarrow seaborn plotly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "13da2d6c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13da2d6c",
        "outputId": "817e4941-beea-44e1-feb1-d9ef4b53a41b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/hackathon_2025_templates.zip not found. Downloading...\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/hackathon_2025_templates.zip'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     14\u001b[39m response = requests.get(download_url, stream=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     15\u001b[39m response.raise_for_status() \u001b[38;5;66;03m# Raise an exception for bad status codes\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mwb\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     18\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m response.iter_content(chunk_size=\u001b[32m8192\u001b[39m):\n\u001b[32m     19\u001b[39m         f.write(chunk)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\IPython\\core\\interactiveshell.py:343\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    337\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    338\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    339\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    340\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    341\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m343\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/content/hackathon_2025_templates.zip'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import requests\n",
        "\n",
        "file_path = '/content/hackathon_2025_templates.zip'\n",
        "file_id = '1Ed-nqUyCT0z-T0AvHwLMsGqHYqjw2248' # This is the file ID\n",
        "\n",
        "if not os.path.exists(file_path):\n",
        "    print(f'{file_path} not found. Downloading...')\n",
        "\n",
        "    # Construct the direct download URL\n",
        "    download_url = f'https://drive.google.com/uc?export=download&id={file_id}'\n",
        "\n",
        "    try:\n",
        "        response = requests.get(download_url, stream=True)\n",
        "        response.raise_for_status() # Raise an exception for bad status codes\n",
        "\n",
        "        with open(file_path, 'wb') as f:\n",
        "            for chunk in response.iter_content(chunk_size=8192):\n",
        "                f.write(chunk)\n",
        "\n",
        "        print(f'{file_path} downloaded successfully.')\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error downloading the file: {e}\")\n",
        "        print(\"Please ensure the file is shared publicly or with 'Anyone with the link'.\")\n",
        "\n",
        "else:\n",
        "    print(f'{file_path} found.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "de6d0ad1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracted hackathon_2025_templates.zip to ./data/\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_path = 'hackathon_2025_templates.zip'\n",
        "extract_dir = './data/'\n",
        "\n",
        "if os.path.exists(zip_path):\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_dir)\n",
        "    print(f'Extracted {zip_path} to {extract_dir}')\n",
        "else:\n",
        "    print(f'{zip_path} not found in the current directory.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "0bbfcf34",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pdv</th>\n",
              "      <th>premise</th>\n",
              "      <th>categoria_pdv</th>\n",
              "      <th>zipcode</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2204965430669363375</td>\n",
              "      <td>On Premise</td>\n",
              "      <td>Mexican Rest</td>\n",
              "      <td>30741</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5211957289528622910</td>\n",
              "      <td>On Premise</td>\n",
              "      <td>Hotel/Motel</td>\n",
              "      <td>80011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9024493554530757353</td>\n",
              "      <td>Off Premise</td>\n",
              "      <td>Convenience</td>\n",
              "      <td>80751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8659197371382902429</td>\n",
              "      <td>On Premise</td>\n",
              "      <td>Restaurant</td>\n",
              "      <td>80439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1400854873763881130</td>\n",
              "      <td>On Premise</td>\n",
              "      <td>Restaurant</td>\n",
              "      <td>30093</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   pdv      premise categoria_pdv  zipcode\n",
              "0  2204965430669363375   On Premise  Mexican Rest    30741\n",
              "1  5211957289528622910   On Premise   Hotel/Motel    80011\n",
              "2  9024493554530757353  Off Premise   Convenience    80751\n",
              "3  8659197371382902429   On Premise    Restaurant    80439\n",
              "4  1400854873763881130   On Premise    Restaurant    30093"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "file_path = './data/part-00000-tid-2779033056155408584-f6316110-4c9a-4061-ae48-69b77c7c8c36-4-1-c000.snappy.parquet'\n",
        "df_pdv = pd.read_parquet(file_path)\n",
        "display(df_pdv.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "0ba2fc66",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>internal_store_id</th>\n",
              "      <th>internal_product_id</th>\n",
              "      <th>distributor_id</th>\n",
              "      <th>transaction_date</th>\n",
              "      <th>reference_date</th>\n",
              "      <th>quantity</th>\n",
              "      <th>gross_value</th>\n",
              "      <th>net_value</th>\n",
              "      <th>gross_profit</th>\n",
              "      <th>discount</th>\n",
              "      <th>taxes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7384367747233276219</td>\n",
              "      <td>328903483604537190</td>\n",
              "      <td>9</td>\n",
              "      <td>2022-07-13</td>\n",
              "      <td>2022-07-01</td>\n",
              "      <td>1.0</td>\n",
              "      <td>38.125000</td>\n",
              "      <td>37.890625</td>\n",
              "      <td>10.042625</td>\n",
              "      <td>3.950000</td>\n",
              "      <td>0.234375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3536908514005606262</td>\n",
              "      <td>5418855670645487653</td>\n",
              "      <td>5</td>\n",
              "      <td>2022-03-21</td>\n",
              "      <td>2022-03-01</td>\n",
              "      <td>6.0</td>\n",
              "      <td>107.250000</td>\n",
              "      <td>106.440002</td>\n",
              "      <td>24.732002</td>\n",
              "      <td>17.100000</td>\n",
              "      <td>0.810000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3138231730993449825</td>\n",
              "      <td>1087005562675741887</td>\n",
              "      <td>6</td>\n",
              "      <td>2022-09-06</td>\n",
              "      <td>2022-09-01</td>\n",
              "      <td>3.0</td>\n",
              "      <td>56.625000</td>\n",
              "      <td>56.220001</td>\n",
              "      <td>14.124002</td>\n",
              "      <td>5.250000</td>\n",
              "      <td>0.405000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3681167389484217654</td>\n",
              "      <td>1401422983880045188</td>\n",
              "      <td>5</td>\n",
              "      <td>2022-09-11</td>\n",
              "      <td>2022-09-01</td>\n",
              "      <td>129.0</td>\n",
              "      <td>1037.160023</td>\n",
              "      <td>1037.160023</td>\n",
              "      <td>156.348026</td>\n",
              "      <td>479.880006</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7762413312337359369</td>\n",
              "      <td>6614994347738381720</td>\n",
              "      <td>4</td>\n",
              "      <td>2022-02-18</td>\n",
              "      <td>2022-02-01</td>\n",
              "      <td>1.0</td>\n",
              "      <td>26.230000</td>\n",
              "      <td>23.950241</td>\n",
              "      <td>6.550241</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.279758</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     internal_store_id  internal_product_id distributor_id transaction_date  \\\n",
              "0  7384367747233276219   328903483604537190              9       2022-07-13   \n",
              "1  3536908514005606262  5418855670645487653              5       2022-03-21   \n",
              "2  3138231730993449825  1087005562675741887              6       2022-09-06   \n",
              "3  3681167389484217654  1401422983880045188              5       2022-09-11   \n",
              "4  7762413312337359369  6614994347738381720              4       2022-02-18   \n",
              "\n",
              "  reference_date  quantity  gross_value    net_value  gross_profit  \\\n",
              "0     2022-07-01       1.0    38.125000    37.890625     10.042625   \n",
              "1     2022-03-01       6.0   107.250000   106.440002     24.732002   \n",
              "2     2022-09-01       3.0    56.625000    56.220001     14.124002   \n",
              "3     2022-09-01     129.0  1037.160023  1037.160023    156.348026   \n",
              "4     2022-02-01       1.0    26.230000    23.950241      6.550241   \n",
              "\n",
              "     discount     taxes  \n",
              "0    3.950000  0.234375  \n",
              "1   17.100000  0.810000  \n",
              "2    5.250000  0.405000  \n",
              "3  479.880006  0.000000  \n",
              "4    0.000000  2.279758  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "file_path = './data/part-00000-tid-5196563791502273604-c90d3a24-52f2-4955-b4ec-fb143aae74d8-4-1-c000.snappy.parquet'\n",
        "df_transactions = pd.read_parquet(file_path)\n",
        "display(df_transactions.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "a6e80f95",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 7,092 unique product IDs in transactions\n",
            "Total rows processed: 7,092\n",
            "Total rows kept: 7,092\n",
            "Filtering efficiency: 100.00%\n",
            "Final products dataframe shape: (7092, 8)\n",
            "\n",
            "First few rows of filtered products:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>produto</th>\n",
              "      <th>categoria</th>\n",
              "      <th>descricao</th>\n",
              "      <th>tipos</th>\n",
              "      <th>label</th>\n",
              "      <th>subcategoria</th>\n",
              "      <th>marca</th>\n",
              "      <th>fabricante</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2282334733936076502</td>\n",
              "      <td>Distilled Spirits</td>\n",
              "      <td>JOSEPH CARTRON CAFÉ LIQUEUR</td>\n",
              "      <td>Distilled Spirits</td>\n",
              "      <td>Core</td>\n",
              "      <td>Liqueurs &amp; Cordials</td>\n",
              "      <td>Joseph Cartron Cafe</td>\n",
              "      <td>Spiribam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6091840953834683482</td>\n",
              "      <td>Distilled Spirits</td>\n",
              "      <td>SPRINGBANK 18 YEAR SINGLE MALT 700ML</td>\n",
              "      <td>Distilled Spirits</td>\n",
              "      <td>Specialty</td>\n",
              "      <td>Scotch Whisky</td>\n",
              "      <td>Springbank 18 Year Single Malt</td>\n",
              "      <td>Pacific Edge Wine &amp; Spirits</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1968645851245092408</td>\n",
              "      <td>Distilled Spirits</td>\n",
              "      <td>J BRANDT TRIPLE SEC 12/750ML 30PF</td>\n",
              "      <td>Distilled Spirits</td>\n",
              "      <td>Private Label</td>\n",
              "      <td>Liqueurs &amp; Cordials</td>\n",
              "      <td>J Brandt Triple Sec</td>\n",
              "      <td>Sazerac Spirits</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>994706710729219179</td>\n",
              "      <td>Draft</td>\n",
              "      <td>REFORMATION CASHMERE IPA 1/4 KEG</td>\n",
              "      <td>Draft</td>\n",
              "      <td>In&amp;Out</td>\n",
              "      <td>Other Draft</td>\n",
              "      <td>Reformation Cashmere Fresh Hop IPA</td>\n",
              "      <td>Reformation Brewery</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9209550539540384349</td>\n",
              "      <td>Non-Alcohol</td>\n",
              "      <td>HELLA MOSCOW MULE 750ML</td>\n",
              "      <td>Non Alcohol</td>\n",
              "      <td>Core</td>\n",
              "      <td>Mixers</td>\n",
              "      <td>Hella Bitters Bloody Mary</td>\n",
              "      <td>Hella Bitter Llc</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               produto          categoria  \\\n",
              "0  2282334733936076502  Distilled Spirits   \n",
              "1  6091840953834683482  Distilled Spirits   \n",
              "2  1968645851245092408  Distilled Spirits   \n",
              "3   994706710729219179              Draft   \n",
              "4  9209550539540384349        Non-Alcohol   \n",
              "\n",
              "                              descricao              tipos          label  \\\n",
              "0           JOSEPH CARTRON CAFÉ LIQUEUR  Distilled Spirits           Core   \n",
              "1  SPRINGBANK 18 YEAR SINGLE MALT 700ML  Distilled Spirits      Specialty   \n",
              "2     J BRANDT TRIPLE SEC 12/750ML 30PF  Distilled Spirits  Private Label   \n",
              "3      REFORMATION CASHMERE IPA 1/4 KEG              Draft         In&Out   \n",
              "4               HELLA MOSCOW MULE 750ML        Non Alcohol           Core   \n",
              "\n",
              "          subcategoria                               marca  \\\n",
              "0  Liqueurs & Cordials                 Joseph Cartron Cafe   \n",
              "1        Scotch Whisky      Springbank 18 Year Single Malt   \n",
              "2  Liqueurs & Cordials                 J Brandt Triple Sec   \n",
              "3          Other Draft  Reformation Cashmere Fresh Hop IPA   \n",
              "4               Mixers           Hella Bitters Bloody Mary   \n",
              "\n",
              "                    fabricante  \n",
              "0                     Spiribam  \n",
              "1  Pacific Edge Wine & Spirits  \n",
              "2              Sazerac Spirits  \n",
              "3          Reformation Brewery  \n",
              "4             Hella Bitter Llc  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import pyarrow.parquet as pq\n",
        "\n",
        "# Get unique product IDs from transactions for filtering\n",
        "valid_product_ids = set(df_transactions['internal_product_id'].unique())\n",
        "print(f\"Found {len(valid_product_ids):,} unique product IDs in transactions\")\n",
        "\n",
        "file_path = './data/part-00000-tid-7173294866425216458-eae53fbf-d19e-4130-ba74-78f96b9675f1-4-1-c000.snappy.parquet'\n",
        "table = pq.ParquetFile(file_path)\n",
        "\n",
        "# Collect filtered chunks\n",
        "filtered_chunks = []\n",
        "total_rows_processed = 0\n",
        "total_rows_kept = 0\n",
        "\n",
        "for batch in table.iter_batches(batch_size=5000):\n",
        "    df_chunk = batch.to_pandas()\n",
        "    total_rows_processed += len(df_chunk)\n",
        "    \n",
        "    # Filter to keep only products that exist in transactions\n",
        "    filtered_chunk = df_chunk[df_chunk['produto'].isin(valid_product_ids)]\n",
        "    total_rows_kept += len(filtered_chunk)\n",
        "    \n",
        "    if len(filtered_chunk) > 0:\n",
        "        filtered_chunks.append(filtered_chunk)\n",
        "\n",
        "# Combine all filtered chunks\n",
        "df_products = pd.concat(filtered_chunks, ignore_index=True) if filtered_chunks else pd.DataFrame()\n",
        "\n",
        "print(f\"Total rows processed: {total_rows_processed:,}\")\n",
        "print(f\"Total rows kept: {total_rows_kept:,}\")\n",
        "print(f\"Filtering efficiency: {(total_rows_kept/total_rows_processed)*100:.2f}%\")\n",
        "print(f\"Final products dataframe shape: {df_products.shape}\")\n",
        "print(\"\\nFirst few rows of filtered products:\")\n",
        "display(df_products.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "794e610a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 FILTERING VERIFICATION\n",
            "==================================================\n",
            "Unique products in filtered dataset: 7,092\n",
            "Unique products in transactions: 7,092\n",
            "Unique products in filtered products: 7,092\n",
            "Products in both datasets: 7,092\n",
            "✅ All transaction products are covered in the products dataset\n",
            "✅ All products have corresponding transactions\n",
            "\n",
            "📊 Data consistency: Perfect match!\n"
          ]
        }
      ],
      "source": [
        "# Verification of the filtering results\n",
        "print(\"🔍 FILTERING VERIFICATION\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Check unique products in filtered dataset\n",
        "unique_products_filtered = df_products['produto'].nunique()\n",
        "print(f\"Unique products in filtered dataset: {unique_products_filtered:,}\")\n",
        "\n",
        "# Check if all transaction products are covered\n",
        "transaction_products = set(df_transactions['internal_product_id'].unique())\n",
        "filtered_products = set(df_products['produto'].unique())\n",
        "\n",
        "print(f\"Unique products in transactions: {len(transaction_products):,}\")\n",
        "print(f\"Unique products in filtered products: {len(filtered_products):,}\")\n",
        "\n",
        "# Check intersection\n",
        "intersection = transaction_products.intersection(filtered_products)\n",
        "print(f\"Products in both datasets: {len(intersection):,}\")\n",
        "\n",
        "# Check if there are products in transactions not in products\n",
        "missing_in_products = transaction_products - filtered_products\n",
        "if missing_in_products:\n",
        "    print(f\"⚠️  Products in transactions but missing in products: {len(missing_in_products)}\")\n",
        "    print(f\"Examples: {list(missing_in_products)[:10]}\")\n",
        "else:\n",
        "    print(\"✅ All transaction products are covered in the products dataset\")\n",
        "\n",
        "# Check if there are products in products not in transactions\n",
        "missing_in_transactions = filtered_products - transaction_products\n",
        "if missing_in_transactions:\n",
        "    print(f\"⚠️  Products in products but missing in transactions: {len(missing_in_transactions)}\")\n",
        "    print(f\"Examples: {list(missing_in_transactions)[:10]}\")\n",
        "else:\n",
        "    print(\"✅ All products have corresponding transactions\")\n",
        "\n",
        "print(f\"\\n📊 Data consistency: {'Perfect match!' if len(missing_in_products) == 0 and len(missing_in_transactions) == 0 else 'Some mismatches found'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12d4a337",
      "metadata": {},
      "source": [
        "1- pdv\tpremise\tcategoria_pdv\tzipcode \n",
        "2- internal_store_id\tinternal_product_id\tdistributor_id\ttransaction_date\treference_date\tquantity\tgross_value\tnet_value\tgross_profit\tdiscount\ttaxes\n",
        "3- produto categoria descricao tipos label subcategoria marca fabricante               \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fbe54ba0",
      "metadata": {},
      "source": [
        "## Visão Geral da Estrutura dos Dados\n",
        "\n",
        "### 📊 Dataset 1: Ponto de Venda (PDV)\n",
        "| Coluna | Descrição |\n",
        "|--------|-----------|\n",
        "| `pdv` | Identificador do Ponto de Venda |\n",
        "| `premise` | Informações da loja/estabelecimento |\n",
        "| `categoria_pdv` | Classificação da categoria do PDV |\n",
        "| `zipcode` | Código postal/CEP |\n",
        "\n",
        "### 💳 Dataset 2: Transações\n",
        "| Coluna | Descrição |\n",
        "|--------|-----------|\n",
        "| `internal_store_id` | Identificador interno da loja |\n",
        "| `internal_product_id` | Identificador interno do produto |\n",
        "| `distributor_id` | Identificador do distribuidor |\n",
        "| `transaction_date` | Data da transação |\n",
        "| `reference_date` | Data de referência |\n",
        "| `quantity` | Quantidade da transação |\n",
        "| `gross_value` | Valor bruto da transação |\n",
        "| `net_value` | Valor líquido da transação |\n",
        "| `gross_profit` | Lucro bruto |\n",
        "| `discount` | Desconto aplicado |\n",
        "| `taxes` | Valor dos impostos |\n",
        "\n",
        "### 🛍️ Dataset 3: Produtos\n",
        "| Coluna | Descrição |\n",
        "|--------|-----------|\n",
        "| `produto` | Identificador do produto |\n",
        "| `categoria` | Categoria do produto |\n",
        "| `descricao` | Descrição do produto |\n",
        "| `tipos` | Tipos do produto |\n",
        "| `label` | Rótulo do produto |\n",
        "| `subcategoria` | Subcategoria do produto |\n",
        "| `marca` | Marca |\n",
        "| `fabricante` | Fabricante |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fd45d3a",
      "metadata": {},
      "source": [
        "# 🚀 EXPLORATORY DATA ANALYSIS - HACKATHON 2025\n",
        "## Going HAM on the Data! 💪\n",
        "\n",
        "Let's dive deep into this retail dataset and uncover insights for forecasting!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "823fad08",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🚀 Libraries loaded successfully! Let's go HAM on this data!\n"
          ]
        }
      ],
      "source": [
        "# Import comprehensive analysis libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configure visualization settings\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', 100)\n",
        "\n",
        "print(\"🚀 Libraries loaded successfully! Let's go HAM on this data!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "4ff35384",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔄 Loading all three datasets...\n",
            "✅ PDV Dataset loaded: (14419, 4)\n",
            "✅ Transactions Dataset loaded: (6560698, 11)\n",
            "✅ Products Dataset loaded: (7092, 8)\n",
            "\n",
            "🎯 Total datasets loaded: 3\n",
            "📈 Combined data points: 6,582,209\n"
          ]
        }
      ],
      "source": [
        "# 📊 LOAD ALL DATASETS\n",
        "print(\"🔄 Loading all three datasets...\")\n",
        "\n",
        "# Dataset 1: PDV (Points of Sale)\n",
        "pdv_file = './data/part-00000-tid-2779033056155408584-f6316110-4c9a-4061-ae48-69b77c7c8c36-4-1-c000.snappy.parquet'\n",
        "df_pdv = pd.read_parquet(pdv_file)\n",
        "print(f\"✅ PDV Dataset loaded: {df_pdv.shape}\")\n",
        "\n",
        "# Dataset 2: Transactions\n",
        "transactions_file = './data/part-00000-tid-5196563791502273604-c90d3a24-52f2-4955-b4ec-fb143aae74d8-4-1-c000.snappy.parquet'\n",
        "df_transactions = pd.read_parquet(transactions_file)\n",
        "print(f\"✅ Transactions Dataset loaded: {df_transactions.shape}\")\n",
        "\n",
        "# Dataset 3: Products (using chunked reading for large file)\n",
        "products_file = './data/part-00000-tid-7173294866425216458-eae53fbf-d19e-4130-ba74-78f96b9675f1-4-1-c000.snappy.parquet'\n",
        "df_products = pd.read_parquet(products_file)\n",
        "print(f\"✅ Products Dataset loaded: {df_products.shape}\")\n",
        "\n",
        "print(f\"\\n🎯 Total datasets loaded: 3\")\n",
        "print(f\"📈 Combined data points: {df_pdv.shape[0] + df_transactions.shape[0] + df_products.shape[0]:,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "d24ce161",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "🔍 DEEP DIVE INTO DATASET STRUCTURES\n",
            "================================================================================\n",
            "\n",
            "📊 PDV DATASET ANALYSIS:\n",
            "   📏 Shape: (14419, 4)\n",
            "   📋 Columns: ['pdv', 'premise', 'categoria_pdv', 'zipcode']\n",
            "   🏷️  Data Types:\n",
            "      pdv: object\n",
            "      premise: object\n",
            "      categoria_pdv: object\n",
            "      zipcode: int32\n",
            "   💾 Memory Usage: 2.62 MB\n",
            "   🕳️  Missing Values: 0\n",
            "   🔢 Unique Values per Column:\n",
            "      pdv: 14,419\n",
            "      premise: 2\n",
            "      categoria_pdv: 54\n",
            "      zipcode: 788\n",
            "------------------------------------------------------------\n",
            "\n",
            "📊 TRANSACTIONS DATASET ANALYSIS:\n",
            "   📏 Shape: (6560698, 11)\n",
            "   📋 Columns: ['internal_store_id', 'internal_product_id', 'distributor_id', 'transaction_date', 'reference_date', 'quantity', 'gross_value', 'net_value', 'gross_profit', 'discount', 'taxes']\n",
            "   🏷️  Data Types:\n",
            "      internal_store_id: object\n",
            "      internal_product_id: object\n",
            "      distributor_id: object\n",
            "      transaction_date: object\n",
            "      reference_date: object\n",
            "      quantity: float64\n",
            "      gross_value: float64\n",
            "      net_value: float64\n",
            "      gross_profit: float64\n",
            "      discount: float64\n",
            "      taxes: float64\n",
            "   💾 Memory Usage: 1963.29 MB\n",
            "   🕳️  Missing Values: 0\n",
            "   🔢 Unique Values per Column:\n",
            "      internal_store_id: 15,086\n",
            "      internal_product_id: 7,092\n",
            "      distributor_id: 8\n",
            "      transaction_date: 365\n",
            "      reference_date: 12\n",
            "      quantity: 16,449\n",
            "      gross_value: 173,883\n",
            "      net_value: 216,337\n",
            "      gross_profit: 363,451\n",
            "      discount: 121,528\n",
            "      taxes: 12,531\n",
            "------------------------------------------------------------\n",
            "\n",
            "📊 PRODUCTS DATASET ANALYSIS:\n",
            "   📏 Shape: (7092, 8)\n",
            "   📋 Columns: ['produto', 'categoria', 'descricao', 'tipos', 'label', 'subcategoria', 'marca', 'fabricante']\n",
            "   🏷️  Data Types:\n",
            "      produto: object\n",
            "      categoria: object\n",
            "      descricao: object\n",
            "      tipos: object\n",
            "      label: object\n",
            "      subcategoria: object\n",
            "      marca: object\n",
            "      fabricante: object\n",
            "   💾 Memory Usage: 3.53 MB\n",
            "   🕳️  Missing Values: 1505\n",
            "   🔢 Unique Values per Column:\n",
            "      produto: 7,092\n",
            "      categoria: 7\n",
            "      descricao: 7,092\n",
            "      tipos: 22\n",
            "      label: 14\n",
            "      subcategoria: 42\n",
            "      marca: 4,221\n",
            "      fabricante: 343\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# 🔍 DATASET STRUCTURE ANALYSIS - Going Deep!\n",
        "print(\"=\"*80)\n",
        "print(\"🔍 DEEP DIVE INTO DATASET STRUCTURES\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "datasets = {\n",
        "    'PDV': df_pdv,\n",
        "    'Transactions': df_transactions,\n",
        "    'Products': df_products\n",
        "}\n",
        "\n",
        "for name, df in datasets.items():\n",
        "    print(f\"\\n📊 {name.upper()} DATASET ANALYSIS:\")\n",
        "    print(f\"   📏 Shape: {df.shape}\")\n",
        "    print(f\"   📋 Columns: {list(df.columns)}\")\n",
        "    print(f\"   🏷️  Data Types:\")\n",
        "    for col, dtype in df.dtypes.items():\n",
        "        print(f\"      {col}: {dtype}\")\n",
        "    print(f\"   💾 Memory Usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
        "    print(f\"   🕳️  Missing Values: {df.isnull().sum().sum()}\")\n",
        "    print(f\"   🔢 Unique Values per Column:\")\n",
        "    for col in df.columns:\n",
        "        unique_count = df[col].nunique()\n",
        "        print(f\"      {col}: {unique_count:,}\")\n",
        "    print(\"-\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29ba9777",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🧹 DATA QUALITY ASSESSMENT - The Deep Clean!\n",
        "print(\"=\"*80)\n",
        "print(\"🧹 DATA QUALITY ASSESSMENT\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def analyze_data_quality(df, name):\n",
        "    print(f\"\\n🔍 {name} QUALITY REPORT:\")\n",
        "    \n",
        "    # Missing values analysis\n",
        "    missing_values = df.isnull().sum()\n",
        "    missing_percent = (missing_values / len(df)) * 100\n",
        "    \n",
        "    print(f\"📊 Missing Values Analysis:\")\n",
        "    for col in df.columns:\n",
        "        if missing_values[col] > 0:\n",
        "            print(f\"   {col}: {missing_values[col]:,} ({missing_percent[col]:.2f}%)\")\n",
        "    \n",
        "    # Duplicates analysis\n",
        "    duplicates = df.duplicated().sum()\n",
        "    print(f\"🔄 Duplicate Rows: {duplicates:,} ({(duplicates/len(df)*100):.2f}%)\")\n",
        "    \n",
        "    # Numerical columns analysis\n",
        "    numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
        "    if len(numerical_cols) > 0:\n",
        "        print(f\"📈 Numerical Columns Analysis:\")\n",
        "        for col in numerical_cols:\n",
        "            q1 = df[col].quantile(0.25)\n",
        "            q3 = df[col].quantile(0.75)\n",
        "            iqr = q3 - q1\n",
        "            outliers = ((df[col] < (q1 - 1.5 * iqr)) | (df[col] > (q3 + 1.5 * iqr))).sum()\n",
        "            print(f\"   {col}: Min={df[col].min():.2f}, Max={df[col].max():.2f}, Outliers={outliers:,}\")\n",
        "    \n",
        "    print(\"-\" * 60)\n",
        "\n",
        "# Analyze each dataset\n",
        "for name, df in datasets.items():\n",
        "    analyze_data_quality(df, name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "f011f8bb",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "💰 SALES TRANSACTION ANALYSIS\n",
            "================================================================================\n",
            "📅 Transaction Date Range:\n",
            "   From: 2022-01-01 00:00:00\n",
            "   To: 2022-12-31 00:00:00\n",
            "   Duration: 364 days\n",
            "\n",
            "💵 Financial Metrics Summary:\n",
            "   quantity:\n",
            "      Total: $53,311,532.07\n",
            "      Average: $8.13\n",
            "      Median: $2.00\n",
            "      Std Dev: $80.49\n",
            "   gross_value:\n",
            "      Total: $805,333,770.76\n",
            "      Average: $122.75\n",
            "      Median: $42.10\n",
            "      Std Dev: $866.43\n",
            "   net_value:\n",
            "      Total: $781,531,966.87\n",
            "      Average: $119.12\n",
            "      Median: $40.77\n",
            "      Std Dev: $865.18\n",
            "   gross_profit:\n",
            "      Total: $143,882,148.80\n",
            "      Average: $21.93\n",
            "      Median: $10.51\n",
            "      Std Dev: $232.65\n",
            "   discount:\n",
            "      Total: $181,513,749.61\n",
            "      Average: $27.67\n",
            "      Median: $2.30\n",
            "      Std Dev: $384.76\n",
            "   taxes:\n",
            "      Total: $23,801,803.14\n",
            "      Average: $3.63\n",
            "      Median: $0.54\n",
            "      Std Dev: $11.31\n",
            "\n",
            "🏪 Top 10 Stores by Total Revenue:\n",
            "   Store 6491855528940268514: $2,932,767.13\n",
            "   Store 3025867614395044464: $2,684,152.80\n",
            "   Store 4374038751643985193: $2,616,642.68\n",
            "   Store 7195906766187577140: $2,338,811.76\n",
            "   Store 6337402841339348330: $2,327,405.16\n",
            "   Store 5130630496972372280: $2,192,520.00\n",
            "   Store 8723723113467008071: $2,182,582.85\n",
            "   Store 8294871217390043140: $2,182,338.53\n",
            "   Store 4003964282058636604: $2,124,037.75\n",
            "   Store 2720921832183866690: $1,921,439.23\n",
            "\n",
            "🛍️ Top 10 Products by Total Sales:\n",
            "   Product 4040509988492387426: $20,987,395.40\n",
            "   Product 8352471677482341950: $13,964,609.53\n",
            "   Product 500478784353013717: $12,630,634.08\n",
            "   Product 3620674245436818138: $12,549,666.40\n",
            "   Product 1029370090212151375: $12,065,719.51\n",
            "   Product 1938760505411922162: $11,353,110.50\n",
            "   Product 3894706280449257667: $10,667,511.27\n",
            "   Product 3262679882836704514: $10,522,927.93\n",
            "   Product 4524932930736383075: $10,460,878.54\n",
            "   Product 1860061817666925715: $8,923,429.36\n"
          ]
        }
      ],
      "source": [
        "# 💰 SALES TRANSACTION ANALYSIS - The Money Maker!\n",
        "print(\"=\"*80)\n",
        "print(\"💰 SALES TRANSACTION ANALYSIS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Convert date columns to datetime\n",
        "if 'transaction_date' in df_transactions.columns:\n",
        "    df_transactions['transaction_date'] = pd.to_datetime(df_transactions['transaction_date'])\n",
        "if 'reference_date' in df_transactions.columns:\n",
        "    df_transactions['reference_date'] = pd.to_datetime(df_transactions['reference_date'])\n",
        "\n",
        "# Time period analysis\n",
        "print(f\"📅 Transaction Date Range:\")\n",
        "if 'transaction_date' in df_transactions.columns:\n",
        "    print(f\"   From: {df_transactions['transaction_date'].min()}\")\n",
        "    print(f\"   To: {df_transactions['transaction_date'].max()}\")\n",
        "    print(f\"   Duration: {(df_transactions['transaction_date'].max() - df_transactions['transaction_date'].min()).days} days\")\n",
        "\n",
        "# Financial metrics overview\n",
        "numerical_cols = ['quantity', 'gross_value', 'net_value', 'gross_profit', 'discount', 'taxes']\n",
        "available_cols = [col for col in numerical_cols if col in df_transactions.columns]\n",
        "\n",
        "print(f\"\\n💵 Financial Metrics Summary:\")\n",
        "if available_cols:\n",
        "    for col in available_cols:\n",
        "        print(f\"   {col}:\")\n",
        "        print(f\"      Total: ${df_transactions[col].sum():,.2f}\")\n",
        "        print(f\"      Average: ${df_transactions[col].mean():.2f}\")\n",
        "        print(f\"      Median: ${df_transactions[col].median():.2f}\")\n",
        "        print(f\"      Std Dev: ${df_transactions[col].std():.2f}\")\n",
        "\n",
        "# Top performing stores and products\n",
        "print(f\"\\n🏪 Top 10 Stores by Total Revenue:\")\n",
        "if 'internal_store_id' in df_transactions.columns and 'gross_value' in df_transactions.columns:\n",
        "    top_stores = df_transactions.groupby('internal_store_id')['gross_value'].sum().sort_values(ascending=False).head(10)\n",
        "    for store_id, revenue in top_stores.items():\n",
        "        print(f\"   Store {store_id}: ${revenue:,.2f}\")\n",
        "\n",
        "print(f\"\\n🛍️ Top 10 Products by Total Sales:\")\n",
        "if 'internal_product_id' in df_transactions.columns and 'gross_value' in df_transactions.columns:\n",
        "    top_products = df_transactions.groupby('internal_product_id')['gross_value'].sum().sort_values(ascending=False).head(10)\n",
        "    for product_id, revenue in top_products.items():\n",
        "        print(f\"   Product {product_id}: ${revenue:,.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "7cd05a43",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "📈 TIME SERIES ANALYSIS\n",
            "================================================================================\n",
            "📊 Daily Sales Statistics:\n",
            "   Total Days with Transactions: 365\n",
            "   Average Daily Revenue: $2,206,393.89\n",
            "   Best Day Revenue: $269,828,419.09\n",
            "   Worst Day Revenue: $11,394.54\n",
            "\n",
            "📅 Weekly Sales Patterns:\n",
            "   Sunday: $280,198,190.63\n",
            "   Monday: $129,634,657.15\n",
            "   Tuesday: $124,884,143.82\n",
            "   Wednesday: $108,631,312.81\n",
            "   Thursday: $91,117,453.89\n",
            "   Friday: $68,646,346.69\n",
            "   Saturday: $2,221,665.77\n",
            "\n",
            "🗓️ Monthly Revenue Trends:\n",
            "   2022-01: $31,089,589.20\n",
            "   2022-02: $34,985,233.80\n",
            "   2022-03: $42,767,181.34\n",
            "   2022-04: $39,708,678.19\n",
            "   2022-05: $48,529,123.84\n",
            "   2022-06: $51,197,744.23\n",
            "   2022-07: $41,707,373.43\n",
            "   2022-08: $51,961,556.34\n",
            "   2022-09: $312,855,647.57\n",
            "   2022-10: $47,909,054.74\n",
            "   2022-11: $50,067,765.72\n",
            "   2022-12: $52,554,822.35\n",
            "\n",
            "🌟 Seasonality Insights:\n",
            "   Peak Sales Month: 9 ($378.86 avg)\n",
            "   Lowest Sales Month: 1 ($80.98 avg)\n"
          ]
        }
      ],
      "source": [
        "# 📈 TIME SERIES ANALYSIS - The Time Machine!\n",
        "print(\"=\"*80)\n",
        "print(\"📈 TIME SERIES ANALYSIS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "if 'transaction_date' in df_transactions.columns:\n",
        "    # Extract time components\n",
        "    df_transactions['year'] = df_transactions['transaction_date'].dt.year\n",
        "    df_transactions['month'] = df_transactions['transaction_date'].dt.month\n",
        "    df_transactions['day'] = df_transactions['transaction_date'].dt.day\n",
        "    df_transactions['weekday'] = df_transactions['transaction_date'].dt.day_name()\n",
        "    df_transactions['week'] = df_transactions['transaction_date'].dt.isocalendar().week\n",
        "    \n",
        "    # Daily sales analysis\n",
        "    daily_sales = df_transactions.groupby('transaction_date').agg({\n",
        "        'gross_value': ['sum', 'mean', 'count'],\n",
        "        'quantity': 'sum'\n",
        "    }).round(2)\n",
        "    \n",
        "    print(f\"📊 Daily Sales Statistics:\")\n",
        "    print(f\"   Total Days with Transactions: {len(daily_sales)}\")\n",
        "    print(f\"   Average Daily Revenue: ${daily_sales[('gross_value', 'sum')].mean():,.2f}\")\n",
        "    print(f\"   Best Day Revenue: ${daily_sales[('gross_value', 'sum')].max():,.2f}\")\n",
        "    print(f\"   Worst Day Revenue: ${daily_sales[('gross_value', 'sum')].min():,.2f}\")\n",
        "    \n",
        "    # Weekly patterns\n",
        "    weekly_patterns = df_transactions.groupby('weekday')['gross_value'].sum().sort_values(ascending=False)\n",
        "    print(f\"\\n📅 Weekly Sales Patterns:\")\n",
        "    for day, revenue in weekly_patterns.items():\n",
        "        print(f\"   {day}: ${revenue:,.2f}\")\n",
        "    \n",
        "    # Monthly trends\n",
        "    if 'gross_value' in df_transactions.columns:\n",
        "        monthly_trends = df_transactions.groupby(['year', 'month'])['gross_value'].sum()\n",
        "        print(f\"\\n🗓️ Monthly Revenue Trends:\")\n",
        "        for (year, month), revenue in monthly_trends.items():\n",
        "            print(f\"   {year}-{month:02d}: ${revenue:,.2f}\")\n",
        "\n",
        "# Seasonality detection\n",
        "print(f\"\\n🌟 Seasonality Insights:\")\n",
        "if 'month' in df_transactions.columns:\n",
        "    seasonal_pattern = df_transactions.groupby('month')['gross_value'].mean().round(2)\n",
        "    peak_month = seasonal_pattern.idxmax()\n",
        "    low_month = seasonal_pattern.idxmin()\n",
        "    print(f\"   Peak Sales Month: {peak_month} (${seasonal_pattern[peak_month]:,.2f} avg)\")\n",
        "    print(f\"   Lowest Sales Month: {low_month} (${seasonal_pattern[low_month]:,.2f} avg)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "c572c185",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "🛍️ PRODUCT PORTFOLIO ANALYSIS\n",
            "================================================================================\n",
            "📦 Product Categories Overview:\n",
            "   Total Categories: 7\n",
            "   Top 10 Categories:\n",
            "      Distilled Spirits: 2,202 products\n",
            "      Wine: 1,879 products\n",
            "      Package: 1,403 products\n",
            "      Draft: 918 products\n",
            "      Non-Alcohol: 597 products\n",
            "      ABA Spirits: 91 products\n",
            "      Tobacco: 2 products\n",
            "\n",
            "🏷️ Brand Analysis:\n",
            "   Total Brands: 4221\n",
            "   Top 10 Brands:\n",
            "      Barrell Bourbon- Private Label: 60 products\n",
            "      Bud Light: 38 products\n",
            "      Budweiser: 36 products\n",
            "      Barrell Stellum - Private Label: 35 products\n",
            "      Fireball Cinnamon Whiskey: 28 products\n",
            "      Buffalo Trace Kentucky Straight Bourbon Whiskey: 27 products\n",
            "      Yukon Jack Canadian Whiskey Honey: 24 products\n",
            "      Stella Artois: 21 products\n",
            "      Michelob Ultra: 21 products\n",
            "      Chi-Chi's Variety Pack: 20 products\n",
            "\n",
            "🏭 Manufacturer Analysis:\n",
            "   Total Manufacturers: 343\n",
            "   Top 10 Manufacturers:\n",
            "      Sazerac Spirits: 1,169 products\n",
            "      AB Anheuser Busch Inc: 878 products\n",
            "      Tilray Brands: 311 products\n",
            "      Barrell Craft Spirits: 132 products\n",
            "      Pacific Edge Wine & Spirits: 130 products\n",
            "      Sazerac ABA: 125 products\n",
            "      Small Vineyards: 112 products\n",
            "      National - The Wine Group: 109 products\n",
            "      Monday Night Brewing: 108 products\n",
            "      Scott Levy: 105 products\n",
            "\n",
            "🎯 Product Types Distribution:\n",
            "   Total Types: 22\n",
            "      Distilled Spirits: 1,816 products\n",
            "      Package: 1,384 products\n",
            "      Wine < 14 %: 1,377 products\n",
            "      Draft: 913 products\n",
            "      Wine > 14 %: 555 products\n",
            "      Non Alcohol: 531 products\n",
            "      Allocated Spirits: 201 products\n",
            "      Distilled Spirits-RTD: 103 products\n",
            "      Hispanic: 52 products\n",
            "      Non Alcohol W&S: 47 products\n",
            "      Distilled Spirits-Domest: 44 products\n",
            "      N/A Beer: 17 products\n",
            "      Wine RTD: 14 products\n",
            "      Wine < 14 % - Domestic: 11 products\n",
            "      Cider Pkg: 8 products\n"
          ]
        }
      ],
      "source": [
        "# 🛍️ PRODUCT PORTFOLIO ANALYSIS - The Product Universe!\n",
        "print(\"=\"*80)\n",
        "print(\"🛍️ PRODUCT PORTFOLIO ANALYSIS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Product categories analysis\n",
        "print(\"📦 Product Categories Overview:\")\n",
        "if 'categoria' in df_products.columns:\n",
        "    category_counts = df_products['categoria'].value_counts()\n",
        "    print(f\"   Total Categories: {len(category_counts)}\")\n",
        "    print(\"   Top 10 Categories:\")\n",
        "    for cat, count in category_counts.head(10).items():\n",
        "        print(f\"      {cat}: {count:,} products\")\n",
        "\n",
        "# Brand analysis\n",
        "print(f\"\\n🏷️ Brand Analysis:\")\n",
        "if 'marca' in df_products.columns:\n",
        "    brand_counts = df_products['marca'].value_counts()\n",
        "    print(f\"   Total Brands: {len(brand_counts)}\")\n",
        "    print(\"   Top 10 Brands:\")\n",
        "    for brand, count in brand_counts.head(10).items():\n",
        "        print(f\"      {brand}: {count:,} products\")\n",
        "\n",
        "# Manufacturer analysis\n",
        "print(f\"\\n🏭 Manufacturer Analysis:\")\n",
        "if 'fabricante' in df_products.columns:\n",
        "    mfg_counts = df_products['fabricante'].value_counts()\n",
        "    print(f\"   Total Manufacturers: {len(mfg_counts)}\")\n",
        "    print(\"   Top 10 Manufacturers:\")\n",
        "    for mfg, count in mfg_counts.head(10).items():\n",
        "        print(f\"      {mfg}: {count:,} products\")\n",
        "\n",
        "# Product types analysis\n",
        "print(f\"\\n🎯 Product Types Distribution:\")\n",
        "if 'tipos' in df_products.columns:\n",
        "    type_counts = df_products['tipos'].value_counts()\n",
        "    print(f\"   Total Types: {len(type_counts)}\")\n",
        "    for ptype, count in type_counts.head(15).items():\n",
        "        print(f\"      {ptype}: {count:,} products\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "b2ee36b2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "🗺️ GEOGRAPHICAL ANALYSIS\n",
            "================================================================================\n",
            "📍 Zipcode Distribution:\n",
            "   Total Unique Zipcodes: 788\n",
            "   Top 15 Zipcodes by Store Count:\n",
            "      80202: 230 stores\n",
            "      30096: 133 stores\n",
            "      80205: 129 stores\n",
            "      80211: 127 stores\n",
            "      81301: 123 stores\n",
            "      80524: 113 stores\n",
            "      80501: 108 stores\n",
            "      30120: 105 stores\n",
            "      30161: 105 stores\n",
            "      80424: 103 stores\n",
            "      80903: 103 stores\n",
            "      30721: 102 stores\n",
            "      80203: 102 stores\n",
            "      80525: 100 stores\n",
            "      80302: 100 stores\n",
            "\n",
            "🏪 PDV Categories:\n",
            "   Total Categories: 54\n",
            "      Restaurant: 3,316 stores\n",
            "      Convenience: 2,849 stores\n",
            "      Package/Liquor: 2,153 stores\n",
            "      Bar: 1,444 stores\n",
            "      Grocery: 697 stores\n",
            "      Mexican Rest: 623 stores\n",
            "      Other On Premise: 473 stores\n",
            "      Hotel/Motel: 359 stores\n",
            "      Asian: 263 stores\n",
            "      Pizza: 187 stores\n",
            "      Super Center: 181 stores\n",
            "      Golf - Public: 168 stores\n",
            "      Drug: 167 stores\n",
            "      Italian: 144 stores\n",
            "      Service Org: 138 stores\n",
            "      Special Event: 137 stores\n",
            "      Golf - Private: 113 stores\n",
            "      Billiard/Bowling: 91 stores\n",
            "      Sports/Rec Club: 88 stores\n",
            "      Stadium/Concession: 79 stores\n",
            "      Barbeque: 76 stores\n",
            "      Theatre: 75 stores\n",
            "      Club Store: 65 stores\n",
            "      Banquet/Caterer: 55 stores\n",
            "      Night Club: 52 stores\n",
            "      Irish: 46 stores\n",
            "      Church: 43 stores\n",
            "      Sample Room: 35 stores\n",
            "      Music Venue: 33 stores\n",
            "      Coffee House: 33 stores\n",
            "      Other Off Premise: 32 stores\n",
            "      Airline/Airport: 20 stores\n",
            "      Bodega: 19 stores\n",
            "      Korean: 18 stores\n",
            "      Adult Entertainment: 17 stores\n",
            "      All Other N/A Off Premise: 16 stores\n",
            "      All Other N/A On Premise: 16 stores\n",
            "      Gay Bar: 16 stores\n",
            "      Military: 11 stores\n",
            "      French: 11 stores\n",
            "      Winery: 9 stores\n",
            "      Gym/Fitness: 8 stores\n",
            "      Theme Park: 7 stores\n",
            "      Sub Distributor: 6 stores\n",
            "      Health Club: 5 stores\n",
            "      German: 4 stores\n",
            "      Salon/Spa/Tann: 4 stores\n",
            "      Non-Traditional: 3 stores\n",
            "      Race Track: 3 stores\n",
            "      Marina / Lake: 3 stores\n",
            "      Neighborhood Store: 3 stores\n",
            "      Country/Western: 3 stores\n",
            "      Casino: 1 stores\n",
            "      Mass Merch: 1 stores\n",
            "\n",
            "🏢 Store Premise Types:\n",
            "   Total Premise Types: 2\n",
            "      On Premise: 8,216 stores\n",
            "      Off Premise: 6,203 stores\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# 🗺️ GEOGRAPHICAL ANALYSIS - The Map Masters!\n",
        "print(\"=\"*80)\n",
        "print(\"🗺️ GEOGRAPHICAL ANALYSIS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# PDV location analysis\n",
        "if 'zipcode' in df_pdv.columns:\n",
        "    zipcode_analysis = df_pdv['zipcode'].value_counts()\n",
        "    print(f\"📍 Zipcode Distribution:\")\n",
        "    print(f\"   Total Unique Zipcodes: {len(zipcode_analysis)}\")\n",
        "    print(\"   Top 15 Zipcodes by Store Count:\")\n",
        "    for zip_code, count in zipcode_analysis.head(15).items():\n",
        "        print(f\"      {zip_code}: {count:,} stores\")\n",
        "\n",
        "# PDV category analysis\n",
        "if 'categoria_pdv' in df_pdv.columns:\n",
        "    pdv_categories = df_pdv['categoria_pdv'].value_counts()\n",
        "    print(f\"\\n🏪 PDV Categories:\")\n",
        "    print(f\"   Total Categories: {len(pdv_categories)}\")\n",
        "    for category, count in pdv_categories.items():\n",
        "        print(f\"      {category}: {count:,} stores\")\n",
        "\n",
        "# Store premise analysis\n",
        "if 'premise' in df_pdv.columns:\n",
        "    premise_analysis = df_pdv['premise'].value_counts()\n",
        "    print(f\"\\n🏢 Store Premise Types:\")\n",
        "    print(f\"   Total Premise Types: {len(premise_analysis)}\")\n",
        "    for premise, count in premise_analysis.head(10).items():\n",
        "        print(f\"      {premise}: {count:,} stores\")\n",
        "\n",
        "print(\"-\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "14eefe09",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "📈 CREATING KILLER VISUALIZATIONS\n",
            "================================================================================\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'make_subplots' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m80\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Create a subplot figure for comprehensive analysis\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m fig = \u001b[43mmake_subplots\u001b[49m(\n\u001b[32m      8\u001b[39m     rows=\u001b[32m2\u001b[39m, cols=\u001b[32m2\u001b[39m,\n\u001b[32m      9\u001b[39m     subplot_titles=(\u001b[33m'\u001b[39m\u001b[33mDaily Sales Trend\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mWeekly Pattern\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mTop Categories\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mRevenue Distribution\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m     10\u001b[39m     specs=[[{\u001b[33m\"\u001b[39m\u001b[33msecondary_y\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m}, {\u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mbar\u001b[39m\u001b[33m\"\u001b[39m}],\n\u001b[32m     11\u001b[39m            [{\u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mpie\u001b[39m\u001b[33m\"\u001b[39m}, {\u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mhistogram\u001b[39m\u001b[33m\"\u001b[39m}]]\n\u001b[32m     12\u001b[39m )\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# 1. Daily sales trend\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mtransaction_date\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m df_transactions.columns \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mgross_value\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m df_transactions.columns:\n",
            "\u001b[31mNameError\u001b[39m: name 'make_subplots' is not defined"
          ]
        }
      ],
      "source": [
        "# 📈 ADVANCED VISUALIZATIONS - The Eye Candy!\n",
        "print(\"=\"*80)\n",
        "print(\"📈 CREATING KILLER VISUALIZATIONS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Create a subplot figure for comprehensive analysis\n",
        "fig = make_subplots(\n",
        "    rows=2, cols=2,\n",
        "    subplot_titles=('Daily Sales Trend', 'Weekly Pattern', 'Top Categories', 'Revenue Distribution'),\n",
        "    specs=[[{\"secondary_y\": True}, {\"type\": \"bar\"}],\n",
        "           [{\"type\": \"pie\"}, {\"type\": \"histogram\"}]]\n",
        ")\n",
        "\n",
        "# 1. Daily sales trend\n",
        "if 'transaction_date' in df_transactions.columns and 'gross_value' in df_transactions.columns:\n",
        "    daily_sales = df_transactions.groupby('transaction_date')['gross_value'].sum().reset_index()\n",
        "    fig.add_trace(\n",
        "        go.Scatter(x=daily_sales['transaction_date'], y=daily_sales['gross_value'],\n",
        "                  mode='lines+markers', name='Daily Sales'),\n",
        "        row=1, col=1\n",
        "    )\n",
        "\n",
        "# 2. Weekly patterns\n",
        "if 'weekday' in df_transactions.columns:\n",
        "    weekly_data = df_transactions.groupby('weekday')['gross_value'].sum().reset_index()\n",
        "    weekday_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
        "    weekly_data['weekday'] = pd.Categorical(weekly_data['weekday'], categories=weekday_order, ordered=True)\n",
        "    weekly_data = weekly_data.sort_values('weekday')\n",
        "    \n",
        "    fig.add_trace(\n",
        "        go.Bar(x=weekly_data['weekday'], y=weekly_data['gross_value'],\n",
        "               name='Weekly Sales', marker_color='lightblue'),\n",
        "        row=1, col=2\n",
        "    )\n",
        "\n",
        "# 3. Top product categories (if we can link products to transactions)\n",
        "if 'categoria' in df_products.columns:\n",
        "    top_categories = df_products['categoria'].value_counts().head(8)\n",
        "    fig.add_trace(\n",
        "        go.Pie(labels=top_categories.index, values=top_categories.values,\n",
        "               name=\"Categories\"),\n",
        "        row=2, col=1\n",
        "    )\n",
        "\n",
        "# 4. Revenue distribution\n",
        "if 'gross_value' in df_transactions.columns:\n",
        "    fig.add_trace(\n",
        "        go.Histogram(x=df_transactions['gross_value'], name='Revenue Distribution',\n",
        "                    nbinsx=50, marker_color='orange'),\n",
        "        row=2, col=2\n",
        "    )\n",
        "\n",
        "# Update layout\n",
        "fig.update_layout(height=800, showlegend=True, \n",
        "                  title_text=\"🚀 Comprehensive Retail Analytics Dashboard\")\n",
        "fig.show()\n",
        "\n",
        "print(\"✅ Interactive dashboard created!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "57bde639",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "🔗 CORRELATION ANALYSIS\n",
            "================================================================================\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'plt' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m correlation_matrix = df_transactions[available_financial].corr()\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Create correlation heatmap\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[43mplt\u001b[49m.figure(figsize=(\u001b[32m12\u001b[39m, \u001b[32m8\u001b[39m))\n\u001b[32m     15\u001b[39m sns.heatmap(correlation_matrix, annot=\u001b[38;5;28;01mTrue\u001b[39;00m, cmap=\u001b[33m'\u001b[39m\u001b[33mcoolwarm\u001b[39m\u001b[33m'\u001b[39m, center=\u001b[32m0\u001b[39m, \n\u001b[32m     16\u001b[39m             square=\u001b[38;5;28;01mTrue\u001b[39;00m, linewidths=\u001b[32m0.5\u001b[39m, cbar_kws={\u001b[33m\"\u001b[39m\u001b[33mshrink\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m.8\u001b[39m})\n\u001b[32m     17\u001b[39m plt.title(\u001b[33m'\u001b[39m\u001b[33m💰 Financial Metrics Correlation Matrix\u001b[39m\u001b[33m'\u001b[39m, fontsize=\u001b[32m16\u001b[39m, fontweight=\u001b[33m'\u001b[39m\u001b[33mbold\u001b[39m\u001b[33m'\u001b[39m)\n",
            "\u001b[31mNameError\u001b[39m: name 'plt' is not defined"
          ]
        }
      ],
      "source": [
        "# 🔗 CORRELATION ANALYSIS - Finding Hidden Relationships!\n",
        "print(\"=\"*80)\n",
        "print(\"🔗 CORRELATION ANALYSIS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Financial metrics correlation\n",
        "financial_cols = ['quantity', 'gross_value', 'net_value', 'gross_profit', 'discount', 'taxes']\n",
        "available_financial = [col for col in financial_cols if col in df_transactions.columns]\n",
        "\n",
        "if len(available_financial) > 1:\n",
        "    correlation_matrix = df_transactions[available_financial].corr()\n",
        "    \n",
        "    # Create correlation heatmap\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
        "                square=True, linewidths=0.5, cbar_kws={\"shrink\": .8})\n",
        "    plt.title('💰 Financial Metrics Correlation Matrix', fontsize=16, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"🔍 Key Correlations:\")\n",
        "    # Find strongest correlations\n",
        "    for i in range(len(correlation_matrix.columns)):\n",
        "        for j in range(i+1, len(correlation_matrix.columns)):\n",
        "            corr_val = correlation_matrix.iloc[i, j]\n",
        "            if abs(corr_val) > 0.7:  # Strong correlation\n",
        "                col1, col2 = correlation_matrix.columns[i], correlation_matrix.columns[j]\n",
        "                print(f\"   {col1} ↔ {col2}: {corr_val:.3f}\")\n",
        "\n",
        "# Distributor performance analysis\n",
        "if 'distributor_id' in df_transactions.columns and 'gross_value' in df_transactions.columns:\n",
        "    distributor_performance = df_transactions.groupby('distributor_id').agg({\n",
        "        'gross_value': ['sum', 'mean', 'count'],\n",
        "        'quantity': 'sum',\n",
        "        'gross_profit': 'sum' if 'gross_profit' in df_transactions.columns else 'mean'\n",
        "    }).round(2)\n",
        "    \n",
        "    print(f\"\\n🚚 Top 10 Distributors by Revenue:\")\n",
        "    top_distributors = df_transactions.groupby('distributor_id')['gross_value'].sum().sort_values(ascending=False).head(10)\n",
        "    for dist_id, revenue in top_distributors.items():\n",
        "        transactions_count = df_transactions[df_transactions['distributor_id'] == dist_id].shape[0]\n",
        "        print(f\"   Distributor {dist_id}: ${revenue:,.2f} ({transactions_count:,} transactions)\")\n",
        "\n",
        "print(\"-\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "7dc620f3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- 1. DADOS DAS LOJAS (PDV) ---\n",
            "Shape: (14419, 4)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pdv</th>\n",
              "      <th>premise</th>\n",
              "      <th>categoria_pdv</th>\n",
              "      <th>zipcode</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2204965430669363375</td>\n",
              "      <td>On Premise</td>\n",
              "      <td>Mexican Rest</td>\n",
              "      <td>30741</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5211957289528622910</td>\n",
              "      <td>On Premise</td>\n",
              "      <td>Hotel/Motel</td>\n",
              "      <td>80011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9024493554530757353</td>\n",
              "      <td>Off Premise</td>\n",
              "      <td>Convenience</td>\n",
              "      <td>80751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8659197371382902429</td>\n",
              "      <td>On Premise</td>\n",
              "      <td>Restaurant</td>\n",
              "      <td>80439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1400854873763881130</td>\n",
              "      <td>On Premise</td>\n",
              "      <td>Restaurant</td>\n",
              "      <td>30093</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   pdv      premise categoria_pdv  zipcode\n",
              "0  2204965430669363375   On Premise  Mexican Rest    30741\n",
              "1  5211957289528622910   On Premise   Hotel/Motel    80011\n",
              "2  9024493554530757353  Off Premise   Convenience    80751\n",
              "3  8659197371382902429   On Premise    Restaurant    80439\n",
              "4  1400854873763881130   On Premise    Restaurant    30093"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\\n==================================================\\n\n",
            "--- 2. DADOS DAS TRANSAÇÕES ---\n",
            "Shape: (6560698, 16)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>internal_store_id</th>\n",
              "      <th>internal_product_id</th>\n",
              "      <th>distributor_id</th>\n",
              "      <th>transaction_date</th>\n",
              "      <th>reference_date</th>\n",
              "      <th>quantity</th>\n",
              "      <th>gross_value</th>\n",
              "      <th>net_value</th>\n",
              "      <th>gross_profit</th>\n",
              "      <th>discount</th>\n",
              "      <th>taxes</th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>weekday</th>\n",
              "      <th>week</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7384367747233276219</td>\n",
              "      <td>328903483604537190</td>\n",
              "      <td>9</td>\n",
              "      <td>2022-07-13</td>\n",
              "      <td>2022-07-01</td>\n",
              "      <td>1.0</td>\n",
              "      <td>38.125000</td>\n",
              "      <td>37.890625</td>\n",
              "      <td>10.042625</td>\n",
              "      <td>3.950000</td>\n",
              "      <td>0.234375</td>\n",
              "      <td>2022</td>\n",
              "      <td>7</td>\n",
              "      <td>13</td>\n",
              "      <td>Wednesday</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3536908514005606262</td>\n",
              "      <td>5418855670645487653</td>\n",
              "      <td>5</td>\n",
              "      <td>2022-03-21</td>\n",
              "      <td>2022-03-01</td>\n",
              "      <td>6.0</td>\n",
              "      <td>107.250000</td>\n",
              "      <td>106.440002</td>\n",
              "      <td>24.732002</td>\n",
              "      <td>17.100000</td>\n",
              "      <td>0.810000</td>\n",
              "      <td>2022</td>\n",
              "      <td>3</td>\n",
              "      <td>21</td>\n",
              "      <td>Monday</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3138231730993449825</td>\n",
              "      <td>1087005562675741887</td>\n",
              "      <td>6</td>\n",
              "      <td>2022-09-06</td>\n",
              "      <td>2022-09-01</td>\n",
              "      <td>3.0</td>\n",
              "      <td>56.625000</td>\n",
              "      <td>56.220001</td>\n",
              "      <td>14.124002</td>\n",
              "      <td>5.250000</td>\n",
              "      <td>0.405000</td>\n",
              "      <td>2022</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>Tuesday</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3681167389484217654</td>\n",
              "      <td>1401422983880045188</td>\n",
              "      <td>5</td>\n",
              "      <td>2022-09-11</td>\n",
              "      <td>2022-09-01</td>\n",
              "      <td>129.0</td>\n",
              "      <td>1037.160023</td>\n",
              "      <td>1037.160023</td>\n",
              "      <td>156.348026</td>\n",
              "      <td>479.880006</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2022</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "      <td>Sunday</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7762413312337359369</td>\n",
              "      <td>6614994347738381720</td>\n",
              "      <td>4</td>\n",
              "      <td>2022-02-18</td>\n",
              "      <td>2022-02-01</td>\n",
              "      <td>1.0</td>\n",
              "      <td>26.230000</td>\n",
              "      <td>23.950241</td>\n",
              "      <td>6.550241</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.279758</td>\n",
              "      <td>2022</td>\n",
              "      <td>2</td>\n",
              "      <td>18</td>\n",
              "      <td>Friday</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     internal_store_id  internal_product_id distributor_id transaction_date  \\\n",
              "0  7384367747233276219   328903483604537190              9       2022-07-13   \n",
              "1  3536908514005606262  5418855670645487653              5       2022-03-21   \n",
              "2  3138231730993449825  1087005562675741887              6       2022-09-06   \n",
              "3  3681167389484217654  1401422983880045188              5       2022-09-11   \n",
              "4  7762413312337359369  6614994347738381720              4       2022-02-18   \n",
              "\n",
              "  reference_date  quantity  gross_value    net_value  gross_profit  \\\n",
              "0     2022-07-01       1.0    38.125000    37.890625     10.042625   \n",
              "1     2022-03-01       6.0   107.250000   106.440002     24.732002   \n",
              "2     2022-09-01       3.0    56.625000    56.220001     14.124002   \n",
              "3     2022-09-01     129.0  1037.160023  1037.160023    156.348026   \n",
              "4     2022-02-01       1.0    26.230000    23.950241      6.550241   \n",
              "\n",
              "     discount     taxes  year  month  day    weekday  week  \n",
              "0    3.950000  0.234375  2022      7   13  Wednesday    28  \n",
              "1   17.100000  0.810000  2022      3   21     Monday    12  \n",
              "2    5.250000  0.405000  2022      9    6    Tuesday    36  \n",
              "3  479.880006  0.000000  2022      9   11     Sunday    36  \n",
              "4    0.000000  2.279758  2022      2   18     Friday     7  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\\n==================================================\\n\n",
            "--- 3. DADOS DOS PRODUTOS ---\n",
            "Shape: (7092, 8)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>produto</th>\n",
              "      <th>categoria</th>\n",
              "      <th>descricao</th>\n",
              "      <th>tipos</th>\n",
              "      <th>label</th>\n",
              "      <th>subcategoria</th>\n",
              "      <th>marca</th>\n",
              "      <th>fabricante</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2282334733936076502</td>\n",
              "      <td>Distilled Spirits</td>\n",
              "      <td>JOSEPH CARTRON CAFÉ LIQUEUR</td>\n",
              "      <td>Distilled Spirits</td>\n",
              "      <td>Core</td>\n",
              "      <td>Liqueurs &amp; Cordials</td>\n",
              "      <td>Joseph Cartron Cafe</td>\n",
              "      <td>Spiribam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6091840953834683482</td>\n",
              "      <td>Distilled Spirits</td>\n",
              "      <td>SPRINGBANK 18 YEAR SINGLE MALT 700ML</td>\n",
              "      <td>Distilled Spirits</td>\n",
              "      <td>Specialty</td>\n",
              "      <td>Scotch Whisky</td>\n",
              "      <td>Springbank 18 Year Single Malt</td>\n",
              "      <td>Pacific Edge Wine &amp; Spirits</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1968645851245092408</td>\n",
              "      <td>Distilled Spirits</td>\n",
              "      <td>J BRANDT TRIPLE SEC 12/750ML 30PF</td>\n",
              "      <td>Distilled Spirits</td>\n",
              "      <td>Private Label</td>\n",
              "      <td>Liqueurs &amp; Cordials</td>\n",
              "      <td>J Brandt Triple Sec</td>\n",
              "      <td>Sazerac Spirits</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>994706710729219179</td>\n",
              "      <td>Draft</td>\n",
              "      <td>REFORMATION CASHMERE IPA 1/4 KEG</td>\n",
              "      <td>Draft</td>\n",
              "      <td>In&amp;Out</td>\n",
              "      <td>Other Draft</td>\n",
              "      <td>Reformation Cashmere Fresh Hop IPA</td>\n",
              "      <td>Reformation Brewery</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9209550539540384349</td>\n",
              "      <td>Non-Alcohol</td>\n",
              "      <td>HELLA MOSCOW MULE 750ML</td>\n",
              "      <td>Non Alcohol</td>\n",
              "      <td>Core</td>\n",
              "      <td>Mixers</td>\n",
              "      <td>Hella Bitters Bloody Mary</td>\n",
              "      <td>Hella Bitter Llc</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               produto          categoria  \\\n",
              "0  2282334733936076502  Distilled Spirits   \n",
              "1  6091840953834683482  Distilled Spirits   \n",
              "2  1968645851245092408  Distilled Spirits   \n",
              "3   994706710729219179              Draft   \n",
              "4  9209550539540384349        Non-Alcohol   \n",
              "\n",
              "                              descricao              tipos          label  \\\n",
              "0           JOSEPH CARTRON CAFÉ LIQUEUR  Distilled Spirits           Core   \n",
              "1  SPRINGBANK 18 YEAR SINGLE MALT 700ML  Distilled Spirits      Specialty   \n",
              "2     J BRANDT TRIPLE SEC 12/750ML 30PF  Distilled Spirits  Private Label   \n",
              "3      REFORMATION CASHMERE IPA 1/4 KEG              Draft         In&Out   \n",
              "4               HELLA MOSCOW MULE 750ML        Non Alcohol           Core   \n",
              "\n",
              "          subcategoria                               marca  \\\n",
              "0  Liqueurs & Cordials                 Joseph Cartron Cafe   \n",
              "1        Scotch Whisky      Springbank 18 Year Single Malt   \n",
              "2  Liqueurs & Cordials                 J Brandt Triple Sec   \n",
              "3          Other Draft  Reformation Cashmere Fresh Hop IPA   \n",
              "4               Mixers           Hella Bitters Bloody Mary   \n",
              "\n",
              "                    fabricante  \n",
              "0                     Spiribam  \n",
              "1  Pacific Edge Wine & Spirits  \n",
              "2              Sazerac Spirits  \n",
              "3          Reformation Brewery  \n",
              "4             Hella Bitter Llc  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "# --- VERIFICAÇÃO ---\n",
        "# Vamos verificar se os arquivos foram carregados corretamente.\n",
        "\n",
        "print(\"--- 1. DADOS DAS LOJAS (PDV) ---\")\n",
        "print(f\"Shape: {df_pdv.shape}\") # Mostra (linhas, colunas)\n",
        "display(df_pdv.head())         # Mostra as 5 primeiras linhas\n",
        "print(\"\\\\n\" + \"=\"*50 + \"\\\\n\")\n",
        "\n",
        "print(\"--- 2. DADOS DAS TRANSAÇÕES ---\")\n",
        "print(f\"Shape: {df_transactions.shape}\")\n",
        "display(df_transactions.head())\n",
        "print(\"\\\\n\" + \"=\"*50 + \"\\\\n\")\n",
        "\n",
        "print(\"--- 3. DADOS DOS PRODUTOS ---\")\n",
        "print(f\"Shape: {df_products.shape}\")\n",
        "display(df_products.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "de96abf7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iniciando a junção das tabelas...\n",
            "Após juntar com produtos, a tabela tem 24 colunas.\n",
            "Após juntar com as lojas, a tabela final tem 28 colunas.\n",
            "\\nJunção concluída! Vamos verificar o resultado:\n",
            "Shape da tabela original de transações: (6560698, 16)\n",
            "Shape da tabela final combinada:      (6560698, 28)\n",
            "\\nExemplo da tabela combinada (note as colunas 'marca', 'categoria', 'premise', etc.):\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>internal_store_id</th>\n",
              "      <th>internal_product_id</th>\n",
              "      <th>distributor_id</th>\n",
              "      <th>transaction_date</th>\n",
              "      <th>reference_date</th>\n",
              "      <th>quantity</th>\n",
              "      <th>gross_value</th>\n",
              "      <th>net_value</th>\n",
              "      <th>gross_profit</th>\n",
              "      <th>discount</th>\n",
              "      <th>...</th>\n",
              "      <th>descricao</th>\n",
              "      <th>tipos</th>\n",
              "      <th>label</th>\n",
              "      <th>subcategoria</th>\n",
              "      <th>marca</th>\n",
              "      <th>fabricante</th>\n",
              "      <th>pdv</th>\n",
              "      <th>premise</th>\n",
              "      <th>categoria_pdv</th>\n",
              "      <th>zipcode</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7384367747233276219</td>\n",
              "      <td>328903483604537190</td>\n",
              "      <td>9</td>\n",
              "      <td>2022-07-13</td>\n",
              "      <td>2022-07-01</td>\n",
              "      <td>1.0</td>\n",
              "      <td>38.125000</td>\n",
              "      <td>37.890625</td>\n",
              "      <td>10.042625</td>\n",
              "      <td>3.950000</td>\n",
              "      <td>...</td>\n",
              "      <td>BUD LIGHT CHELADA FUEGO 15/25 CN</td>\n",
              "      <td>Package</td>\n",
              "      <td>Core</td>\n",
              "      <td>Specialty</td>\n",
              "      <td>Bud Light Chelada Fuego</td>\n",
              "      <td>AB Anheuser Busch Inc</td>\n",
              "      <td>7384367747233276219</td>\n",
              "      <td>Off Premise</td>\n",
              "      <td>Package/Liquor</td>\n",
              "      <td>80905.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3536908514005606262</td>\n",
              "      <td>5418855670645487653</td>\n",
              "      <td>5</td>\n",
              "      <td>2022-03-21</td>\n",
              "      <td>2022-03-01</td>\n",
              "      <td>6.0</td>\n",
              "      <td>107.250000</td>\n",
              "      <td>106.440002</td>\n",
              "      <td>24.732002</td>\n",
              "      <td>17.100000</td>\n",
              "      <td>...</td>\n",
              "      <td>MICHELOB ULTRA 18/12 CN</td>\n",
              "      <td>Package</td>\n",
              "      <td>Core</td>\n",
              "      <td>Lager</td>\n",
              "      <td>Michelob Ultra</td>\n",
              "      <td>AB Anheuser Busch Inc</td>\n",
              "      <td>3536908514005606262</td>\n",
              "      <td>Off Premise</td>\n",
              "      <td>Package/Liquor</td>\n",
              "      <td>80239.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3138231730993449825</td>\n",
              "      <td>1087005562675741887</td>\n",
              "      <td>6</td>\n",
              "      <td>2022-09-06</td>\n",
              "      <td>2022-09-01</td>\n",
              "      <td>3.0</td>\n",
              "      <td>56.625000</td>\n",
              "      <td>56.220001</td>\n",
              "      <td>14.124002</td>\n",
              "      <td>5.250000</td>\n",
              "      <td>...</td>\n",
              "      <td>BUD LIGHT LIME 18/12 CN</td>\n",
              "      <td>Package</td>\n",
              "      <td>Core</td>\n",
              "      <td>Lager</td>\n",
              "      <td>Bud Light Lime</td>\n",
              "      <td>AB Anheuser Busch Inc</td>\n",
              "      <td>3138231730993449825</td>\n",
              "      <td>Off Premise</td>\n",
              "      <td>Package/Liquor</td>\n",
              "      <td>80634.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3681167389484217654</td>\n",
              "      <td>1401422983880045188</td>\n",
              "      <td>5</td>\n",
              "      <td>2022-09-11</td>\n",
              "      <td>2022-09-01</td>\n",
              "      <td>129.0</td>\n",
              "      <td>1037.160023</td>\n",
              "      <td>1037.160023</td>\n",
              "      <td>156.348026</td>\n",
              "      <td>479.880006</td>\n",
              "      <td>...</td>\n",
              "      <td>99 BUTTERSCOTCH 12/10/50ML 99PF</td>\n",
              "      <td>Allocated Spirits</td>\n",
              "      <td>None</td>\n",
              "      <td>Liqueurs &amp; Cordials</td>\n",
              "      <td>99 Butterscotch</td>\n",
              "      <td>Sazerac Spirits</td>\n",
              "      <td>3681167389484217654</td>\n",
              "      <td>Off Premise</td>\n",
              "      <td>Package/Liquor</td>\n",
              "      <td>80226.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7762413312337359369</td>\n",
              "      <td>6614994347738381720</td>\n",
              "      <td>4</td>\n",
              "      <td>2022-02-18</td>\n",
              "      <td>2022-02-01</td>\n",
              "      <td>1.0</td>\n",
              "      <td>26.230000</td>\n",
              "      <td>23.950241</td>\n",
              "      <td>6.550241</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>NB VOODOO RANGER IMPERIAL IPA 15/19.2 CN</td>\n",
              "      <td>Package</td>\n",
              "      <td>Core</td>\n",
              "      <td>IPA</td>\n",
              "      <td>New Belgium Voodoo Ranger Imperial IPA</td>\n",
              "      <td>NB New Belgium</td>\n",
              "      <td>7762413312337359369</td>\n",
              "      <td>Off Premise</td>\n",
              "      <td>Convenience</td>\n",
              "      <td>30096.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 28 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     internal_store_id  internal_product_id distributor_id transaction_date  \\\n",
              "0  7384367747233276219   328903483604537190              9       2022-07-13   \n",
              "1  3536908514005606262  5418855670645487653              5       2022-03-21   \n",
              "2  3138231730993449825  1087005562675741887              6       2022-09-06   \n",
              "3  3681167389484217654  1401422983880045188              5       2022-09-11   \n",
              "4  7762413312337359369  6614994347738381720              4       2022-02-18   \n",
              "\n",
              "  reference_date  quantity  gross_value    net_value  gross_profit  \\\n",
              "0     2022-07-01       1.0    38.125000    37.890625     10.042625   \n",
              "1     2022-03-01       6.0   107.250000   106.440002     24.732002   \n",
              "2     2022-09-01       3.0    56.625000    56.220001     14.124002   \n",
              "3     2022-09-01     129.0  1037.160023  1037.160023    156.348026   \n",
              "4     2022-02-01       1.0    26.230000    23.950241      6.550241   \n",
              "\n",
              "     discount  ...                                 descricao  \\\n",
              "0    3.950000  ...          BUD LIGHT CHELADA FUEGO 15/25 CN   \n",
              "1   17.100000  ...                   MICHELOB ULTRA 18/12 CN   \n",
              "2    5.250000  ...                   BUD LIGHT LIME 18/12 CN   \n",
              "3  479.880006  ...           99 BUTTERSCOTCH 12/10/50ML 99PF   \n",
              "4    0.000000  ...  NB VOODOO RANGER IMPERIAL IPA 15/19.2 CN   \n",
              "\n",
              "               tipos  label         subcategoria  \\\n",
              "0            Package   Core            Specialty   \n",
              "1            Package   Core                Lager   \n",
              "2            Package   Core                Lager   \n",
              "3  Allocated Spirits   None  Liqueurs & Cordials   \n",
              "4            Package   Core                  IPA   \n",
              "\n",
              "                                    marca             fabricante  \\\n",
              "0                 Bud Light Chelada Fuego  AB Anheuser Busch Inc   \n",
              "1                          Michelob Ultra  AB Anheuser Busch Inc   \n",
              "2                          Bud Light Lime  AB Anheuser Busch Inc   \n",
              "3                         99 Butterscotch        Sazerac Spirits   \n",
              "4  New Belgium Voodoo Ranger Imperial IPA         NB New Belgium   \n",
              "\n",
              "                   pdv      premise   categoria_pdv  zipcode  \n",
              "0  7384367747233276219  Off Premise  Package/Liquor  80905.0  \n",
              "1  3536908514005606262  Off Premise  Package/Liquor  80239.0  \n",
              "2  3138231730993449825  Off Premise  Package/Liquor  80634.0  \n",
              "3  3681167389484217654  Off Premise  Package/Liquor  80226.0  \n",
              "4  7762413312337359369  Off Premise     Convenience  30096.0  \n",
              "\n",
              "[5 rows x 28 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# --- PASSO 1: JUNTAR OS DATAFRAMES (MERGE) ---\n",
        "\n",
        "print(\"Iniciando a junção das tabelas...\")\n",
        "\n",
        "# 1. Juntamos as transações com os dados dos produtos\n",
        "# A conexão é feita usando 'internal_product_id' e 'produto' como chaves.\n",
        "df_merged = pd.merge(\n",
        "    df_transactions, \n",
        "    df_products,\n",
        "    left_on='internal_product_id',\n",
        "    right_on='produto',\n",
        "    how='left'  # 'how=left' garante que todas as transações sejam mantidas.\n",
        ")\n",
        "\n",
        "print(f\"Após juntar com produtos, a tabela tem {df_merged.shape[1]} colunas.\")\n",
        "\n",
        "\n",
        "# 2. Agora, juntamos o resultado anterior com os dados das lojas (PDV)\n",
        "# A conexão é feita usando 'internal_store_id' e 'pdv' como chaves.\n",
        "df_merged = pd.merge(\n",
        "    df_merged,\n",
        "    df_pdv,\n",
        "    left_on='internal_store_id',\n",
        "    right_on='pdv',\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "print(f\"Após juntar com as lojas, a tabela final tem {df_merged.shape[1]} colunas.\")\n",
        "\n",
        "\n",
        "# --- VERIFICAÇÃO ---\n",
        "print(\"\\\\nJunção concluída! Vamos verificar o resultado:\")\n",
        "\n",
        "# O número de linhas deve ser o mesmo da tabela de transações original\n",
        "print(f\"Shape da tabela original de transações: {df_transactions.shape}\")\n",
        "print(f\"Shape da tabela final combinada:      {df_merged.shape}\")\n",
        "\n",
        "# Verifique que a tabela agora tem colunas das 3 tabelas originais\n",
        "print(\"\\\\nExemplo da tabela combinada (note as colunas 'marca', 'categoria', 'premise', etc.):\")\n",
        "display(df_merged.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "fb944e4f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tipo de dado da coluna 'transaction_date':\n",
            "datetime64[ns]\n"
          ]
        }
      ],
      "source": [
        "# Vamos verificar o tipo de dado (dtype) da coluna transaction_date\n",
        "print(\"Tipo de dado da coluna 'transaction_date':\")\n",
        "print(df_merged['transaction_date'].dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "19a83415",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iniciando diagnóstico do dataframe 'df_merged'...\n",
            "==================================================\\n\n",
            "--- 1. Contagem de Valores Nulos por Coluna ---\n",
            "label            526953\n",
            "subcategoria      10312\n",
            "pdv               45582\n",
            "premise           45582\n",
            "categoria_pdv     45582\n",
            "zipcode           45582\n",
            "dtype: int64\n",
            "\\n\n",
            "--- 2. Informações Gerais e Tipos de Dados ---\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6560698 entries, 0 to 6560697\n",
            "Data columns (total 28 columns):\n",
            " #   Column               Dtype         \n",
            "---  ------               -----         \n",
            " 0   internal_store_id    object        \n",
            " 1   internal_product_id  object        \n",
            " 2   distributor_id       object        \n",
            " 3   transaction_date     datetime64[ns]\n",
            " 4   reference_date       datetime64[ns]\n",
            " 5   quantity             float64       \n",
            " 6   gross_value          float64       \n",
            " 7   net_value            float64       \n",
            " 8   gross_profit         float64       \n",
            " 9   discount             float64       \n",
            " 10  taxes                float64       \n",
            " 11  year                 int32         \n",
            " 12  month                int32         \n",
            " 13  day                  int32         \n",
            " 14  weekday              object        \n",
            " 15  week                 UInt32        \n",
            " 16  produto              object        \n",
            " 17  categoria            object        \n",
            " 18  descricao            object        \n",
            " 19  tipos                object        \n",
            " 20  label                object        \n",
            " 21  subcategoria         object        \n",
            " 22  marca                object        \n",
            " 23  fabricante           object        \n",
            " 24  pdv                  object        \n",
            " 25  premise              object        \n",
            " 26  categoria_pdv        object        \n",
            " 27  zipcode              float64       \n",
            "dtypes: UInt32(1), datetime64[ns](2), float64(7), int32(3), object(15)\n",
            "memory usage: 1.3+ GB\n",
            "\\n\n",
            "--- 3. Resumo Estatístico das Colunas Numéricas ---\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>quantity</th>\n",
              "      <th>gross_value</th>\n",
              "      <th>net_value</th>\n",
              "      <th>gross_profit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>6.560698e+06</td>\n",
              "      <td>6.560698e+06</td>\n",
              "      <td>6.560698e+06</td>\n",
              "      <td>6.560698e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>8.125893e+00</td>\n",
              "      <td>1.227512e+02</td>\n",
              "      <td>1.191233e+02</td>\n",
              "      <td>2.193092e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>8.049387e+01</td>\n",
              "      <td>8.664265e+02</td>\n",
              "      <td>8.651757e+02</td>\n",
              "      <td>2.326470e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-1.530000e+03</td>\n",
              "      <td>-4.267290e+04</td>\n",
              "      <td>-3.984800e+04</td>\n",
              "      <td>-2.743960e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>2.803500e+01</td>\n",
              "      <td>2.711032e+01</td>\n",
              "      <td>7.140242e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>4.210000e+01</td>\n",
              "      <td>4.077048e+01</td>\n",
              "      <td>1.051024e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>4.000000e+00</td>\n",
              "      <td>9.200000e+01</td>\n",
              "      <td>8.787900e+01</td>\n",
              "      <td>2.173200e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>9.423000e+04</td>\n",
              "      <td>6.041739e+05</td>\n",
              "      <td>6.041739e+05</td>\n",
              "      <td>2.744160e+05</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           quantity   gross_value     net_value  gross_profit\n",
              "count  6.560698e+06  6.560698e+06  6.560698e+06  6.560698e+06\n",
              "mean   8.125893e+00  1.227512e+02  1.191233e+02  2.193092e+01\n",
              "std    8.049387e+01  8.664265e+02  8.651757e+02  2.326470e+02\n",
              "min   -1.530000e+03 -4.267290e+04 -3.984800e+04 -2.743960e+05\n",
              "25%    1.000000e+00  2.803500e+01  2.711032e+01  7.140242e+00\n",
              "50%    2.000000e+00  4.210000e+01  4.077048e+01  1.051024e+01\n",
              "75%    4.000000e+00  9.200000e+01  8.787900e+01  2.173200e+01\n",
              "max    9.423000e+04  6.041739e+05  6.041739e+05  2.744160e+05"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# --- PASSO DE DIAGNÓSTICO: INVESTIGAR A SAÚDE DOS DADOS ---\n",
        "\n",
        "print(\"Iniciando diagnóstico do dataframe 'df_merged'...\")\n",
        "print(\"=\"*50 + \"\\\\n\")\n",
        "\n",
        "\n",
        "# --- Diagnóstico 1: Valores Nulos (Buracos nos dados) ---\n",
        "# Vamos contar quantos valores nulos (NaN) existem em cada coluna.\n",
        "print(\"--- 1. Contagem de Valores Nulos por Coluna ---\")\n",
        "missing_values = df_merged.isnull().sum()\n",
        "print(missing_values[missing_values > 0]) # Mostra apenas as colunas que TÊM valores nulos\n",
        "print(\"\\\\n\")\n",
        "\n",
        "\n",
        "# --- Diagnóstico 2: Tipos de Dados ---\n",
        "# Vamos verificar se o pandas entendeu cada coluna corretamente (ex: data é data, número é número).\n",
        "print(\"--- 2. Informações Gerais e Tipos de Dados ---\")\n",
        "# O .info() nos dá um resumo completo, incluindo o tipo (Dtype) e a contagem de valores não-nulos.\n",
        "df_merged.info()\n",
        "print(\"\\\\n\")\n",
        "\n",
        "\n",
        "# --- Diagnóstico 3: Estatísticas de Colunas Numéricas ---\n",
        "# Vamos olhar um resumo estatístico das colunas com números.\n",
        "# Isso ajuda a encontrar coisas estranhas, como valores negativos ou absurdamente altos.\n",
        "print(\"--- 3. Resumo Estatístico das Colunas Numéricas ---\")\n",
        "# O .describe() mostra contagem, média, desvio padrão, mínimo, máximo, etc.\n",
        "display(df_merged[['quantity', 'gross_value', 'net_value', 'gross_profit']].describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "9ee92c55",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iniciando diagnóstico preciso do dataframe 'df_merged'...\n",
            "==================================================\\n\n",
            "--- 4. Verificação de Linhas Duplicadas ---\n",
            "Número de linhas completamente duplicadas encontradas: 0\n",
            "\\n\n",
            "--- 5. Análise de Conteúdo (Valores Mais Comuns) ---\n",
            "\\n--- Categoria do Produto ('categoria') ---\n",
            "categoria\n",
            "Package              4625080\n",
            "Non-Alcohol           955097\n",
            "Distilled Spirits     611285\n",
            "Draft                 192300\n",
            "Wine                  124232\n",
            "ABA Spirits            52274\n",
            "Tobacco                  430\n",
            "Name: count, dtype: int64\n",
            "------------------------------\n",
            "\\n--- Tipo de Loja ('premise') ---\n",
            "premise\n",
            "Off Premise    5823678\n",
            "On Premise      691438\n",
            "NaN              45582\n",
            "Name: count, dtype: int64\n",
            "------------------------------\n",
            "\\n--- Categoria da Loja ('categoria_pdv') ---\n",
            "categoria_pdv\n",
            "Convenience         2126380\n",
            "Package/Liquor      2016477\n",
            "Grocery             1276042\n",
            "Super Center         365825\n",
            "Restaurant           261861\n",
            "Bar                  192643\n",
            "NaN                   45582\n",
            "Mexican Rest          43712\n",
            "Hotel/Motel           20827\n",
            "Golf - Public         19807\n",
            "Drug                  19159\n",
            "Service Org           17230\n",
            "Pizza                 14995\n",
            "Billiard/Bowling      14239\n",
            "Golf - Private        13713\n",
            "Name: count, dtype: int64\n",
            "------------------------------\n"
          ]
        }
      ],
      "source": [
        "# --- DIAGNÓSTICO MAIS PRECISO ---\n",
        "\n",
        "print(\"Iniciando diagnóstico preciso do dataframe 'df_merged'...\")\n",
        "print(\"=\"*50 + \"\\\\n\")\n",
        "\n",
        "\n",
        "# --- Diagnóstico 4: Análise de Linhas Duplicadas ---\n",
        "# Linhas 100% idênticas podem indicar erros de registro e inflar os dados.\n",
        "print(\"--- 4. Verificação de Linhas Duplicadas ---\")\n",
        "num_duplicatas = df_merged.duplicated().sum()\n",
        "print(f\"Número de linhas completamente duplicadas encontradas: {num_duplicatas:,}\")\n",
        "if num_duplicatas > 0:\n",
        "    # Mostra um exemplo das linhas que são duplicadas\n",
        "    print(\"\\\\nExemplo de linhas duplicadas:\")\n",
        "    display(df_merged[df_merged.duplicated(keep=False)].sort_values(by=list(df_merged.columns)).head(10))\n",
        "print(\"\\\\n\")\n",
        "\n",
        "\n",
        "# --- Diagnóstico 5: Análise de Conteúdo das Colunas de Texto ---\n",
        "# O comando .value_counts() é excelente para isso. Ele conta quantas vezes cada valor aparece.\n",
        "# O `dropna=False` nos ajuda a contar os valores nulos (NaN) também.\n",
        "\n",
        "print(\"--- 5. Análise de Conteúdo (Valores Mais Comuns) ---\")\n",
        "\n",
        "print(\"\\\\n--- Categoria do Produto ('categoria') ---\")\n",
        "print(df_merged['categoria'].value_counts(dropna=False).head(10))\n",
        "print(\"-\" * 30)\n",
        "\n",
        "print(\"\\\\n--- Tipo de Loja ('premise') ---\")\n",
        "print(df_merged['premise'].value_counts(dropna=False).head(10))\n",
        "print(\"-\" * 30)\n",
        "\n",
        "print(\"\\\\n--- Categoria da Loja ('categoria_pdv') ---\")\n",
        "print(df_merged['categoria_pdv'].value_counts(dropna=False).head(15)) # Mostrando 15 para ter mais detalhes\n",
        "print(\"-\" * 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "f1200f9d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vamos investigar todos os tipos de loja existentes.\n",
            "No total, encontramos 54 tipos diferentes de lojas.\\n\n",
            "Abaixo está a lista completa de todas as categorias de loja e o número de transações em cada uma:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "categoria_pdv\n",
              "Convenience                  2126380\n",
              "Package/Liquor               2016477\n",
              "Grocery                      1276042\n",
              "Super Center                  365825\n",
              "Restaurant                    261861\n",
              "Bar                           192643\n",
              "NaN                            45582\n",
              "Mexican Rest                   43712\n",
              "Hotel/Motel                    20827\n",
              "Golf - Public                  19807\n",
              "Drug                           19159\n",
              "Service Org                    17230\n",
              "Pizza                          14995\n",
              "Billiard/Bowling               14239\n",
              "Golf - Private                 13713\n",
              "Sports/Rec Club                11223\n",
              "Italian                         9659\n",
              "Irish                           9213\n",
              "Asian                           7922\n",
              "Other On Premise                7026\n",
              "Stadium/Concession              7021\n",
              "Bodega                          5284\n",
              "Barbeque                        4932\n",
              "Club Store                      4798\n",
              "Military                        4724\n",
              "Church                          4696\n",
              "Airline/Airport                 3699\n",
              "Sample Room                     3358\n",
              "Other Off Premise               3272\n",
              "Night Club                      2993\n",
              "Music Venue                     2877\n",
              "Special Event                   2805\n",
              "Theatre                         2741\n",
              "Adult Entertainment             2623\n",
              "Gay Bar                         2084\n",
              "Banquet/Caterer                 1764\n",
              "Coffee House                    1128\n",
              "All Other N/A On Premise         920\n",
              "Neighborhood Store               876\n",
              "Theme Park                       803\n",
              "All Other N/A Off Premise        683\n",
              "Korean                           632\n",
              "Country/Western                  504\n",
              "Winery                           485\n",
              "French                           351\n",
              "Health Club                      266\n",
              "Race Track                       221\n",
              "Gym/Fitness                      201\n",
              "Sub Distributor                  138\n",
              "Marina / Lake                    121\n",
              "Salon/Spa/Tann                   111\n",
              "Non-Traditional                   18\n",
              "German                            16\n",
              "Casino                            16\n",
              "Mass Merch                         2\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# --- Análise Completa da Coluna 'categoria_pdv' ---\n",
        "\n",
        "print(\"Vamos investigar todos os tipos de loja existentes.\")\n",
        "\n",
        "# 1. Contar quantos tipos únicos de loja (PDV) existem no total\n",
        "num_categorias_loja = df_merged['categoria_pdv'].nunique()\n",
        "print(f\"No total, encontramos {num_categorias_loja} tipos diferentes de lojas.\\\\n\")\n",
        "\n",
        "# 2. Mostrar a contagem para CADA tipo de loja, ordenado do mais comum para o menos comum\n",
        "print(\"Abaixo está a lista completa de todas as categorias de loja e o número de transações em cada uma:\")\n",
        "# O display() do jupyter notebook formata a saída de forma mais legível\n",
        "display(df_merged['categoria_pdv'].value_counts(dropna=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "a834d0d3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iniciando a limpeza com a regra customizada para 'premise'...\n",
            "1. Linhas com quantidade inválida e fora de 2022 removidas.\n",
            "2. Nulos em outras colunas de texto preenchidos.\n",
            "3. Aplicando a regra para deduzir 'premise' a partir de 'categoria_pdv'...\n",
            "4. Lógica de dedução para 'premise' aplicada com sucesso!\n",
            "\\nLimpeza e dedução de 'premise' concluídas!\n",
            "\\nContagem de valores na coluna 'premise' ANTES da nossa regra (no df_merged):\n",
            "premise\n",
            "Off Premise    5823678\n",
            "On Premise      691438\n",
            "NaN              45582\n",
            "Name: count, dtype: int64\n",
            "\\nContagem de valores na coluna 'premise' DEPOIS da nossa regra (no df_clean):\n",
            "premise\n",
            "Off Premise    5739410\n",
            "On Premise      684470\n",
            "Unknown           6281\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# --- PASSO 2: LIMPEZA (VERSÃO AVANÇADA COM REGRA PARA 'PREMISE') ---\n",
        "\n",
        "print(\"Iniciando a limpeza com a regra customizada para 'premise'...\")\n",
        "\n",
        "df_clean = df_merged.copy()\n",
        "\n",
        "# Ações preliminares que já tínhamos definido:\n",
        "df_clean = df_clean[df_clean['quantity'] > 0]\n",
        "df_clean = df_clean[df_clean['transaction_date'].dt.year == 2022]\n",
        "print(\"1. Linhas com quantidade inválida e fora de 2022 removidas.\")\n",
        "\n",
        "# Preenche nulos nas outras colunas, mas DEIXA 'premise' em paz por enquanto\n",
        "for col in ['categoria', 'marca', 'categoria_pdv']:\n",
        "    if col in df_clean.columns:\n",
        "        df_clean[col] = df_clean[col].fillna('Unknown')\n",
        "print(\"2. Nulos em outras colunas de texto preenchidos.\")\n",
        "\n",
        "\n",
        "# Ação principal: Implementar a regra para preencher 'premise'\n",
        "print(\"3. Aplicando a regra para deduzir 'premise' a partir de 'categoria_pdv'...\")\n",
        "\n",
        "# Listas de mapeamento baseadas na nossa análise\n",
        "on_premise_categorias = [\n",
        "    'Restaurant', 'Bar', 'Mexican Rest', 'Hotel/Motel', 'Golf - Public', 'Pizza', \n",
        "    'Billiard/Bowling', 'Golf - Private', 'Sports/Rec Club', 'Italian', 'Irish', \n",
        "    'Asian', 'Stadium/Concession', 'Barbeque', 'German', 'Casino', 'Other On Premise'\n",
        "]\n",
        "off_premise_categorias = [\n",
        "    'Convenience', 'Package/Liquor', 'Grocery', 'Super Center', 'Drug', \n",
        "    'Club Store', 'Bodega', 'Mass Merch'\n",
        "]\n",
        "\n",
        "# Função que contém a nossa lógica\n",
        "def deduzir_premise(row):\n",
        "    # Se 'premise' já tem um valor e não é nulo, mantém ele.\n",
        "    if pd.notna(row['premise']):\n",
        "        return row['premise']\n",
        "    \n",
        "    # Se 'premise' for nulo, tentamos deduzir...\n",
        "    if row['categoria_pdv'] in on_premise_categorias:\n",
        "        return 'On Premise'\n",
        "    elif row['categoria_pdv'] in off_premise_categorias:\n",
        "        return 'Off Premise'\n",
        "    \n",
        "    # Se a categoria da loja também for desconhecida ou não estiver no nosso mapa,\n",
        "    # então não conseguimos deduzir.\n",
        "    else:\n",
        "        return 'Unknown'\n",
        "\n",
        "# O comando .apply executa nossa função em cada linha do dataframe.\n",
        "# O resultado será salvo na própria coluna 'premise'.\n",
        "df_clean['premise'] = df_clean.apply(deduzir_premise, axis=1)\n",
        "print(\"4. Lógica de dedução para 'premise' aplicada com sucesso!\")\n",
        "\n",
        "\n",
        "# --- VERIFICAÇÃO ---\n",
        "print(\"\\\\nLimpeza e dedução de 'premise' concluídas!\")\n",
        "\n",
        "print(\"\\\\nContagem de valores na coluna 'premise' ANTES da nossa regra (no df_merged):\")\n",
        "print(df_merged['premise'].value_counts(dropna=False))\n",
        "\n",
        "print(\"\\\\nContagem de valores na coluna 'premise' DEPOIS da nossa regra (no df_clean):\")\n",
        "print(df_clean['premise'].value_counts(dropna=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "4bd6e12d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Instalando/Verificando a biblioteca pgeocode...\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Preparando para mapear CEPs para estado e cidade...\n",
            "Mapeando...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\danie\\AppData\\Local\\Temp\\ipykernel_27404\\3386771597.py:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_clean['state'].fillna('Unknown', inplace=True)\n",
            "C:\\Users\\danie\\AppData\\Local\\Temp\\ipykernel_27404\\3386771597.py:28: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_clean['city'].fillna('Unknown', inplace=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\\nMAPEAMENTO CONCLUÍDO!\n",
            "Colunas 'state' e 'city' criadas.\n"
          ]
        }
      ],
      "source": [
        "# --- PASSO 3 (VERSÃO FINAL): CRIAR FEATURES DE ESTADO E CIDADE ---\n",
        "\n",
        "print(\"Instalando/Verificando a biblioteca pgeocode...\")\n",
        "%pip install pgeocode -q\n",
        "\n",
        "import pgeocode\n",
        "import pandas as pd\n",
        "\n",
        "print(\"Preparando para mapear CEPs para estado e cidade...\")\n",
        "nomi = pgeocode.Nominatim('us')\n",
        "df_clean['zipcode_str'] = df_clean['zipcode'].astype(str).str.slice(0, 5)\n",
        "\n",
        "print(\"Mapeando...\")\n",
        "zip_codes = df_clean['zipcode_str'].unique()\n",
        "state_info = nomi.query_postal_code(zip_codes)\n",
        "\n",
        "# Dicionário para mapear CEP -> Estado\n",
        "zip_to_state = pd.Series(state_info.state_code.values, index=state_info.postal_code).to_dict()\n",
        "# Dicionário para mapear CEP -> Cidade\n",
        "zip_to_city = pd.Series(state_info.place_name.values, index=state_info.postal_code).to_dict()\n",
        "\n",
        "# Mapear as novas colunas\n",
        "df_clean['state'] = df_clean['zipcode_str'].map(zip_to_state)\n",
        "df_clean['city'] = df_clean['zipcode_str'].map(zip_to_city)\n",
        "\n",
        "# Preencher o que não foi encontrado\n",
        "df_clean['state'].fillna('Unknown', inplace=True)\n",
        "df_clean['city'].fillna('Unknown', inplace=True)\n",
        "\n",
        "print(\"\\\\nMAPEAMENTO CONCLUÍDO!\")\n",
        "print(\"Colunas 'state' e 'city' criadas.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "d0a21575",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filtrando o dataframe para mostrar apenas as linhas onde o estado é 'Unknown'...\n",
            "Encontramos 21 CEPs únicos que não foram mapeados.\\n\n",
            "Abaixo estão os valores únicos da coluna ORIGINAL 'zipcode' que falharam:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([   nan, 30136., 30221., 30211., 30155., 30640., 30245., 30202.,\n",
              "       30201., 30020., 30190., 80039., 90920., 90132.,  8107., 80328.,\n",
              "       80147., 31972., 81153., 80029., 90919.])"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\\nE aqui estão esses mesmos valores depois da nossa limpeza para 5 dígitos ('zipcode_str'):\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array(['nan', '30136', '30221', '30211', '30155', '30640', '30245',\n",
              "       '30202', '30201', '30020', '30190', '80039', '90920', '90132',\n",
              "       '8107.', '80328', '80147', '31972', '81153', '80029', '90919'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# --- Investigando os CEPs não encontrados ---\n",
        "\n",
        "print(\"Filtrando o dataframe para mostrar apenas as linhas onde o estado é 'Unknown'...\")\n",
        "\n",
        "# Cria um novo dataframe apenas com as linhas problemáticas\n",
        "ceps_problematicos_df = df_clean[df_clean['state'] == 'Unknown']\n",
        "\n",
        "print(f\"Encontramos {len(ceps_problematicos_df['zipcode'].unique())} CEPs únicos que não foram mapeados.\\\\n\")\n",
        "\n",
        "print(\"Abaixo estão os valores únicos da coluna ORIGINAL 'zipcode' que falharam:\")\n",
        "# O .unique() nos mostra todos os valores diferentes que existem na coluna\n",
        "display(ceps_problematicos_df['zipcode'].unique())\n",
        "\n",
        "print(\"\\\\nE aqui estão esses mesmos valores depois da nossa limpeza para 5 dígitos ('zipcode_str'):\")\n",
        "display(ceps_problematicos_df['zipcode_str'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "020d548b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- PASSO 3.1: CORREÇÃO MANUAL DE ESTADO E CIDADE ---\n",
        "print(\"Aplicando correção manual para estado e cidade...\")\n",
        "\n",
        "correction_map = {\n",
        "    '30221': {'state': 'GA', 'city': 'Grayson'},\n",
        "    '30211': {'state': 'GA', 'city': 'Dacula'},\n",
        "    '30245': {'state': 'GA', 'city': 'Lawrenceville'},\n",
        "    '30020': {'state': 'GA', 'city': 'Clarkdale'},\n",
        "    '90132': {'state': 'CA', 'city': 'Los Angeles'},\n",
        "    '80328': {'state': 'CO', 'city': 'Boulder'},\n",
        "    '81153': {'state': 'CO', 'city': 'San Pablo'}\n",
        "}\n",
        "\n",
        "def corrigir_local(row):\n",
        "    if row['zipcode_str'] in correction_map:\n",
        "        # Pega os dados do nosso mapa de correção\n",
        "        info = correction_map[row['zipcode_str']]\n",
        "        row['state'] = info.get('state', 'Unknown')\n",
        "        row['city'] = info.get('city', 'Unknown')\n",
        "    return row\n",
        "\n",
        "df_clean = df_clean.apply(corrigir_local, axis=1)\n",
        "\n",
        "print(\"Correção manual concluída!\")\n",
        "print(\"\\\\nContagem de 'Unknown' em 'state' após correção:\")\n",
        "print(df_clean['state'].value_counts().get('Unknown', 0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "2acfb567",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Aplicando correção manual para estado e cidade...\n",
            "Número de 'Unknowns' antes da correção: 24165\n",
            "\\nCorreção manual concluída!\n",
            "Número de 'Unknowns' DEPOIS da correção: 17592\n",
            "\\nExemplo de uma das correções feitas:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>zipcode_str</th>\n",
              "      <th>state</th>\n",
              "      <th>city</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3650</th>\n",
              "      <td>30221</td>\n",
              "      <td>GA</td>\n",
              "      <td>Grayson</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     zipcode_str state     city\n",
              "3650       30221    GA  Grayson"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# --- PASSO 3.1 (VERSÃO REVISADA E CORRIGIDA) ---\n",
        "\n",
        "print(\"Aplicando correção manual para estado e cidade...\")\n",
        "\n",
        "# 1. Dicionário de correção (com a chave 'state' corrigida para 81153)\n",
        "correction_map = {\n",
        "    '30221': {'state': 'GA', 'city': 'Grayson'},\n",
        "    '30211': {'state': 'GA', 'city': 'Dacula'},\n",
        "    '30245': {'state': 'GA', 'city': 'Lawrenceville'},\n",
        "    '30020': {'state': 'GA', 'city': 'Clarkdale'},\n",
        "    '90132': {'state': 'CA', 'city': 'Los Angeles'},\n",
        "    '80328': {'state': 'CO', 'city': 'Boulder'},\n",
        "    '81153': {'state': 'CO', 'city': 'San Pablo'}  # Erro corrigido aqui\n",
        "}\n",
        "\n",
        "# 2. Contar 'Unknowns' ANTES da correção para podermos comparar\n",
        "unknowns_antes = df_clean['state'].value_counts().get('Unknown', 0)\n",
        "print(f\"Número de 'Unknowns' antes da correção: {unknowns_antes}\")\n",
        "\n",
        "# 3. Iterar pelo mapa e aplicar as correções de forma segura usando .loc\n",
        "# .loc é uma forma eficiente de selecionar e alterar dados específicos\n",
        "for zip_code, info in correction_map.items():\n",
        "    # Criamos uma \"máscara\" para encontrar as linhas exatas que queremos alterar:\n",
        "    # Onde o CEP é o que queremos corrigir E o estado atual é 'Unknown'\n",
        "    mask = (df_clean['zipcode_str'] == zip_code) & (df_clean['state'] == 'Unknown')\n",
        "    \n",
        "    # Usamos a máscara para atualizar 'state' e 'city' apenas nessas linhas\n",
        "    df_clean.loc[mask, 'state'] = info['state']\n",
        "    df_clean.loc[mask, 'city'] = info['city']\n",
        "\n",
        "# --- VERIFICAÇÃO ---\n",
        "print(\"\\\\nCorreção manual concluída!\")\n",
        "unknowns_depois = df_clean['state'].value_counts().get('Unknown', 0)\n",
        "print(f\"Número de 'Unknowns' DEPOIS da correção: {unknowns_depois}\")\n",
        "\n",
        "# Verificando se a cidade também foi preenchida\n",
        "print(\"\\\\nExemplo de uma das correções feitas:\")\n",
        "display(df_clean[df_clean['zipcode_str'] == '30221'][['zipcode_str', 'state', 'city']].head(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "a1ec5604",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iniciando agregação de dados por semana (incluindo estado e cidade)...\n",
            "\\nAgregação concluída! De 6,430,161 transações, criamos 6,140,206 linhas de dados semanais.\n",
            "Cada linha agora representa o total vendido de um produto em uma loja/cidade em uma semana.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>week</th>\n",
              "      <th>internal_store_id</th>\n",
              "      <th>internal_product_id</th>\n",
              "      <th>categoria</th>\n",
              "      <th>marca</th>\n",
              "      <th>premise</th>\n",
              "      <th>categoria_pdv</th>\n",
              "      <th>state</th>\n",
              "      <th>city</th>\n",
              "      <th>total_quantity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1001371918471115422</td>\n",
              "      <td>1029370090212151375</td>\n",
              "      <td>Package</td>\n",
              "      <td>Michelob Ultra</td>\n",
              "      <td>Off Premise</td>\n",
              "      <td>Convenience</td>\n",
              "      <td>GA</td>\n",
              "      <td>Talking Rock</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1001371918471115422</td>\n",
              "      <td>1120490062981954254</td>\n",
              "      <td>Package</td>\n",
              "      <td>Bud Light</td>\n",
              "      <td>Off Premise</td>\n",
              "      <td>Convenience</td>\n",
              "      <td>GA</td>\n",
              "      <td>Talking Rock</td>\n",
              "      <td>18.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1001371918471115422</td>\n",
              "      <td>2239307647969388381</td>\n",
              "      <td>Package</td>\n",
              "      <td>Natural Light</td>\n",
              "      <td>Off Premise</td>\n",
              "      <td>Convenience</td>\n",
              "      <td>GA</td>\n",
              "      <td>Talking Rock</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1001371918471115422</td>\n",
              "      <td>4353552881410365573</td>\n",
              "      <td>Package</td>\n",
              "      <td>Natural Light</td>\n",
              "      <td>Off Premise</td>\n",
              "      <td>Convenience</td>\n",
              "      <td>GA</td>\n",
              "      <td>Talking Rock</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1001371918471115422</td>\n",
              "      <td>4797439216678436447</td>\n",
              "      <td>Package</td>\n",
              "      <td>Bud Light Lime</td>\n",
              "      <td>Off Premise</td>\n",
              "      <td>Convenience</td>\n",
              "      <td>GA</td>\n",
              "      <td>Talking Rock</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   week    internal_store_id  internal_product_id categoria           marca  \\\n",
              "0     1  1001371918471115422  1029370090212151375   Package  Michelob Ultra   \n",
              "1     1  1001371918471115422  1120490062981954254   Package       Bud Light   \n",
              "2     1  1001371918471115422  2239307647969388381   Package   Natural Light   \n",
              "3     1  1001371918471115422  4353552881410365573   Package   Natural Light   \n",
              "4     1  1001371918471115422  4797439216678436447   Package  Bud Light Lime   \n",
              "\n",
              "       premise categoria_pdv state          city  total_quantity  \n",
              "0  Off Premise   Convenience    GA  Talking Rock             3.0  \n",
              "1  Off Premise   Convenience    GA  Talking Rock            18.0  \n",
              "2  Off Premise   Convenience    GA  Talking Rock             2.0  \n",
              "3  Off Premise   Convenience    GA  Talking Rock             7.0  \n",
              "4  Off Premise   Convenience    GA  Talking Rock             1.0  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# --- PASSO 4: AGREGAÇÃO SEMANAL COM CIDADE ---\n",
        "\n",
        "print(\"Iniciando agregação de dados por semana (incluindo estado e cidade)...\")\n",
        "\n",
        "# Cria a coluna 'week' para podermos agrupar por ela\n",
        "df_clean['week'] = df_clean['transaction_date'].dt.isocalendar().week\n",
        "\n",
        "# Define todas as colunas que queremos manter após o agrupamento.\n",
        "# Note que 'state' e 'city' estão na lista.\n",
        "grouping_keys = [\n",
        "    'week', \n",
        "    'internal_store_id', \n",
        "    'internal_product_id', \n",
        "    'categoria', \n",
        "    'marca', \n",
        "    'premise', \n",
        "    'categoria_pdv',\n",
        "    'state',\n",
        "    'city'\n",
        "]\n",
        "\n",
        "# Agrupa os dados usando as chaves definidas e soma a quantidade de vendas para cada grupo\n",
        "weekly_data = df_clean.groupby(grouping_keys).agg(\n",
        "    total_quantity=('quantity', 'sum')\n",
        ").reset_index()\n",
        "\n",
        "\n",
        "# --- VERIFICAÇÃO ---\n",
        "print(f\"\\\\nAgregação concluída! De {len(df_clean):,} transações, criamos {len(weekly_data):,} linhas de dados semanais.\")\n",
        "print(\"Cada linha agora representa o total vendido de um produto em uma loja/cidade em uma semana.\")\n",
        "display(weekly_data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "e19a0121",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Criando features de lag e média móvel no 'weekly_data'...\n",
            "\\nCriação de features concluída!\n",
            "Nosso dataset está 100% pronto para o treinamento do modelo.\n",
            "Note as novas colunas 'quantity_lag_...' e 'quantity_rolling_avg_...':\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>week</th>\n",
              "      <th>internal_store_id</th>\n",
              "      <th>internal_product_id</th>\n",
              "      <th>categoria</th>\n",
              "      <th>marca</th>\n",
              "      <th>premise</th>\n",
              "      <th>categoria_pdv</th>\n",
              "      <th>state</th>\n",
              "      <th>city</th>\n",
              "      <th>total_quantity</th>\n",
              "      <th>quantity_lag_1</th>\n",
              "      <th>quantity_lag_2</th>\n",
              "      <th>quantity_lag_3</th>\n",
              "      <th>quantity_lag_4</th>\n",
              "      <th>quantity_rolling_avg_2</th>\n",
              "      <th>quantity_rolling_avg_4</th>\n",
              "      <th>quantity_rolling_avg_8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>433888</th>\n",
              "      <td>6</td>\n",
              "      <td>1000237487041964405</td>\n",
              "      <td>1837429607327399565</td>\n",
              "      <td>Package</td>\n",
              "      <td>Fire Maker Perfect Match IPA</td>\n",
              "      <td>On Premise</td>\n",
              "      <td>Winery</td>\n",
              "      <td>GA</td>\n",
              "      <td>Talking Rock</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>529002</th>\n",
              "      <td>7</td>\n",
              "      <td>1000237487041964405</td>\n",
              "      <td>1837429607327399565</td>\n",
              "      <td>Package</td>\n",
              "      <td>Fire Maker Perfect Match IPA</td>\n",
              "      <td>On Premise</td>\n",
              "      <td>Winery</td>\n",
              "      <td>GA</td>\n",
              "      <td>Talking Rock</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2042472</th>\n",
              "      <td>21</td>\n",
              "      <td>1000237487041964405</td>\n",
              "      <td>1837429607327399565</td>\n",
              "      <td>Package</td>\n",
              "      <td>Fire Maker Perfect Match IPA</td>\n",
              "      <td>On Premise</td>\n",
              "      <td>Winery</td>\n",
              "      <td>GA</td>\n",
              "      <td>Talking Rock</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>1.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2521528</th>\n",
              "      <td>25</td>\n",
              "      <td>1000237487041964405</td>\n",
              "      <td>1837429607327399565</td>\n",
              "      <td>Package</td>\n",
              "      <td>Fire Maker Perfect Match IPA</td>\n",
              "      <td>On Premise</td>\n",
              "      <td>Winery</td>\n",
              "      <td>GA</td>\n",
              "      <td>Talking Rock</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1.333333</td>\n",
              "      <td>1.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2891177</th>\n",
              "      <td>28</td>\n",
              "      <td>1000237487041964405</td>\n",
              "      <td>1837429607327399565</td>\n",
              "      <td>Package</td>\n",
              "      <td>Fire Maker Perfect Match IPA</td>\n",
              "      <td>On Premise</td>\n",
              "      <td>Winery</td>\n",
              "      <td>GA</td>\n",
              "      <td>Talking Rock</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>1.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3599754</th>\n",
              "      <td>34</td>\n",
              "      <td>1000237487041964405</td>\n",
              "      <td>1837429607327399565</td>\n",
              "      <td>Package</td>\n",
              "      <td>Fire Maker Perfect Match IPA</td>\n",
              "      <td>On Premise</td>\n",
              "      <td>Winery</td>\n",
              "      <td>GA</td>\n",
              "      <td>Talking Rock</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.750000</td>\n",
              "      <td>1.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4481600</th>\n",
              "      <td>39</td>\n",
              "      <td>1000237487041964405</td>\n",
              "      <td>1837429607327399565</td>\n",
              "      <td>Package</td>\n",
              "      <td>Fire Maker Perfect Match IPA</td>\n",
              "      <td>On Premise</td>\n",
              "      <td>Winery</td>\n",
              "      <td>GA</td>\n",
              "      <td>Talking Rock</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.750000</td>\n",
              "      <td>1.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5321037</th>\n",
              "      <td>46</td>\n",
              "      <td>1000237487041964405</td>\n",
              "      <td>1837429607327399565</td>\n",
              "      <td>Package</td>\n",
              "      <td>Fire Maker Perfect Match IPA</td>\n",
              "      <td>On Premise</td>\n",
              "      <td>Winery</td>\n",
              "      <td>GA</td>\n",
              "      <td>Talking Rock</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1.750000</td>\n",
              "      <td>1.571429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1565795</th>\n",
              "      <td>17</td>\n",
              "      <td>1000237487041964405</td>\n",
              "      <td>4038588102284338370</td>\n",
              "      <td>Package</td>\n",
              "      <td>Jekyll Cooter Brown</td>\n",
              "      <td>On Premise</td>\n",
              "      <td>Winery</td>\n",
              "      <td>GA</td>\n",
              "      <td>Talking Rock</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.666667</td>\n",
              "      <td>1.571429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>433889</th>\n",
              "      <td>6</td>\n",
              "      <td>1000237487041964405</td>\n",
              "      <td>5429216175252037173</td>\n",
              "      <td>Package</td>\n",
              "      <td>Jekyll Southern Juice IPA</td>\n",
              "      <td>On Premise</td>\n",
              "      <td>Winery</td>\n",
              "      <td>GA</td>\n",
              "      <td>Talking Rock</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>1.666667</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         week    internal_store_id  internal_product_id categoria  \\\n",
              "433888      6  1000237487041964405  1837429607327399565   Package   \n",
              "529002      7  1000237487041964405  1837429607327399565   Package   \n",
              "2042472    21  1000237487041964405  1837429607327399565   Package   \n",
              "2521528    25  1000237487041964405  1837429607327399565   Package   \n",
              "2891177    28  1000237487041964405  1837429607327399565   Package   \n",
              "3599754    34  1000237487041964405  1837429607327399565   Package   \n",
              "4481600    39  1000237487041964405  1837429607327399565   Package   \n",
              "5321037    46  1000237487041964405  1837429607327399565   Package   \n",
              "1565795    17  1000237487041964405  4038588102284338370   Package   \n",
              "433889      6  1000237487041964405  5429216175252037173   Package   \n",
              "\n",
              "                                marca     premise categoria_pdv state  \\\n",
              "433888   Fire Maker Perfect Match IPA  On Premise        Winery    GA   \n",
              "529002   Fire Maker Perfect Match IPA  On Premise        Winery    GA   \n",
              "2042472  Fire Maker Perfect Match IPA  On Premise        Winery    GA   \n",
              "2521528  Fire Maker Perfect Match IPA  On Premise        Winery    GA   \n",
              "2891177  Fire Maker Perfect Match IPA  On Premise        Winery    GA   \n",
              "3599754  Fire Maker Perfect Match IPA  On Premise        Winery    GA   \n",
              "4481600  Fire Maker Perfect Match IPA  On Premise        Winery    GA   \n",
              "5321037  Fire Maker Perfect Match IPA  On Premise        Winery    GA   \n",
              "1565795           Jekyll Cooter Brown  On Premise        Winery    GA   \n",
              "433889      Jekyll Southern Juice IPA  On Premise        Winery    GA   \n",
              "\n",
              "                 city  total_quantity  quantity_lag_1  quantity_lag_2  \\\n",
              "433888   Talking Rock             1.0             0.0             0.0   \n",
              "529002   Talking Rock             2.0             1.0             0.0   \n",
              "2042472  Talking Rock             1.0             2.0             1.0   \n",
              "2521528  Talking Rock             2.0             1.0             2.0   \n",
              "2891177  Talking Rock             2.0             2.0             1.0   \n",
              "3599754  Talking Rock             2.0             2.0             2.0   \n",
              "4481600  Talking Rock             1.0             2.0             2.0   \n",
              "5321037  Talking Rock             2.0             1.0             2.0   \n",
              "1565795  Talking Rock             1.0             0.0             0.0   \n",
              "433889   Talking Rock             2.0             0.0             0.0   \n",
              "\n",
              "         quantity_lag_3  quantity_lag_4  quantity_rolling_avg_2  \\\n",
              "433888              0.0             0.0                     0.0   \n",
              "529002              0.0             0.0                     1.0   \n",
              "2042472             0.0             0.0                     1.5   \n",
              "2521528             1.0             0.0                     1.5   \n",
              "2891177             2.0             1.0                     1.5   \n",
              "3599754             1.0             2.0                     2.0   \n",
              "4481600             2.0             1.0                     2.0   \n",
              "5321037             2.0             2.0                     1.5   \n",
              "1565795             0.0             0.0                     1.0   \n",
              "433889              0.0             0.0                     0.0   \n",
              "\n",
              "         quantity_rolling_avg_4  quantity_rolling_avg_8  \n",
              "433888                 0.000000                0.000000  \n",
              "529002                 1.000000                1.000000  \n",
              "2042472                1.500000                1.500000  \n",
              "2521528                1.333333                1.333333  \n",
              "2891177                1.500000                1.500000  \n",
              "3599754                1.750000                1.600000  \n",
              "4481600                1.750000                1.666667  \n",
              "5321037                1.750000                1.571429  \n",
              "1565795                1.666667                1.571429  \n",
              "433889                 1.500000                1.666667  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# --- PASSO 5: CRIAÇÃO DE FEATURES DE SÉRIES TEMPORAIS ---\n",
        "\n",
        "print(\"Criando features de lag e média móvel no 'weekly_data'...\")\n",
        "\n",
        "# 1. Ordenar os dados é crucial para que a sequência de semanas esteja correta para cada produto\n",
        "weekly_data = weekly_data.sort_values(by=['internal_store_id', 'internal_product_id', 'week'])\n",
        "\n",
        "# 2. Criar \"Lag Features\": a venda da semana passada, retrasada, etc.\n",
        "# O groupby garante que o .shift() seja calculado para cada produto/loja separadamente, sem misturar os históricos.\n",
        "for lag in [1, 2, 3, 4]:\n",
        "    weekly_data[f'quantity_lag_{lag}'] = weekly_data.groupby(['internal_store_id', 'internal_product_id'])['total_quantity'].shift(lag)\n",
        "\n",
        "# 3. Criar \"Rolling Features\": a média de vendas das últimas semanas.\n",
        "# Isso ajuda a suavizar ruídos e capturar tendências. Usamos .shift(1) para não usar a venda da semana atual no cálculo da média do passado.\n",
        "for window in [2, 4, 8]:\n",
        "    weekly_data[f'quantity_rolling_avg_{window}'] = weekly_data.groupby(['internal_store_id', 'internal_product_id'])['total_quantity'].shift(1).rolling(window=window, min_periods=1).mean()\n",
        "\n",
        "# 4. Preencher os valores nulos (NaN) que foram criados com zero.\n",
        "# Isso acontece nas primeiras semanas do histórico de cada produto, onde não há dados passados para calcular lag/média.\n",
        "weekly_data.fillna(0, inplace=True)\n",
        "\n",
        "\n",
        "# --- VERIFICAÇÃO ---\n",
        "print(\"\\\\nCriação de features concluída!\")\n",
        "print(\"Nosso dataset está 100% pronto para o treinamento do modelo.\")\n",
        "print(\"Note as novas colunas 'quantity_lag_...' e 'quantity_rolling_avg_...':\")\n",
        "display(weekly_data.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "963d9082",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gerando a lista de todos os estados e cidades únicos no nosso conjunto de dados...\n",
            "======================================================================\n",
            "\\nEncontramos 4 estados únicos em nossos dados:\n",
            "['CA', 'CO', 'GA', 'Unknown']\n",
            "----------------------------------------------------------------------\n",
            "\\nEncontramos 500 cidades únicas.\n",
            "----------------------------------------------------------------------\n",
            "\\nPara referência, aqui estão as cidades que temos em cada estado:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "state\n",
              "CA                                             [Los Angeles]\n",
              "CO         [Grand Junction, Denver, Arvada, Longmont, Lit...\n",
              "GA         [Talking Rock, Atlanta, Brunswick, Canton, Alp...\n",
              "Unknown                                            [Unknown]\n",
              "Name: city, dtype: object"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# --- LISTANDO ESTADOS E CIDADES PRESENTES NOS DADOS ---\n",
        "\n",
        "print(\"Gerando a lista de todos os estados e cidades únicos no nosso conjunto de dados...\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# 1. Contar e listar os estados únicos\n",
        "# .unique() pega todos os valores diferentes e .tolist() transforma em uma lista python\n",
        "estados_unicos = sorted(weekly_data['state'].unique())\n",
        "print(f\"\\\\nEncontramos {len(estados_unicos)} estados únicos em nossos dados:\")\n",
        "print(estados_unicos)\n",
        "print(\"-\" * 70)\n",
        "\n",
        "# 2. Contar as cidades únicas\n",
        "cidades_unicas = weekly_data['city'].unique()\n",
        "print(f\"\\\\nEncontramos {len(cidades_unicas)} cidades únicas.\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "\n",
        "# 3. Mostrar as cidades agrupadas por estado (para melhor organização)\n",
        "print(\"\\\\nPara referência, aqui estão as cidades que temos em cada estado:\")\n",
        "cidades_por_estado = weekly_data.groupby('state')['city'].unique()\n",
        "# Usamos display para uma formatação mais amigável no notebook\n",
        "display(cidades_por_estado)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "205717bd",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Criando features de feriado com base na sua sugestão...\n",
            "\\nCriação das features de feriado concluída!\n",
            "Semanas marcadas como feriado: 1,360,715\n",
            "Semanas de feriado em locais On Premise: 183,862\n",
            "Semanas de feriado em locais Off Premise: 1,170,572\n",
            "\\nExemplo das novas colunas em uma semana de feriado (semana 3):\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>week</th>\n",
              "      <th>internal_store_id</th>\n",
              "      <th>internal_product_id</th>\n",
              "      <th>categoria</th>\n",
              "      <th>marca</th>\n",
              "      <th>premise</th>\n",
              "      <th>categoria_pdv</th>\n",
              "      <th>state</th>\n",
              "      <th>city</th>\n",
              "      <th>total_quantity</th>\n",
              "      <th>quantity_lag_1</th>\n",
              "      <th>quantity_lag_2</th>\n",
              "      <th>quantity_lag_3</th>\n",
              "      <th>quantity_lag_4</th>\n",
              "      <th>quantity_rolling_avg_2</th>\n",
              "      <th>quantity_rolling_avg_4</th>\n",
              "      <th>quantity_rolling_avg_8</th>\n",
              "      <th>is_holiday_week</th>\n",
              "      <th>holiday_on_premise</th>\n",
              "      <th>holiday_off_premise</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>158456</th>\n",
              "      <td>3</td>\n",
              "      <td>1001371918471115422</td>\n",
              "      <td>1120490062981954254</td>\n",
              "      <td>Package</td>\n",
              "      <td>Bud Light</td>\n",
              "      <td>Off Premise</td>\n",
              "      <td>Convenience</td>\n",
              "      <td>GA</td>\n",
              "      <td>Talking Rock</td>\n",
              "      <td>18.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>9.5</td>\n",
              "      <td>5.800000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>158457</th>\n",
              "      <td>3</td>\n",
              "      <td>1001371918471115422</td>\n",
              "      <td>1394381856358939027</td>\n",
              "      <td>Package</td>\n",
              "      <td>Budweiser</td>\n",
              "      <td>Off Premise</td>\n",
              "      <td>Convenience</td>\n",
              "      <td>GA</td>\n",
              "      <td>Talking Rock</td>\n",
              "      <td>13.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.571429</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>158458</th>\n",
              "      <td>3</td>\n",
              "      <td>1001371918471115422</td>\n",
              "      <td>2626864159264988174</td>\n",
              "      <td>Package</td>\n",
              "      <td>Bud Ice</td>\n",
              "      <td>Off Premise</td>\n",
              "      <td>Convenience</td>\n",
              "      <td>GA</td>\n",
              "      <td>Talking Rock</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>158459</th>\n",
              "      <td>3</td>\n",
              "      <td>1001371918471115422</td>\n",
              "      <td>4353552881410365573</td>\n",
              "      <td>Package</td>\n",
              "      <td>Natural Light</td>\n",
              "      <td>Off Premise</td>\n",
              "      <td>Convenience</td>\n",
              "      <td>GA</td>\n",
              "      <td>Talking Rock</td>\n",
              "      <td>4.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.200000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>158460</th>\n",
              "      <td>3</td>\n",
              "      <td>1001371918471115422</td>\n",
              "      <td>4974205226846185245</td>\n",
              "      <td>Package</td>\n",
              "      <td>Natural Ice</td>\n",
              "      <td>Off Premise</td>\n",
              "      <td>Convenience</td>\n",
              "      <td>GA</td>\n",
              "      <td>Talking Rock</td>\n",
              "      <td>3.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        week    internal_store_id  internal_product_id categoria  \\\n",
              "158456     3  1001371918471115422  1120490062981954254   Package   \n",
              "158457     3  1001371918471115422  1394381856358939027   Package   \n",
              "158458     3  1001371918471115422  2626864159264988174   Package   \n",
              "158459     3  1001371918471115422  4353552881410365573   Package   \n",
              "158460     3  1001371918471115422  4974205226846185245   Package   \n",
              "\n",
              "                marca      premise categoria_pdv state          city  \\\n",
              "158456      Bud Light  Off Premise   Convenience    GA  Talking Rock   \n",
              "158457      Budweiser  Off Premise   Convenience    GA  Talking Rock   \n",
              "158458        Bud Ice  Off Premise   Convenience    GA  Talking Rock   \n",
              "158459  Natural Light  Off Premise   Convenience    GA  Talking Rock   \n",
              "158460    Natural Ice  Off Premise   Convenience    GA  Talking Rock   \n",
              "\n",
              "        total_quantity  quantity_lag_1  quantity_lag_2  quantity_lag_3  \\\n",
              "158456            18.0            18.0             0.0             0.0   \n",
              "158457            13.0             0.0             0.0             0.0   \n",
              "158458             2.0             0.0             0.0             0.0   \n",
              "158459             4.0             7.0             0.0             0.0   \n",
              "158460             3.0             7.0             0.0             0.0   \n",
              "\n",
              "        quantity_lag_4  quantity_rolling_avg_2  quantity_rolling_avg_4  \\\n",
              "158456             0.0                    18.0                     9.5   \n",
              "158457             0.0                    10.0                    10.0   \n",
              "158458             0.0                     1.0                     4.0   \n",
              "158459             0.0                     7.0                     4.0   \n",
              "158460             0.0                     7.0                     3.0   \n",
              "\n",
              "        quantity_rolling_avg_8  is_holiday_week  holiday_on_premise  \\\n",
              "158456                5.800000                1                   0   \n",
              "158457               10.571429                1                   0   \n",
              "158458                5.000000                1                   0   \n",
              "158459                2.200000                1                   0   \n",
              "158460                2.000000                1                   0   \n",
              "\n",
              "        holiday_off_premise  \n",
              "158456                    1  \n",
              "158457                    1  \n",
              "158458                    1  \n",
              "158459                    1  \n",
              "158460                    1  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# --- PASSO 6: CRIAR FEATURES DE FERIADO E INTERAÇÃO ---\n",
        "\n",
        "print(\"Criando features de feriado com base na sua sugestão...\")\n",
        "import numpy as np\n",
        "\n",
        "# 1. Lista das semanas de 2022 que contêm feriados importantes nos EUA\n",
        "# (Ex: MLK Day, Memorial Day, 4th of July, Labor Day, Thanksgiving, Christmas)\n",
        "holiday_weeks = [3, 8, 22, 25, 27, 36, 41, 45, 47, 52]\n",
        "\n",
        "# 2. Criar uma feature binária simples para marcar se a semana tem feriado ou não\n",
        "# Usamos .isin() para verificar se o valor da coluna 'week' está na nossa lista\n",
        "weekly_data['is_holiday_week'] = weekly_data['week'].isin(holiday_weeks).astype(int)\n",
        "\n",
        "\n",
        "# 3. Criar as \"Features de Interação\" que você idealizou\n",
        "# Elas combinam a informação do feriado com o tipo de local (premise)\n",
        "# O modelo agora pode aprender pesos diferentes para cada uma dessas condições\n",
        "\n",
        "# Feature para feriado em locais On-Premise\n",
        "weekly_data['holiday_on_premise'] = np.where(\n",
        "    (weekly_data['is_holiday_week'] == 1) & (weekly_data['premise'] == 'On Premise'), 1, 0\n",
        ")\n",
        "\n",
        "# Feature para feriado em locais Off-Premise\n",
        "weekly_data['holiday_off_premise'] = np.where(\n",
        "    (weekly_data['is_holiday_week'] == 1) & (weekly_data['premise'] == 'Off Premise'), 1, 0\n",
        ")\n",
        "\n",
        "\n",
        "# --- VERIFICAÇÃO ---\n",
        "print(\"\\\\nCriação das features de feriado concluída!\")\n",
        "\n",
        "# Vamos verificar a contagem de cada nova feature\n",
        "print(f\"Semanas marcadas como feriado: {weekly_data['is_holiday_week'].sum():,}\")\n",
        "print(f\"Semanas de feriado em locais On Premise: {weekly_data['holiday_on_premise'].sum():,}\")\n",
        "print(f\"Semanas de feriado em locais Off Premise: {weekly_data['holiday_off_premise'].sum():,}\")\n",
        "\n",
        "# Mostra as novas colunas no dataframe\n",
        "print(\"\\\\nExemplo das novas colunas em uma semana de feriado (semana 3):\")\n",
        "display(weekly_data[weekly_data['week'] == 3].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "0bbc99a9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Criando features para feriados estaduais específicos (CA, CO, GA)...\n",
            "\\nCriação das features de feriados estaduais concluída!\n",
            "Semanas marcadas como feriado da Califórnia: 0\n",
            "Semanas marcadas como feriado do Colorado: 122,948\n",
            "Semanas marcadas como feriado da Geórgia: 88,852\n",
            "\\nExemplo de feriado da Geórgia (semana 15 ou 51):\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>week</th>\n",
              "      <th>internal_store_id</th>\n",
              "      <th>internal_product_id</th>\n",
              "      <th>categoria</th>\n",
              "      <th>marca</th>\n",
              "      <th>premise</th>\n",
              "      <th>categoria_pdv</th>\n",
              "      <th>state</th>\n",
              "      <th>city</th>\n",
              "      <th>total_quantity</th>\n",
              "      <th>...</th>\n",
              "      <th>quantity_lag_4</th>\n",
              "      <th>quantity_rolling_avg_2</th>\n",
              "      <th>quantity_rolling_avg_4</th>\n",
              "      <th>quantity_rolling_avg_8</th>\n",
              "      <th>is_holiday_week</th>\n",
              "      <th>holiday_on_premise</th>\n",
              "      <th>holiday_off_premise</th>\n",
              "      <th>is_holiday_ca</th>\n",
              "      <th>is_holiday_co</th>\n",
              "      <th>is_holiday_ga</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5915415</th>\n",
              "      <td>51</td>\n",
              "      <td>1001371918471115422</td>\n",
              "      <td>1009179103632945474</td>\n",
              "      <td>Package</td>\n",
              "      <td>Busch</td>\n",
              "      <td>Off Premise</td>\n",
              "      <td>Convenience</td>\n",
              "      <td>GA</td>\n",
              "      <td>Talking Rock</td>\n",
              "      <td>2.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1.25</td>\n",
              "      <td>1.125000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5915416</th>\n",
              "      <td>51</td>\n",
              "      <td>1001371918471115422</td>\n",
              "      <td>1120490062981954254</td>\n",
              "      <td>Package</td>\n",
              "      <td>Bud Light</td>\n",
              "      <td>Off Premise</td>\n",
              "      <td>Convenience</td>\n",
              "      <td>GA</td>\n",
              "      <td>Talking Rock</td>\n",
              "      <td>10.0</td>\n",
              "      <td>...</td>\n",
              "      <td>10.0</td>\n",
              "      <td>12.5</td>\n",
              "      <td>11.25</td>\n",
              "      <td>14.500000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1356600</th>\n",
              "      <td>15</td>\n",
              "      <td>1001371918471115422</td>\n",
              "      <td>1394381856358939027</td>\n",
              "      <td>Package</td>\n",
              "      <td>Budweiser</td>\n",
              "      <td>Off Premise</td>\n",
              "      <td>Convenience</td>\n",
              "      <td>GA</td>\n",
              "      <td>Talking Rock</td>\n",
              "      <td>13.0</td>\n",
              "      <td>...</td>\n",
              "      <td>20.0</td>\n",
              "      <td>12.5</td>\n",
              "      <td>15.25</td>\n",
              "      <td>13.857143</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5915417</th>\n",
              "      <td>51</td>\n",
              "      <td>1001371918471115422</td>\n",
              "      <td>1394381856358939027</td>\n",
              "      <td>Package</td>\n",
              "      <td>Budweiser</td>\n",
              "      <td>Off Premise</td>\n",
              "      <td>Convenience</td>\n",
              "      <td>GA</td>\n",
              "      <td>Talking Rock</td>\n",
              "      <td>13.0</td>\n",
              "      <td>...</td>\n",
              "      <td>9.0</td>\n",
              "      <td>19.5</td>\n",
              "      <td>14.50</td>\n",
              "      <td>13.250000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1356601</th>\n",
              "      <td>15</td>\n",
              "      <td>1001371918471115422</td>\n",
              "      <td>1454838625590783593</td>\n",
              "      <td>Package</td>\n",
              "      <td>Bud Ice</td>\n",
              "      <td>Off Premise</td>\n",
              "      <td>Convenience</td>\n",
              "      <td>GA</td>\n",
              "      <td>Talking Rock</td>\n",
              "      <td>3.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19.50</td>\n",
              "      <td>12.500000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 23 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         week    internal_store_id  internal_product_id categoria      marca  \\\n",
              "5915415    51  1001371918471115422  1009179103632945474   Package      Busch   \n",
              "5915416    51  1001371918471115422  1120490062981954254   Package  Bud Light   \n",
              "1356600    15  1001371918471115422  1394381856358939027   Package  Budweiser   \n",
              "5915417    51  1001371918471115422  1394381856358939027   Package  Budweiser   \n",
              "1356601    15  1001371918471115422  1454838625590783593   Package    Bud Ice   \n",
              "\n",
              "             premise categoria_pdv state          city  total_quantity  ...  \\\n",
              "5915415  Off Premise   Convenience    GA  Talking Rock             2.0  ...   \n",
              "5915416  Off Premise   Convenience    GA  Talking Rock            10.0  ...   \n",
              "1356600  Off Premise   Convenience    GA  Talking Rock            13.0  ...   \n",
              "5915417  Off Premise   Convenience    GA  Talking Rock            13.0  ...   \n",
              "1356601  Off Premise   Convenience    GA  Talking Rock             3.0  ...   \n",
              "\n",
              "         quantity_lag_4  quantity_rolling_avg_2  quantity_rolling_avg_4  \\\n",
              "5915415             1.0                     1.5                    1.25   \n",
              "5915416            10.0                    12.5                   11.25   \n",
              "1356600            20.0                    12.5                   15.25   \n",
              "5915417             9.0                    19.5                   14.50   \n",
              "1356601             0.0                     0.0                   19.50   \n",
              "\n",
              "         quantity_rolling_avg_8  is_holiday_week  holiday_on_premise  \\\n",
              "5915415                1.125000                0                   0   \n",
              "5915416               14.500000                0                   0   \n",
              "1356600               13.857143                0                   0   \n",
              "5915417               13.250000                0                   0   \n",
              "1356601               12.500000                0                   0   \n",
              "\n",
              "         holiday_off_premise  is_holiday_ca  is_holiday_co  is_holiday_ga  \n",
              "5915415                    0              0              0              1  \n",
              "5915416                    0              0              0              1  \n",
              "1356600                    0              0              0              1  \n",
              "5915417                    0              0              0              1  \n",
              "1356601                    0              0              0              1  \n",
              "\n",
              "[5 rows x 23 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# --- PASSO 7: CRIAR FEATURES DE FERIADOS ESTADUAIS ---\n",
        "\n",
        "print(\"Criando features para feriados estaduais específicos (CA, CO, GA)...\")\n",
        "import numpy as np\n",
        "\n",
        "# 1. Definir as semanas dos feriados únicos para cada estado, com base na nossa pesquisa\n",
        "# (Converti as datas dos feriados para o número da semana em 2022)\n",
        "ca_holiday_weeks = [13]  # Cesar Chavez Day\n",
        "co_holiday_weeks = [13, 40] # Cesar Chavez Day, Frances Xavier Cabrini Day\n",
        "ga_holiday_weeks = [15, 51] # Good Friday, State Holiday (Dec 23)\n",
        "\n",
        "# 2. Criar a feature para feriados da Califórnia (CA)\n",
        "weekly_data['is_holiday_ca'] = np.where(\n",
        "    (weekly_data['state'] == 'CA') & (weekly_data['week'].isin(ca_holiday_weeks)), 1, 0\n",
        ")\n",
        "\n",
        "# 3. Criar a feature para feriados do Colorado (CO)\n",
        "weekly_data['is_holiday_co'] = np.where(\n",
        "    (weekly_data['state'] == 'CO') & (weekly_data['week'].isin(co_holiday_weeks)), 1, 0\n",
        ")\n",
        "\n",
        "# 4. Criar a feature para feriados da Geórgia (GA)\n",
        "weekly_data['is_holiday_ga'] = np.where(\n",
        "    (weekly_data['state'] == 'GA') & (weekly_data['week'].isin(ga_holiday_weeks)), 1, 0\n",
        ")\n",
        "\n",
        "\n",
        "# --- VERIFICAÇÃO ---\n",
        "print(\"\\\\nCriação das features de feriados estaduais concluída!\")\n",
        "\n",
        "# Verificar se as colunas foram criadas e quantas marcações cada uma tem\n",
        "ca_count = weekly_data['is_holiday_ca'].sum()\n",
        "co_count = weekly_data['is_holiday_co'].sum()\n",
        "ga_count = weekly_data['is_holiday_ga'].sum()\n",
        "\n",
        "print(f\"Semanas marcadas como feriado da Califórnia: {ca_count:,}\")\n",
        "print(f\"Semanas marcadas como feriado do Colorado: {co_count:,}\")\n",
        "print(f\"Semanas marcadas como feriado da Geórgia: {ga_count:,}\")\n",
        "\n",
        "# Se houver marcações, mostrar um exemplo\n",
        "if ga_count > 0:\n",
        "    print(\"\\\\nExemplo de feriado da Geórgia (semana 15 ou 51):\")\n",
        "    display(weekly_data[weekly_data['is_holiday_ga'] == 1].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "1af26e13",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Investigando os dados da Califórnia e da semana 13...\n",
            "============================================================\n",
            "Número total de linhas de vendas semanais da Califórnia: 432\n",
            "Número total de linhas de vendas semanais da semana 13 (de todos os estados): 107,262\n",
            "\\nNúmero de linhas que são da Califórnia E da semana 13: 0\n",
            "\\nConclusão: Como suspeitado, não há registros de vendas em nosso dataset para a Califórnia durante a semana 13 de 2022.\n"
          ]
        }
      ],
      "source": [
        "# --- DIAGNÓSTICO: POR QUE O FERIADO DA CALIFÓRNIA NÃO APARECE? ---\n",
        "\n",
        "print(\"Investigando os dados da Califórnia e da semana 13...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# 1. Temos dados da Califórnia no geral?\n",
        "ca_total_rows = len(weekly_data[weekly_data['state'] == 'CA'])\n",
        "print(f\"Número total de linhas de vendas semanais da Califórnia: {ca_total_rows:,}\")\n",
        "\n",
        "# 2. Temos dados da semana 13 no geral?\n",
        "week_13_total_rows = len(weekly_data[weekly_data['week'] == 13])\n",
        "print(f\"Número total de linhas de vendas semanais da semana 13 (de todos os estados): {week_13_total_rows:,}\")\n",
        "\n",
        "# 3. A verificação final: Temos dados que são da CA E da semana 13 ao mesmo tempo?\n",
        "combinacao_df = weekly_data[(weekly_data['state'] == 'CA') & (weekly_data['week'] == 13)]\n",
        "num_combinacao = len(combinacao_df)\n",
        "print(f\"\\\\nNúmero de linhas que são da Califórnia E da semana 13: {num_combinacao}\")\n",
        "\n",
        "if num_combinacao == 0:\n",
        "    print(\"\\\\nConclusão: Como suspeitado, não há registros de vendas em nosso dataset para a Califórnia durante a semana 13 de 2022.\")\n",
        "else:\n",
        "    print(\"\\\\nConclusão: Encontramos dados para a CA na semana 13. Pode haver outro problema.\")\n",
        "    display(combinacao_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af2cad95",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A biblioteca 'scikit-learn' não foi encontrada. Instalando agora...\n",
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.7.2-cp313-cp313-win_amd64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\danie\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (2.3.2)\n",
            "Collecting scipy>=1.8.0 (from scikit-learn)\n",
            "  Downloading scipy-1.16.2-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
            "Collecting joblib>=1.2.0 (from scikit-learn)\n",
            "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
            "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
            "Downloading scikit_learn-1.7.2-cp313-cp313-win_amd64.whl (8.7 MB)\n",
            "   ---------------------------------------- 0.0/8.7 MB ? eta -:--:--\n",
            "   ---------------------------------------- 8.7/8.7 MB 62.3 MB/s  0:00:00\n",
            "Downloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
            "Downloading scipy-1.16.2-cp313-cp313-win_amd64.whl (38.5 MB)\n",
            "   ---------------------------------------- 0.0/38.5 MB ? eta -:--:--\n",
            "   --------------------- ------------------ 20.4/38.5 MB 97.6 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 34.6/38.5 MB 93.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 38.5/38.5 MB 62.4 MB/s  0:00:00\n",
            "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
            "\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   -------------------- ------------------- 2/4 [joblib]\n",
            "   -------------------- ------------------- 2/4 [joblib]\n",
            "   -------------------- ------------------- 2/4 [joblib]\n",
            "   -------------------- ------------------- 2/4 [joblib]\n",
            "   -------------------- ------------------- 2/4 [joblib]\n",
            "   -------------------- ------------------- 2/4 [joblib]\n",
            "   -------------------- ------------------- 2/4 [joblib]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ---------------------------------------- 4/4 [scikit-learn]\n",
            "\n",
            "Successfully installed joblib-1.5.2 scikit-learn-1.7.2 scipy-1.16.2 threadpoolctl-3.6.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "7839982e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iniciando a preparação dos dados para o treinamento...\n",
            "Colunas de texto convertidas para números.\n",
            "\\nDados prontos para o modelo!\n",
            "Nosso 'alvo' (y - o que queremos prever) tem 6,140,206 linhas.\n",
            "Nossas 'features' (X - as pistas) têm 6,140,206 linhas e 20 colunas.\n",
            "\\nExemplo das features (X) que o modelo vai usar:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>week</th>\n",
              "      <th>quantity_lag_1</th>\n",
              "      <th>quantity_lag_2</th>\n",
              "      <th>quantity_lag_3</th>\n",
              "      <th>quantity_lag_4</th>\n",
              "      <th>quantity_rolling_avg_2</th>\n",
              "      <th>quantity_rolling_avg_4</th>\n",
              "      <th>quantity_rolling_avg_8</th>\n",
              "      <th>is_holiday_week</th>\n",
              "      <th>holiday_on_premise</th>\n",
              "      <th>holiday_off_premise</th>\n",
              "      <th>is_holiday_ca</th>\n",
              "      <th>is_holiday_co</th>\n",
              "      <th>is_holiday_ga</th>\n",
              "      <th>categoria_encoded</th>\n",
              "      <th>marca_encoded</th>\n",
              "      <th>premise_encoded</th>\n",
              "      <th>categoria_pdv_encoded</th>\n",
              "      <th>state_encoded</th>\n",
              "      <th>city_encoded</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>433888</th>\n",
              "      <td>6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1449</td>\n",
              "      <td>1</td>\n",
              "      <td>54</td>\n",
              "      <td>2</td>\n",
              "      <td>442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>529002</th>\n",
              "      <td>7</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1449</td>\n",
              "      <td>1</td>\n",
              "      <td>54</td>\n",
              "      <td>2</td>\n",
              "      <td>442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2042472</th>\n",
              "      <td>21</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1449</td>\n",
              "      <td>1</td>\n",
              "      <td>54</td>\n",
              "      <td>2</td>\n",
              "      <td>442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2521528</th>\n",
              "      <td>25</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1.333333</td>\n",
              "      <td>1.333333</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1449</td>\n",
              "      <td>1</td>\n",
              "      <td>54</td>\n",
              "      <td>2</td>\n",
              "      <td>442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2891177</th>\n",
              "      <td>28</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1449</td>\n",
              "      <td>1</td>\n",
              "      <td>54</td>\n",
              "      <td>2</td>\n",
              "      <td>442</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         week  quantity_lag_1  quantity_lag_2  quantity_lag_3  quantity_lag_4  \\\n",
              "433888      6             0.0             0.0             0.0             0.0   \n",
              "529002      7             1.0             0.0             0.0             0.0   \n",
              "2042472    21             2.0             1.0             0.0             0.0   \n",
              "2521528    25             1.0             2.0             1.0             0.0   \n",
              "2891177    28             2.0             1.0             2.0             1.0   \n",
              "\n",
              "         quantity_rolling_avg_2  quantity_rolling_avg_4  \\\n",
              "433888                      0.0                0.000000   \n",
              "529002                      1.0                1.000000   \n",
              "2042472                     1.5                1.500000   \n",
              "2521528                     1.5                1.333333   \n",
              "2891177                     1.5                1.500000   \n",
              "\n",
              "         quantity_rolling_avg_8  is_holiday_week  holiday_on_premise  \\\n",
              "433888                 0.000000                0                   0   \n",
              "529002                 1.000000                0                   0   \n",
              "2042472                1.500000                0                   0   \n",
              "2521528                1.333333                1                   1   \n",
              "2891177                1.500000                0                   0   \n",
              "\n",
              "         holiday_off_premise  is_holiday_ca  is_holiday_co  is_holiday_ga  \\\n",
              "433888                     0              0              0              0   \n",
              "529002                     0              0              0              0   \n",
              "2042472                    0              0              0              0   \n",
              "2521528                    0              0              0              0   \n",
              "2891177                    0              0              0              0   \n",
              "\n",
              "         categoria_encoded  marca_encoded  premise_encoded  \\\n",
              "433888                   4           1449                1   \n",
              "529002                   4           1449                1   \n",
              "2042472                  4           1449                1   \n",
              "2521528                  4           1449                1   \n",
              "2891177                  4           1449                1   \n",
              "\n",
              "         categoria_pdv_encoded  state_encoded  city_encoded  \n",
              "433888                      54              2           442  \n",
              "529002                      54              2           442  \n",
              "2042472                     54              2           442  \n",
              "2521528                     54              2           442  \n",
              "2891177                     54              2           442  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# --- PASSO 8: PREPARAR DADOS PARA O MODELO ---\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "print(\"Iniciando a preparação dos dados para o treinamento...\")\n",
        "\n",
        "# 1. Lidar com colunas categóricas (texto)\n",
        "# O LabelEncoder transforma cada categoria única em um número. Ex: 'CA' -> 0, 'CO' -> 1, 'GA' -> 2\n",
        "categorical_features = [\n",
        "    'categoria', 'marca', 'premise', 'categoria_pdv', 'state', 'city'\n",
        "]\n",
        "\n",
        "# Copiamos para não alterar o weekly_data original\n",
        "data_for_training = weekly_data.copy()\n",
        "\n",
        "for feature in categorical_features:\n",
        "    encoder = LabelEncoder()\n",
        "    # Cria uma nova coluna com o sufixo '_encoded' com os valores numéricos\n",
        "    data_for_training[f'{feature}_encoded'] = encoder.fit_transform(data_for_training[feature])\n",
        "\n",
        "print(\"Colunas de texto convertidas para números.\")\n",
        "\n",
        "\n",
        "# 2. Definir as 'features' (X) e o 'alvo' (y)\n",
        "# O alvo (y) é o que queremos prever: 'total_quantity'\n",
        "y = data_for_training['total_quantity']\n",
        "\n",
        "# As features (X) são todas as pistas que preparamos\n",
        "feature_columns = [\n",
        "    'week',\n",
        "    # Lags e Rolling Averages\n",
        "    'quantity_lag_1', 'quantity_lag_2', 'quantity_lag_3', 'quantity_lag_4',\n",
        "    'quantity_rolling_avg_2', 'quantity_rolling_avg_4', 'quantity_rolling_avg_8',\n",
        "    # Features de Feriado (Federais e Estaduais)\n",
        "    'is_holiday_week', 'holiday_on_premise', 'holiday_off_premise',\n",
        "    'is_holiday_ca', 'is_holiday_co', 'is_holiday_ga',\n",
        "    # Features Categóricas que acabamos de codificar\n",
        "    'categoria_encoded', 'marca_encoded', 'premise_encoded',\n",
        "    'categoria_pdv_encoded', 'state_encoded', 'city_encoded'\n",
        "]\n",
        "X = data_for_training[feature_columns]\n",
        "\n",
        "\n",
        "# --- VERIFICAÇÃO ---\n",
        "print(\"\\\\nDados prontos para o modelo!\")\n",
        "print(f\"Nosso 'alvo' (y - o que queremos prever) tem {len(y):,} linhas.\")\n",
        "print(f\"Nossas 'features' (X - as pistas) têm {X.shape[0]:,} linhas e {X.shape[1]} colunas.\")\n",
        "print(\"\\\\nExemplo das features (X) que o modelo vai usar:\")\n",
        "display(X.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "ba5edbd0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dividindo os dados em conjuntos de treino e validação (80/20)...\n",
            "\\nDivisão concluída!\n",
            "Tamanho do conjunto de treino (X_train): 4,912,164 linhas\n",
            "Tamanho do conjunto de validação (X_val): 1,228,042 linhas\n"
          ]
        }
      ],
      "source": [
        "# --- PASSO 9: DIVIDIR DADOS EM TREINO E VALIDAÇÃO ---\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "print(\"Dividindo os dados em conjuntos de treino e validação (80/20)...\")\n",
        "\n",
        "# A função train_test_split faz a divisão de forma aleatória e estratificada\n",
        "# test_size=0.2 significa que 20% dos dados irão para validação\n",
        "# random_state=42 garante que a divisão seja sempre a mesma se rodarmos o código de novo\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y, \n",
        "    test_size=0.2, \n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# --- VERIFICAÇÃO ---\n",
        "print(\"\\\\nDivisão concluída!\")\n",
        "print(f\"Tamanho do conjunto de treino (X_train): {len(X_train):,} linhas\")\n",
        "print(f\"Tamanho do conjunto de validação (X_val): {len(X_val):,} linhas\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "ba01b25f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Instalando/Verificando a biblioteca 'catboost'...\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "\\nBiblioteca CatBoost pronta.\n",
            "\\nIniciando o treinamento do modelo... (Isso pode levar alguns minutos)\n",
            "0:\tlearn: 85.9999628\ttest: 66.5104908\tbest: 66.5104908 (0)\ttotal: 607ms\tremaining: 10m 6s\n",
            "Stopped by overfitting detector  (50 iterations wait)\n",
            "\n",
            "bestTest = 62.60593379\n",
            "bestIteration = 34\n",
            "\n",
            "Shrink model to first 35 iterations.\n",
            "\\n--- TREINAMENTO CONCLUÍDO! ---\n",
            "Seu modelo de previsão de vendas foi treinado com sucesso.\n"
          ]
        }
      ],
      "source": [
        "# --- PASSO 10: TREINAR O MODELO CATBOOST ---\n",
        "\n",
        "# 1. Instalar a biblioteca catboost, caso ainda não tenha\n",
        "print(\"Instalando/Verificando a biblioteca 'catboost'...\")\n",
        "%pip install catboost -q\n",
        "\n",
        "from catboost import CatBoostRegressor\n",
        "print(\"\\\\nBiblioteca CatBoost pronta.\")\n",
        "\n",
        "\n",
        "# 2. Inicializar o modelo com alguns parâmetros\n",
        "# iterations: O número máximo de \"rodadas\" de aprendizado.\n",
        "# learning_rate: O quão rápido o modelo aprende.\n",
        "# depth: A profundidade das \"árvores de decisão\" que o modelo constrói.\n",
        "model = CatBoostRegressor(\n",
        "    iterations=1000,\n",
        "    learning_rate=0.05,\n",
        "    depth=10,\n",
        "    loss_function='RMSE', # Métrica de erro que o modelo tentará minimizar\n",
        "    random_seed=42,\n",
        "    verbose=100  # Mostra o progresso do treino a cada 100 rodadas\n",
        ")\n",
        "\n",
        "print(\"\\\\nIniciando o treinamento do modelo... (Isso pode levar alguns minutos)\")\n",
        "\n",
        "# 3. Treinar o modelo!\n",
        "# Passamos os dados de treino (X_train, y_train) para ele aprender.\n",
        "# Passamos os dados de validação (eval_set) para ele monitorar a própria performance e evitar \"decoreba\".\n",
        "model.fit(\n",
        "    X_train, y_train,\n",
        "    eval_set=(X_val, y_val),\n",
        "    early_stopping_rounds=50, # Para de treinar se a performance na validação não melhorar por 50 rodadas\n",
        "    verbose=100\n",
        ")\n",
        "\n",
        "print(\"\\\\n--- TREINAMENTO CONCLUÍDO! ---\")\n",
        "print(\"Seu modelo de previsão de vendas foi treinado com sucesso.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "238e0977",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iniciando a geração das previsões para as 5 primeiras semanas de 2023...\n",
            "Prevendo a semana 1 de 2023...\n",
            "Prevendo a semana 2 de 2023...\n",
            "Prevendo a semana 3 de 2023...\n",
            "Prevendo a semana 4 de 2023...\n",
            "Prevendo a semana 5 de 2023...\n",
            "\\nPREVISÕES GERADAS COM SUCESSO!\n",
            "Total de previsões geradas: 5,114,685\n",
            "Amostra do arquivo final de previsão:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>semana</th>\n",
              "      <th>pdv</th>\n",
              "      <th>produto</th>\n",
              "      <th>quantidade_prevista</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1000237487041964405</td>\n",
              "      <td>1837429607327399565</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1000237487041964405</td>\n",
              "      <td>4038588102284338370</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1000237487041964405</td>\n",
              "      <td>5429216175252037173</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1000237487041964405</td>\n",
              "      <td>596381974901127871</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1000237487041964405</td>\n",
              "      <td>7270233133454638680</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>1000237487041964405</td>\n",
              "      <td>7370044109082767116</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>1000237487041964405</td>\n",
              "      <td>7405304019373961901</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>1000237487041964405</td>\n",
              "      <td>777251454728290683</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>1000237487041964405</td>\n",
              "      <td>8313805606242965556</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>1000275275922029725</td>\n",
              "      <td>1735457469340543861</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   semana                  pdv              produto  quantidade_prevista\n",
              "0       1  1000237487041964405  1837429607327399565                    3\n",
              "1       1  1000237487041964405  4038588102284338370                    4\n",
              "2       1  1000237487041964405  5429216175252037173                    3\n",
              "3       1  1000237487041964405   596381974901127871                    3\n",
              "4       1  1000237487041964405  7270233133454638680                    3\n",
              "5       1  1000237487041964405  7370044109082767116                    3\n",
              "6       1  1000237487041964405  7405304019373961901                    3\n",
              "7       1  1000237487041964405   777251454728290683                    3\n",
              "8       1  1000237487041964405  8313805606242965556                    3\n",
              "9       1  1000275275922029725  1735457469340543861                   32"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\\nArquivo 'previsoes_vendas_2023.csv' salvo com sucesso no seu diretório!\n"
          ]
        }
      ],
      "source": [
        "# --- PASSO 11: GERAR AS PREVISÕES PARA 2023 ---\n",
        "\n",
        "print(\"Iniciando a geração das previsões para as 5 primeiras semanas de 2023...\")\n",
        "\n",
        "# 1. Pegar o último registro de cada combinação loja/produto de 2022\n",
        "# Isso nos dará as informações mais recentes para basear nossas previsões\n",
        "latest_records = data_for_training.loc[data_for_training.groupby(['internal_store_id', 'internal_product_id'])['week'].idxmax()]\n",
        "\n",
        "# 2. Loop para prever cada uma das 5 semanas\n",
        "all_predictions = []\n",
        "current_features = latest_records.copy()\n",
        "\n",
        "for week_num in range(1, 6):\n",
        "    print(f\"Prevendo a semana {week_num} de 2023...\")\n",
        "    \n",
        "    # Atualizar a feature 'week' para a semana que queremos prever\n",
        "    current_features['week'] = week_num\n",
        "    \n",
        "    # Garantir que as features estão na ordem correta que o modelo espera\n",
        "    X_future = current_features[feature_columns]\n",
        "    \n",
        "    # Fazer a previsão!\n",
        "    predictions = model.predict(X_future)\n",
        "    \n",
        "    # Garantir que não teremos previsões negativas\n",
        "    predictions = np.maximum(0, predictions).round().astype(int)\n",
        "    \n",
        "    # Guardar as previsões em um formato amigável\n",
        "    week_predictions = pd.DataFrame({\n",
        "        'semana': week_num,\n",
        "        'pdv': current_features['internal_store_id'],\n",
        "        'produto': current_features['internal_product_id'],\n",
        "        'quantidade_prevista': predictions\n",
        "    })\n",
        "    all_predictions.append(week_predictions)\n",
        "    \n",
        "    # ATUALIZAÇÃO PARA A PRÓXIMA SEMANA:\n",
        "    # As previsões desta semana se tornam o 'lag_1' da próxima semana, e os outros lags são deslocados.\n",
        "    # Esta é a parte mais complexa, que simula o tempo passando.\n",
        "    current_features['quantity_lag_4'] = current_features['quantity_lag_3']\n",
        "    current_features['quantity_lag_3'] = current_features['quantity_lag_2']\n",
        "    current_features['quantity_lag_2'] = current_features['quantity_lag_1']\n",
        "    current_features['quantity_lag_1'] = predictions\n",
        "\n",
        "# 3. Juntar todas as previsões em um único dataframe\n",
        "predictions_df = pd.concat(all_predictions, ignore_index=True)\n",
        "\n",
        "\n",
        "# --- VERIFICAÇÃO ---\n",
        "print(\"\\\\nPREVISÕES GERADAS COM SUCESSO!\")\n",
        "print(f\"Total de previsões geradas: {len(predictions_df):,}\")\n",
        "print(\"Amostra do arquivo final de previsão:\")\n",
        "display(predictions_df.head(10))\n",
        "\n",
        "# Salvar as previsões em um arquivo CSV\n",
        "predictions_df.to_csv(\"previsoes_vendas_2023.csv\", index=False, sep=';')\n",
        "print(\"\\\\nArquivo 'previsoes_vendas_2023.csv' salvo com sucesso no seu diretório!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "d106741e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculando métricas de avaliação detalhadas no conjunto de validação...\n",
            "\\n========================================\n",
            "--- Relatório de Avaliação do Modelo ---\n",
            "========================================\n",
            "RMSE (Root Mean Squared Error): 62.61\n",
            "  -> Interpretação: Em média, as previsões erraram em ~63 unidades.\n",
            "\\nMAE (Mean Absolute Error): 8.15\n",
            "  -> Interpretação: Na média, o erro absoluto de cada previsão foi de 8 unidades.\n",
            "\\nMAPE (Mean Absolute Percentage Error): 202201.39%\n",
            "  -> Interpretação: Na média, as previsões tiveram um desvio de 202201.4% em relação ao valor real.\n",
            "\\nR² (R-squared): 0.13\n",
            "  -> Interpretação: Nosso modelo consegue explicar 12.5% da variação nas vendas.\n",
            "========================================\n"
          ]
        }
      ],
      "source": [
        "# --- PASSO 12: AVALIAÇÃO DETALHADA DO MODELO (O SEU \"EVAL\") ---\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "print(\"Calculando métricas de avaliação detalhadas no conjunto de validação...\")\n",
        "\n",
        "# 1. Usar o modelo para fazer previsões nos dados de validação que separamos\n",
        "y_pred = model.predict(X_val)\n",
        "\n",
        "# 2. Calcular as métricas de erro comparando o real (y_val) com o previsto (y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
        "mae = mean_absolute_error(y_val, y_pred)\n",
        "r2 = r2_score(y_val, y_pred)\n",
        "\n",
        "# Calcular MAPE (Erro Percentual Absoluto Médio) com cuidado para não dividir por zero\n",
        "epsilon = 1e-10 # Um número muito pequeno para evitar divisão por zero\n",
        "mape = np.mean(np.abs((y_val - y_pred) / (y_val + epsilon))) * 100\n",
        "\n",
        "\n",
        "# --- APRESENTAÇÃO DOS RESULTADOS (O SEU \"EVAL\") ---\n",
        "print(\"\\\\n\" + \"=\"*40)\n",
        "print(\"--- Relatório de Avaliação do Modelo ---\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "print(f\"RMSE (Root Mean Squared Error): {rmse:.2f}\")\n",
        "print(f\"  -> Interpretação: Em média, as previsões erraram em ~{rmse:.0f} unidades.\")\n",
        "\n",
        "print(f\"\\\\nMAE (Mean Absolute Error): {mae:.2f}\")\n",
        "print(f\"  -> Interpretação: Na média, o erro absoluto de cada previsão foi de {mae:.0f} unidades.\")\n",
        "\n",
        "print(f\"\\\\nMAPE (Mean Absolute Percentage Error): {mape:.2f}%\")\n",
        "print(f\"  -> Interpretação: Na média, as previsões tiveram um desvio de {mape:.1f}% em relação ao valor real.\")\n",
        "\n",
        "print(f\"\\\\nR² (R-squared): {r2:.2f}\")\n",
        "print(f\"  -> Interpretação: Nosso modelo consegue explicar {r2:.1%} da variação nas vendas.\")\n",
        "print(\"=\"*40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "2264c821",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculando o WMAPE (a métrica mais importante para este problema)...\n",
            "\\n=======================================================\n",
            "--- Métrica WMAPE (Weighted Mean Absolute Percentage Error) ---\n",
            "=======================================================\n",
            "WMAPE: 94.22%\n",
            "\\n  -> Interpretação: O erro total do nosso modelo corresponde a 94.2% do volume total de vendas no período de validação.\n",
            "=======================================================\n"
          ]
        }
      ],
      "source": [
        "# --- CÁLCULO DO WMAPE ---\n",
        "\n",
        "print(\"Calculando o WMAPE (a métrica mais importante para este problema)...\")\n",
        "\n",
        "# Relembrando, y_val são as vendas reais e y_pred são as previsões do modelo para o conjunto de validação.\n",
        "\n",
        "# A fórmula é: Soma dos erros absolutos / Soma dos valores reais\n",
        "wmape = np.sum(np.abs(y_val - y_pred)) / np.sum(np.abs(y_val)) * 100\n",
        "\n",
        "\n",
        "# --- RESULTADO ---\n",
        "print(\"\\\\n\" + \"=\"*55)\n",
        "print(\"--- Métrica WMAPE (Weighted Mean Absolute Percentage Error) ---\")\n",
        "print(\"=\"*55)\n",
        "print(f\"WMAPE: {wmape:.2f}%\")\n",
        "print(\"\\\\n  -> Interpretação: O erro total do nosso modelo corresponde a \" \\\n",
        "      f\"{wmape:.1f}% do volume total de vendas no período de validação.\")\n",
        "print(\"=\"*55)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "42ad324c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Refazendo o processo com uma divisão de dados baseada no tempo...\n",
            "Divisão temporal concluída: 4,952,155 linhas de treino, 1,188,051 linhas de validação.\n",
            "\\nInicializando um novo modelo com parâmetros mais seguros...\n",
            "Iniciando o retreinamento...\n",
            "0:\tlearn: 91.8266380\ttest: 14.8056012\tbest: 14.8056012 (0)\ttotal: 419ms\tremaining: 13m 57s\n",
            "Stopped by overfitting detector  (100 iterations wait)\n",
            "\n",
            "bestTest = 13.62186428\n",
            "bestIteration = 32\n",
            "\n",
            "Shrink model to first 33 iterations.\n",
            "\\n--- Reavaliando o Modelo v2 ---\n",
            "Novo WMAPE: 94.34%\n"
          ]
        }
      ],
      "source": [
        "# --- PASSO 9 e 10 (VERSÃO CORRIGIDA): DIVISÃO TEMPORAL E RETREINAMENTO ---\n",
        "\n",
        "print(\"Refazendo o processo com uma divisão de dados baseada no tempo...\")\n",
        "\n",
        "# 1. Ordenar os dados por semana\n",
        "data_for_training = data_for_training.sort_values(by='week')\n",
        "\n",
        "# 2. Fazer a divisão temporal\n",
        "# Vamos usar as semanas até a semana 42 para treino, e o resto para validação.\n",
        "split_week = 42 \n",
        "train_data = data_for_training[data_for_training['week'] <= split_week]\n",
        "val_data = data_for_training[data_for_training['week'] > split_week]\n",
        "\n",
        "# Separar features (X) e alvo (y) para cada conjunto\n",
        "X_train = train_data[feature_columns]\n",
        "y_train = train_data['total_quantity']\n",
        "X_val = val_data[feature_columns]\n",
        "y_val = val_data['total_quantity']\n",
        "\n",
        "print(f\"Divisão temporal concluída: {len(X_train):,} linhas de treino, {len(X_val):,} linhas de validação.\")\n",
        "\n",
        "\n",
        "# 3. Inicializar um novo modelo com parâmetros mais seguros\n",
        "print(\"\\\\nInicializando um novo modelo com parâmetros mais seguros...\")\n",
        "model_v2 = CatBoostRegressor(\n",
        "    iterations=2000, # Aumentamos as iterações pois esperamos que demore mais para convergir\n",
        "    learning_rate=0.05,\n",
        "    depth=7, # Profundidade menor para evitar overfitting\n",
        "    loss_function='RMSE',\n",
        "    random_seed=42,\n",
        "    verbose=200\n",
        ")\n",
        "\n",
        "# 4. Retreinar o modelo com os dados corretamente divididos\n",
        "print(\"Iniciando o retreinamento...\")\n",
        "model_v2.fit(\n",
        "    X_train, y_train,\n",
        "    eval_set=(X_val, y_val),\n",
        "    early_stopping_rounds=100 # Aumentamos a paciência do early stopping\n",
        ")\n",
        "\n",
        "\n",
        "# 5. Reavaliar o WMAPE\n",
        "print(\"\\\\n--- Reavaliando o Modelo v2 ---\")\n",
        "y_pred_v2 = model_v2.predict(X_val)\n",
        "\n",
        "wmape_v2 = np.sum(np.abs(y_val - y_pred_v2)) / np.sum(np.abs(y_val)) * 100\n",
        "\n",
        "print(f\"Novo WMAPE: {wmape_v2:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "36364d54",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Investigando o conjunto de validação (y_val) para entender o WMAPE...\n",
            "Número total de linhas no y_val: 1,188,051\n",
            "Número de vendas zero no y_val: 0\n",
            "Porcentagem de vendas zero no y_val: 0.00%\n",
            "Soma total das vendas no y_val (denominador do WMAPE): 6,004,308.94\n",
            "\\nEstatísticas descritivas de y_val:\n",
            "count    1.188051e+06\n",
            "mean     5.053915e+00\n",
            "std      1.426702e+01\n",
            "min      4.166700e-02\n",
            "25%      1.000000e+00\n",
            "50%      2.000000e+00\n",
            "75%      4.000000e+00\n",
            "max      2.472000e+03\n",
            "Name: total_quantity, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# --- INVESTIGANDO O CONJUNTO DE VALIDAÇÃO (y_val) ---\n",
        "\n",
        "print(\"Investigando o conjunto de validação (y_val) para entender o WMAPE...\")\n",
        "print(f\"Número total de linhas no y_val: {len(y_val):,}\")\n",
        "\n",
        "# Contar quantas vendas são zero no conjunto de validação\n",
        "num_vendas_zero = (y_val == 0).sum()\n",
        "print(f\"Número de vendas zero no y_val: {num_vendas_zero:,}\")\n",
        "\n",
        "# Calcular a porcentagem de vendas zero\n",
        "porcentagem_vendas_zero = (num_vendas_zero / len(y_val)) * 100\n",
        "print(f\"Porcentagem de vendas zero no y_val: {porcentagem_vendas_zero:.2f}%\")\n",
        "\n",
        "# Calcular a soma total das vendas no y_val (o denominador do WMAPE)\n",
        "soma_total_vendas = y_val.sum()\n",
        "print(f\"Soma total das vendas no y_val (denominador do WMAPE): {soma_total_vendas:,.2f}\")\n",
        "\n",
        "# Mostrar algumas estatísticas de y_val\n",
        "print(\"\\\\nEstatísticas descritivas de y_val:\")\n",
        "print(y_val.describe())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
