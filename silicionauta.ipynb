{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Martoto/BigData_ForecastHackathon/blob/main/silicionauta.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5cbfde9a",
      "metadata": {
        "id": "5cbfde9a"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "559b0055",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/mnt/batch/tasks/shared/LS_root/mounts/clusters/memoryman/code/Users/daniel.sant.salles\n"
          ]
        }
      ],
      "source": [
        "%cd Users/daniel.sant.salles/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4472b044",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in c:\\users\\danie\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.2.3)\n",
            "Requirement already satisfied: pyarrow in c:\\users\\danie\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (21.0.0)\n",
            "Requirement already satisfied: seaborn in c:\\users\\danie\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.13.2)\n",
            "Requirement already satisfied: plotly in c:\\users\\danie\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (5.24.1)\n",
            "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\danie\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\danie\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\danie\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\danie\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\danie\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from seaborn) (3.10.5)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\danie\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from plotly) (9.1.2)\n",
            "Requirement already satisfied: packaging in c:\\users\\danie\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from plotly) (24.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\danie\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\danie\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\danie\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\danie\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\danie\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\danie\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.3)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\danie\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install pandas pyarrow seaborn plotly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "13da2d6c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13da2d6c",
        "outputId": "817e4941-beea-44e1-feb1-d9ef4b53a41b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/hackathon_2025_templates.zip not found. Downloading...\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/hackathon_2025_templates.zip'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     14\u001b[39m response = requests.get(download_url, stream=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     15\u001b[39m response.raise_for_status() \u001b[38;5;66;03m# Raise an exception for bad status codes\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mwb\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     18\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m response.iter_content(chunk_size=\u001b[32m8192\u001b[39m):\n\u001b[32m     19\u001b[39m         f.write(chunk)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\IPython\\core\\interactiveshell.py:343\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    337\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    338\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    339\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    340\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    341\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m343\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/content/hackathon_2025_templates.zip'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import requests\n",
        "\n",
        "file_path = '/content/hackathon_2025_templates.zip'\n",
        "file_id = '1Ed-nqUyCT0z-T0AvHwLMsGqHYqjw2248' # This is the file ID\n",
        "\n",
        "if not os.path.exists(file_path):\n",
        "    print(f'{file_path} not found. Downloading...')\n",
        "\n",
        "    # Construct the direct download URL\n",
        "    download_url = f'https://drive.google.com/uc?export=download&id={file_id}'\n",
        "\n",
        "    try:\n",
        "        response = requests.get(download_url, stream=True)\n",
        "        response.raise_for_status() # Raise an exception for bad status codes\n",
        "\n",
        "        with open(file_path, 'wb') as f:\n",
        "            for chunk in response.iter_content(chunk_size=8192):\n",
        "                f.write(chunk)\n",
        "\n",
        "        print(f'{file_path} downloaded successfully.')\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error downloading the file: {e}\")\n",
        "        print(\"Please ensure the file is shared publicly or with 'Anyone with the link'.\")\n",
        "\n",
        "else:\n",
        "    print(f'{file_path} found.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "de6d0ad1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracted hackathon_2025_templates.zip to ./data/\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_path = 'hackathon_2025_templates.zip'\n",
        "extract_dir = './data/'\n",
        "\n",
        "if os.path.exists(zip_path):\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_dir)\n",
        "    print(f'Extracted {zip_path} to {extract_dir}')\n",
        "else:\n",
        "    print(f'{zip_path} not found in the current directory.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "0bbfcf34",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pdv</th>\n",
              "      <th>premise</th>\n",
              "      <th>categoria_pdv</th>\n",
              "      <th>zipcode</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2204965430669363375</td>\n",
              "      <td>On Premise</td>\n",
              "      <td>Mexican Rest</td>\n",
              "      <td>30741</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5211957289528622910</td>\n",
              "      <td>On Premise</td>\n",
              "      <td>Hotel/Motel</td>\n",
              "      <td>80011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9024493554530757353</td>\n",
              "      <td>Off Premise</td>\n",
              "      <td>Convenience</td>\n",
              "      <td>80751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8659197371382902429</td>\n",
              "      <td>On Premise</td>\n",
              "      <td>Restaurant</td>\n",
              "      <td>80439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1400854873763881130</td>\n",
              "      <td>On Premise</td>\n",
              "      <td>Restaurant</td>\n",
              "      <td>30093</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   pdv      premise categoria_pdv  zipcode\n",
              "0  2204965430669363375   On Premise  Mexican Rest    30741\n",
              "1  5211957289528622910   On Premise   Hotel/Motel    80011\n",
              "2  9024493554530757353  Off Premise   Convenience    80751\n",
              "3  8659197371382902429   On Premise    Restaurant    80439\n",
              "4  1400854873763881130   On Premise    Restaurant    30093"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "file_path = './data/part-00000-tid-2779033056155408584-f6316110-4c9a-4061-ae48-69b77c7c8c36-4-1-c000.snappy.parquet'\n",
        "df_pdv = pd.read_parquet(file_path)\n",
        "display(df_pdv.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "0ba2fc66",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>internal_store_id</th>\n",
              "      <th>internal_product_id</th>\n",
              "      <th>distributor_id</th>\n",
              "      <th>transaction_date</th>\n",
              "      <th>reference_date</th>\n",
              "      <th>quantity</th>\n",
              "      <th>gross_value</th>\n",
              "      <th>net_value</th>\n",
              "      <th>gross_profit</th>\n",
              "      <th>discount</th>\n",
              "      <th>taxes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7384367747233276219</td>\n",
              "      <td>328903483604537190</td>\n",
              "      <td>9</td>\n",
              "      <td>2022-07-13</td>\n",
              "      <td>2022-07-01</td>\n",
              "      <td>1.0</td>\n",
              "      <td>38.125000</td>\n",
              "      <td>37.890625</td>\n",
              "      <td>10.042625</td>\n",
              "      <td>3.950000</td>\n",
              "      <td>0.234375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3536908514005606262</td>\n",
              "      <td>5418855670645487653</td>\n",
              "      <td>5</td>\n",
              "      <td>2022-03-21</td>\n",
              "      <td>2022-03-01</td>\n",
              "      <td>6.0</td>\n",
              "      <td>107.250000</td>\n",
              "      <td>106.440002</td>\n",
              "      <td>24.732002</td>\n",
              "      <td>17.100000</td>\n",
              "      <td>0.810000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3138231730993449825</td>\n",
              "      <td>1087005562675741887</td>\n",
              "      <td>6</td>\n",
              "      <td>2022-09-06</td>\n",
              "      <td>2022-09-01</td>\n",
              "      <td>3.0</td>\n",
              "      <td>56.625000</td>\n",
              "      <td>56.220001</td>\n",
              "      <td>14.124002</td>\n",
              "      <td>5.250000</td>\n",
              "      <td>0.405000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3681167389484217654</td>\n",
              "      <td>1401422983880045188</td>\n",
              "      <td>5</td>\n",
              "      <td>2022-09-11</td>\n",
              "      <td>2022-09-01</td>\n",
              "      <td>129.0</td>\n",
              "      <td>1037.160023</td>\n",
              "      <td>1037.160023</td>\n",
              "      <td>156.348026</td>\n",
              "      <td>479.880006</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7762413312337359369</td>\n",
              "      <td>6614994347738381720</td>\n",
              "      <td>4</td>\n",
              "      <td>2022-02-18</td>\n",
              "      <td>2022-02-01</td>\n",
              "      <td>1.0</td>\n",
              "      <td>26.230000</td>\n",
              "      <td>23.950241</td>\n",
              "      <td>6.550241</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.279758</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     internal_store_id  internal_product_id distributor_id transaction_date  \\\n",
              "0  7384367747233276219   328903483604537190              9       2022-07-13   \n",
              "1  3536908514005606262  5418855670645487653              5       2022-03-21   \n",
              "2  3138231730993449825  1087005562675741887              6       2022-09-06   \n",
              "3  3681167389484217654  1401422983880045188              5       2022-09-11   \n",
              "4  7762413312337359369  6614994347738381720              4       2022-02-18   \n",
              "\n",
              "  reference_date  quantity  gross_value    net_value  gross_profit  \\\n",
              "0     2022-07-01       1.0    38.125000    37.890625     10.042625   \n",
              "1     2022-03-01       6.0   107.250000   106.440002     24.732002   \n",
              "2     2022-09-01       3.0    56.625000    56.220001     14.124002   \n",
              "3     2022-09-01     129.0  1037.160023  1037.160023    156.348026   \n",
              "4     2022-02-01       1.0    26.230000    23.950241      6.550241   \n",
              "\n",
              "     discount     taxes  \n",
              "0    3.950000  0.234375  \n",
              "1   17.100000  0.810000  \n",
              "2    5.250000  0.405000  \n",
              "3  479.880006  0.000000  \n",
              "4    0.000000  2.279758  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "file_path = './data/part-00000-tid-5196563791502273604-c90d3a24-52f2-4955-b4ec-fb143aae74d8-4-1-c000.snappy.parquet'\n",
        "df_transactions = pd.read_parquet(file_path)\n",
        "display(df_transactions.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "a6e80f95",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 7,092 unique product IDs in transactions\n",
            "Total rows processed: 7,092\n",
            "Total rows kept: 7,092\n",
            "Filtering efficiency: 100.00%\n",
            "Final products dataframe shape: (7092, 8)\n",
            "\n",
            "First few rows of filtered products:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>produto</th>\n",
              "      <th>categoria</th>\n",
              "      <th>descricao</th>\n",
              "      <th>tipos</th>\n",
              "      <th>label</th>\n",
              "      <th>subcategoria</th>\n",
              "      <th>marca</th>\n",
              "      <th>fabricante</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2282334733936076502</td>\n",
              "      <td>Distilled Spirits</td>\n",
              "      <td>JOSEPH CARTRON CAF√â LIQUEUR</td>\n",
              "      <td>Distilled Spirits</td>\n",
              "      <td>Core</td>\n",
              "      <td>Liqueurs &amp; Cordials</td>\n",
              "      <td>Joseph Cartron Cafe</td>\n",
              "      <td>Spiribam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6091840953834683482</td>\n",
              "      <td>Distilled Spirits</td>\n",
              "      <td>SPRINGBANK 18 YEAR SINGLE MALT 700ML</td>\n",
              "      <td>Distilled Spirits</td>\n",
              "      <td>Specialty</td>\n",
              "      <td>Scotch Whisky</td>\n",
              "      <td>Springbank 18 Year Single Malt</td>\n",
              "      <td>Pacific Edge Wine &amp; Spirits</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1968645851245092408</td>\n",
              "      <td>Distilled Spirits</td>\n",
              "      <td>J BRANDT TRIPLE SEC 12/750ML 30PF</td>\n",
              "      <td>Distilled Spirits</td>\n",
              "      <td>Private Label</td>\n",
              "      <td>Liqueurs &amp; Cordials</td>\n",
              "      <td>J Brandt Triple Sec</td>\n",
              "      <td>Sazerac Spirits</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>994706710729219179</td>\n",
              "      <td>Draft</td>\n",
              "      <td>REFORMATION CASHMERE IPA 1/4 KEG</td>\n",
              "      <td>Draft</td>\n",
              "      <td>In&amp;Out</td>\n",
              "      <td>Other Draft</td>\n",
              "      <td>Reformation Cashmere Fresh Hop IPA</td>\n",
              "      <td>Reformation Brewery</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9209550539540384349</td>\n",
              "      <td>Non-Alcohol</td>\n",
              "      <td>HELLA MOSCOW MULE 750ML</td>\n",
              "      <td>Non Alcohol</td>\n",
              "      <td>Core</td>\n",
              "      <td>Mixers</td>\n",
              "      <td>Hella Bitters Bloody Mary</td>\n",
              "      <td>Hella Bitter Llc</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               produto          categoria  \\\n",
              "0  2282334733936076502  Distilled Spirits   \n",
              "1  6091840953834683482  Distilled Spirits   \n",
              "2  1968645851245092408  Distilled Spirits   \n",
              "3   994706710729219179              Draft   \n",
              "4  9209550539540384349        Non-Alcohol   \n",
              "\n",
              "                              descricao              tipos          label  \\\n",
              "0           JOSEPH CARTRON CAF√â LIQUEUR  Distilled Spirits           Core   \n",
              "1  SPRINGBANK 18 YEAR SINGLE MALT 700ML  Distilled Spirits      Specialty   \n",
              "2     J BRANDT TRIPLE SEC 12/750ML 30PF  Distilled Spirits  Private Label   \n",
              "3      REFORMATION CASHMERE IPA 1/4 KEG              Draft         In&Out   \n",
              "4               HELLA MOSCOW MULE 750ML        Non Alcohol           Core   \n",
              "\n",
              "          subcategoria                               marca  \\\n",
              "0  Liqueurs & Cordials                 Joseph Cartron Cafe   \n",
              "1        Scotch Whisky      Springbank 18 Year Single Malt   \n",
              "2  Liqueurs & Cordials                 J Brandt Triple Sec   \n",
              "3          Other Draft  Reformation Cashmere Fresh Hop IPA   \n",
              "4               Mixers           Hella Bitters Bloody Mary   \n",
              "\n",
              "                    fabricante  \n",
              "0                     Spiribam  \n",
              "1  Pacific Edge Wine & Spirits  \n",
              "2              Sazerac Spirits  \n",
              "3          Reformation Brewery  \n",
              "4             Hella Bitter Llc  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import pyarrow.parquet as pq\n",
        "\n",
        "# Get unique product IDs from transactions for filtering\n",
        "valid_product_ids = set(df_transactions['internal_product_id'].unique())\n",
        "print(f\"Found {len(valid_product_ids):,} unique product IDs in transactions\")\n",
        "\n",
        "file_path = './data/part-00000-tid-7173294866425216458-eae53fbf-d19e-4130-ba74-78f96b9675f1-4-1-c000.snappy.parquet'\n",
        "table = pq.ParquetFile(file_path)\n",
        "\n",
        "# Collect filtered chunks\n",
        "filtered_chunks = []\n",
        "total_rows_processed = 0\n",
        "total_rows_kept = 0\n",
        "\n",
        "for batch in table.iter_batches(batch_size=5000):\n",
        "    df_chunk = batch.to_pandas()\n",
        "    total_rows_processed += len(df_chunk)\n",
        "    \n",
        "    # Filter to keep only products that exist in transactions\n",
        "    filtered_chunk = df_chunk[df_chunk['produto'].isin(valid_product_ids)]\n",
        "    total_rows_kept += len(filtered_chunk)\n",
        "    \n",
        "    if len(filtered_chunk) > 0:\n",
        "        filtered_chunks.append(filtered_chunk)\n",
        "\n",
        "# Combine all filtered chunks\n",
        "df_products = pd.concat(filtered_chunks, ignore_index=True) if filtered_chunks else pd.DataFrame()\n",
        "\n",
        "print(f\"Total rows processed: {total_rows_processed:,}\")\n",
        "print(f\"Total rows kept: {total_rows_kept:,}\")\n",
        "print(f\"Filtering efficiency: {(total_rows_kept/total_rows_processed)*100:.2f}%\")\n",
        "print(f\"Final products dataframe shape: {df_products.shape}\")\n",
        "print(\"\\nFirst few rows of filtered products:\")\n",
        "display(df_products.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "794e610a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç FILTERING VERIFICATION\n",
            "==================================================\n",
            "Unique products in filtered dataset: 7,092\n",
            "Unique products in transactions: 7,092\n",
            "Unique products in filtered products: 7,092\n",
            "Products in both datasets: 7,092\n",
            "‚úÖ All transaction products are covered in the products dataset\n",
            "‚úÖ All products have corresponding transactions\n",
            "\n",
            "üìä Data consistency: Perfect match!\n"
          ]
        }
      ],
      "source": [
        "# Verification of the filtering results\n",
        "print(\"üîç FILTERING VERIFICATION\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Check unique products in filtered dataset\n",
        "unique_products_filtered = df_products['produto'].nunique()\n",
        "print(f\"Unique products in filtered dataset: {unique_products_filtered:,}\")\n",
        "\n",
        "# Check if all transaction products are covered\n",
        "transaction_products = set(df_transactions['internal_product_id'].unique())\n",
        "filtered_products = set(df_products['produto'].unique())\n",
        "\n",
        "print(f\"Unique products in transactions: {len(transaction_products):,}\")\n",
        "print(f\"Unique products in filtered products: {len(filtered_products):,}\")\n",
        "\n",
        "# Check intersection\n",
        "intersection = transaction_products.intersection(filtered_products)\n",
        "print(f\"Products in both datasets: {len(intersection):,}\")\n",
        "\n",
        "# Check if there are products in transactions not in products\n",
        "missing_in_products = transaction_products - filtered_products\n",
        "if missing_in_products:\n",
        "    print(f\"‚ö†Ô∏è  Products in transactions but missing in products: {len(missing_in_products)}\")\n",
        "    print(f\"Examples: {list(missing_in_products)[:10]}\")\n",
        "else:\n",
        "    print(\"‚úÖ All transaction products are covered in the products dataset\")\n",
        "\n",
        "# Check if there are products in products not in transactions\n",
        "missing_in_transactions = filtered_products - transaction_products\n",
        "if missing_in_transactions:\n",
        "    print(f\"‚ö†Ô∏è  Products in products but missing in transactions: {len(missing_in_transactions)}\")\n",
        "    print(f\"Examples: {list(missing_in_transactions)[:10]}\")\n",
        "else:\n",
        "    print(\"‚úÖ All products have corresponding transactions\")\n",
        "\n",
        "print(f\"\\nüìä Data consistency: {'Perfect match!' if len(missing_in_products) == 0 and len(missing_in_transactions) == 0 else 'Some mismatches found'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12d4a337",
      "metadata": {},
      "source": [
        "1- pdv\tpremise\tcategoria_pdv\tzipcode \n",
        "2- internal_store_id\tinternal_product_id\tdistributor_id\ttransaction_date\treference_date\tquantity\tgross_value\tnet_value\tgross_profit\tdiscount\ttaxes\n",
        "3- produto categoria descricao tipos label subcategoria marca fabricante               \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fbe54ba0",
      "metadata": {},
      "source": [
        "## Vis√£o Geral da Estrutura dos Dados\n",
        "\n",
        "### üìä Dataset 1: Ponto de Venda (PDV)\n",
        "| Coluna | Descri√ß√£o |\n",
        "|--------|-----------|\n",
        "| `pdv` | Identificador do Ponto de Venda |\n",
        "| `premise` | Informa√ß√µes da loja/estabelecimento |\n",
        "| `categoria_pdv` | Classifica√ß√£o da categoria do PDV |\n",
        "| `zipcode` | C√≥digo postal/CEP |\n",
        "\n",
        "### üí≥ Dataset 2: Transa√ß√µes\n",
        "| Coluna | Descri√ß√£o |\n",
        "|--------|-----------|\n",
        "| `internal_store_id` | Identificador interno da loja |\n",
        "| `internal_product_id` | Identificador interno do produto |\n",
        "| `distributor_id` | Identificador do distribuidor |\n",
        "| `transaction_date` | Data da transa√ß√£o |\n",
        "| `reference_date` | Data de refer√™ncia |\n",
        "| `quantity` | Quantidade da transa√ß√£o |\n",
        "| `gross_value` | Valor bruto da transa√ß√£o |\n",
        "| `net_value` | Valor l√≠quido da transa√ß√£o |\n",
        "| `gross_profit` | Lucro bruto |\n",
        "| `discount` | Desconto aplicado |\n",
        "| `taxes` | Valor dos impostos |\n",
        "\n",
        "### üõçÔ∏è Dataset 3: Produtos\n",
        "| Coluna | Descri√ß√£o |\n",
        "|--------|-----------|\n",
        "| `produto` | Identificador do produto |\n",
        "| `categoria` | Categoria do produto |\n",
        "| `descricao` | Descri√ß√£o do produto |\n",
        "| `tipos` | Tipos do produto |\n",
        "| `label` | R√≥tulo do produto |\n",
        "| `subcategoria` | Subcategoria do produto |\n",
        "| `marca` | Marca |\n",
        "| `fabricante` | Fabricante |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fd45d3a",
      "metadata": {},
      "source": [
        "# üöÄ EXPLORATORY DATA ANALYSIS - HACKATHON 2025\n",
        "## Going HAM on the Data! üí™\n",
        "\n",
        "Let's dive deep into this retail dataset and uncover insights for forecasting!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "823fad08",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üöÄ Libraries loaded successfully! Let's go HAM on this data!\n"
          ]
        }
      ],
      "source": [
        "# Import comprehensive analysis libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configure visualization settings\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', 100)\n",
        "\n",
        "print(\"üöÄ Libraries loaded successfully! Let's go HAM on this data!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "4ff35384",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîÑ Loading all three datasets...\n",
            "‚úÖ PDV Dataset loaded: (14419, 4)\n",
            "‚úÖ Transactions Dataset loaded: (6560698, 11)\n",
            "‚úÖ Products Dataset loaded: (7092, 8)\n",
            "\n",
            "üéØ Total datasets loaded: 3\n",
            "üìà Combined data points: 6,582,209\n"
          ]
        }
      ],
      "source": [
        "# üìä LOAD ALL DATASETS\n",
        "print(\"üîÑ Loading all three datasets...\")\n",
        "\n",
        "# Dataset 1: PDV (Points of Sale)\n",
        "pdv_file = './data/part-00000-tid-2779033056155408584-f6316110-4c9a-4061-ae48-69b77c7c8c36-4-1-c000.snappy.parquet'\n",
        "df_pdv = pd.read_parquet(pdv_file)\n",
        "print(f\"‚úÖ PDV Dataset loaded: {df_pdv.shape}\")\n",
        "\n",
        "# Dataset 2: Transactions\n",
        "transactions_file = './data/part-00000-tid-5196563791502273604-c90d3a24-52f2-4955-b4ec-fb143aae74d8-4-1-c000.snappy.parquet'\n",
        "df_transactions = pd.read_parquet(transactions_file)\n",
        "print(f\"‚úÖ Transactions Dataset loaded: {df_transactions.shape}\")\n",
        "\n",
        "# Dataset 3: Products (using chunked reading for large file)\n",
        "products_file = './data/part-00000-tid-7173294866425216458-eae53fbf-d19e-4130-ba74-78f96b9675f1-4-1-c000.snappy.parquet'\n",
        "df_products = pd.read_parquet(products_file)\n",
        "print(f\"‚úÖ Products Dataset loaded: {df_products.shape}\")\n",
        "\n",
        "print(f\"\\nüéØ Total datasets loaded: 3\")\n",
        "print(f\"üìà Combined data points: {df_pdv.shape[0] + df_transactions.shape[0] + df_products.shape[0]:,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "d24ce161",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "üîç DEEP DIVE INTO DATASET STRUCTURES\n",
            "================================================================================\n",
            "\n",
            "üìä PDV DATASET ANALYSIS:\n",
            "   üìè Shape: (14419, 4)\n",
            "   üìã Columns: ['pdv', 'premise', 'categoria_pdv', 'zipcode']\n",
            "   üè∑Ô∏è  Data Types:\n",
            "      pdv: object\n",
            "      premise: object\n",
            "      categoria_pdv: object\n",
            "      zipcode: int32\n",
            "   üíæ Memory Usage: 2.62 MB\n",
            "   üï≥Ô∏è  Missing Values: 0\n",
            "   üî¢ Unique Values per Column:\n",
            "      pdv: 14,419\n",
            "      premise: 2\n",
            "      categoria_pdv: 54\n",
            "      zipcode: 788\n",
            "------------------------------------------------------------\n",
            "\n",
            "üìä TRANSACTIONS DATASET ANALYSIS:\n",
            "   üìè Shape: (6560698, 11)\n",
            "   üìã Columns: ['internal_store_id', 'internal_product_id', 'distributor_id', 'transaction_date', 'reference_date', 'quantity', 'gross_value', 'net_value', 'gross_profit', 'discount', 'taxes']\n",
            "   üè∑Ô∏è  Data Types:\n",
            "      internal_store_id: object\n",
            "      internal_product_id: object\n",
            "      distributor_id: object\n",
            "      transaction_date: object\n",
            "      reference_date: object\n",
            "      quantity: float64\n",
            "      gross_value: float64\n",
            "      net_value: float64\n",
            "      gross_profit: float64\n",
            "      discount: float64\n",
            "      taxes: float64\n",
            "   üíæ Memory Usage: 1963.29 MB\n",
            "   üï≥Ô∏è  Missing Values: 0\n",
            "   üî¢ Unique Values per Column:\n",
            "      internal_store_id: 15,086\n",
            "      internal_product_id: 7,092\n",
            "      distributor_id: 8\n",
            "      transaction_date: 365\n",
            "      reference_date: 12\n",
            "      quantity: 16,449\n",
            "      gross_value: 173,883\n",
            "      net_value: 216,337\n",
            "      gross_profit: 363,451\n",
            "      discount: 121,528\n",
            "      taxes: 12,531\n",
            "------------------------------------------------------------\n",
            "\n",
            "üìä PRODUCTS DATASET ANALYSIS:\n",
            "   üìè Shape: (7092, 8)\n",
            "   üìã Columns: ['produto', 'categoria', 'descricao', 'tipos', 'label', 'subcategoria', 'marca', 'fabricante']\n",
            "   üè∑Ô∏è  Data Types:\n",
            "      produto: object\n",
            "      categoria: object\n",
            "      descricao: object\n",
            "      tipos: object\n",
            "      label: object\n",
            "      subcategoria: object\n",
            "      marca: object\n",
            "      fabricante: object\n",
            "   üíæ Memory Usage: 3.53 MB\n",
            "   üï≥Ô∏è  Missing Values: 1505\n",
            "   üî¢ Unique Values per Column:\n",
            "      produto: 7,092\n",
            "      categoria: 7\n",
            "      descricao: 7,092\n",
            "      tipos: 22\n",
            "      label: 14\n",
            "      subcategoria: 42\n",
            "      marca: 4,221\n",
            "      fabricante: 343\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# üîç DATASET STRUCTURE ANALYSIS - Going Deep!\n",
        "print(\"=\"*80)\n",
        "print(\"üîç DEEP DIVE INTO DATASET STRUCTURES\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "datasets = {\n",
        "    'PDV': df_pdv,\n",
        "    'Transactions': df_transactions,\n",
        "    'Products': df_products\n",
        "}\n",
        "\n",
        "for name, df in datasets.items():\n",
        "    print(f\"\\nüìä {name.upper()} DATASET ANALYSIS:\")\n",
        "    print(f\"   üìè Shape: {df.shape}\")\n",
        "    print(f\"   üìã Columns: {list(df.columns)}\")\n",
        "    print(f\"   üè∑Ô∏è  Data Types:\")\n",
        "    for col, dtype in df.dtypes.items():\n",
        "        print(f\"      {col}: {dtype}\")\n",
        "    print(f\"   üíæ Memory Usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
        "    print(f\"   üï≥Ô∏è  Missing Values: {df.isnull().sum().sum()}\")\n",
        "    print(f\"   üî¢ Unique Values per Column:\")\n",
        "    for col in df.columns:\n",
        "        unique_count = df[col].nunique()\n",
        "        print(f\"      {col}: {unique_count:,}\")\n",
        "    print(\"-\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29ba9777",
      "metadata": {},
      "outputs": [],
      "source": [
        "# üßπ DATA QUALITY ASSESSMENT - The Deep Clean!\n",
        "print(\"=\"*80)\n",
        "print(\"üßπ DATA QUALITY ASSESSMENT\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def analyze_data_quality(df, name):\n",
        "    print(f\"\\nüîç {name} QUALITY REPORT:\")\n",
        "    \n",
        "    # Missing values analysis\n",
        "    missing_values = df.isnull().sum()\n",
        "    missing_percent = (missing_values / len(df)) * 100\n",
        "    \n",
        "    print(f\"üìä Missing Values Analysis:\")\n",
        "    for col in df.columns:\n",
        "        if missing_values[col] > 0:\n",
        "            print(f\"   {col}: {missing_values[col]:,} ({missing_percent[col]:.2f}%)\")\n",
        "    \n",
        "    # Duplicates analysis\n",
        "    duplicates = df.duplicated().sum()\n",
        "    print(f\"üîÑ Duplicate Rows: {duplicates:,} ({(duplicates/len(df)*100):.2f}%)\")\n",
        "    \n",
        "    # Numerical columns analysis\n",
        "    numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
        "    if len(numerical_cols) > 0:\n",
        "        print(f\"üìà Numerical Columns Analysis:\")\n",
        "        for col in numerical_cols:\n",
        "            q1 = df[col].quantile(0.25)\n",
        "            q3 = df[col].quantile(0.75)\n",
        "            iqr = q3 - q1\n",
        "            outliers = ((df[col] < (q1 - 1.5 * iqr)) | (df[col] > (q3 + 1.5 * iqr))).sum()\n",
        "            print(f\"   {col}: Min={df[col].min():.2f}, Max={df[col].max():.2f}, Outliers={outliers:,}\")\n",
        "    \n",
        "    print(\"-\" * 60)\n",
        "\n",
        "# Analyze each dataset\n",
        "for name, df in datasets.items():\n",
        "    analyze_data_quality(df, name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "f011f8bb",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "üí∞ SALES TRANSACTION ANALYSIS\n",
            "================================================================================\n",
            "üìÖ Transaction Date Range:\n",
            "   From: 2022-01-01 00:00:00\n",
            "   To: 2022-12-31 00:00:00\n",
            "   Duration: 364 days\n",
            "\n",
            "üíµ Financial Metrics Summary:\n",
            "   quantity:\n",
            "      Total: $53,311,532.07\n",
            "      Average: $8.13\n",
            "      Median: $2.00\n",
            "      Std Dev: $80.49\n",
            "   gross_value:\n",
            "      Total: $805,333,770.76\n",
            "      Average: $122.75\n",
            "      Median: $42.10\n",
            "      Std Dev: $866.43\n",
            "   net_value:\n",
            "      Total: $781,531,966.87\n",
            "      Average: $119.12\n",
            "      Median: $40.77\n",
            "      Std Dev: $865.18\n",
            "   gross_profit:\n",
            "      Total: $143,882,148.80\n",
            "      Average: $21.93\n",
            "      Median: $10.51\n",
            "      Std Dev: $232.65\n",
            "   discount:\n",
            "      Total: $181,513,749.61\n",
            "      Average: $27.67\n",
            "      Median: $2.30\n",
            "      Std Dev: $384.76\n",
            "   taxes:\n",
            "      Total: $23,801,803.14\n",
            "      Average: $3.63\n",
            "      Median: $0.54\n",
            "      Std Dev: $11.31\n",
            "\n",
            "üè™ Top 10 Stores by Total Revenue:\n",
            "   Store 6491855528940268514: $2,932,767.13\n",
            "   Store 3025867614395044464: $2,684,152.80\n",
            "   Store 4374038751643985193: $2,616,642.68\n",
            "   Store 7195906766187577140: $2,338,811.76\n",
            "   Store 6337402841339348330: $2,327,405.16\n",
            "   Store 5130630496972372280: $2,192,520.00\n",
            "   Store 8723723113467008071: $2,182,582.85\n",
            "   Store 8294871217390043140: $2,182,338.53\n",
            "   Store 4003964282058636604: $2,124,037.75\n",
            "   Store 2720921832183866690: $1,921,439.23\n",
            "\n",
            "üõçÔ∏è Top 10 Products by Total Sales:\n",
            "   Product 4040509988492387426: $20,987,395.40\n",
            "   Product 8352471677482341950: $13,964,609.53\n",
            "   Product 500478784353013717: $12,630,634.08\n",
            "   Product 3620674245436818138: $12,549,666.40\n",
            "   Product 1029370090212151375: $12,065,719.51\n",
            "   Product 1938760505411922162: $11,353,110.50\n",
            "   Product 3894706280449257667: $10,667,511.27\n",
            "   Product 3262679882836704514: $10,522,927.93\n",
            "   Product 4524932930736383075: $10,460,878.54\n",
            "   Product 1860061817666925715: $8,923,429.36\n"
          ]
        }
      ],
      "source": [
        "# üí∞ SALES TRANSACTION ANALYSIS - The Money Maker!\n",
        "print(\"=\"*80)\n",
        "print(\"üí∞ SALES TRANSACTION ANALYSIS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Convert date columns to datetime\n",
        "if 'transaction_date' in df_transactions.columns:\n",
        "    df_transactions['transaction_date'] = pd.to_datetime(df_transactions['transaction_date'])\n",
        "if 'reference_date' in df_transactions.columns:\n",
        "    df_transactions['reference_date'] = pd.to_datetime(df_transactions['reference_date'])\n",
        "\n",
        "# Time period analysis\n",
        "print(f\"üìÖ Transaction Date Range:\")\n",
        "if 'transaction_date' in df_transactions.columns:\n",
        "    print(f\"   From: {df_transactions['transaction_date'].min()}\")\n",
        "    print(f\"   To: {df_transactions['transaction_date'].max()}\")\n",
        "    print(f\"   Duration: {(df_transactions['transaction_date'].max() - df_transactions['transaction_date'].min()).days} days\")\n",
        "\n",
        "# Financial metrics overview\n",
        "numerical_cols = ['quantity', 'gross_value', 'net_value', 'gross_profit', 'discount', 'taxes']\n",
        "available_cols = [col for col in numerical_cols if col in df_transactions.columns]\n",
        "\n",
        "print(f\"\\nüíµ Financial Metrics Summary:\")\n",
        "if available_cols:\n",
        "    for col in available_cols:\n",
        "        print(f\"   {col}:\")\n",
        "        print(f\"      Total: ${df_transactions[col].sum():,.2f}\")\n",
        "        print(f\"      Average: ${df_transactions[col].mean():.2f}\")\n",
        "        print(f\"      Median: ${df_transactions[col].median():.2f}\")\n",
        "        print(f\"      Std Dev: ${df_transactions[col].std():.2f}\")\n",
        "\n",
        "# Top performing stores and products\n",
        "print(f\"\\nüè™ Top 10 Stores by Total Revenue:\")\n",
        "if 'internal_store_id' in df_transactions.columns and 'gross_value' in df_transactions.columns:\n",
        "    top_stores = df_transactions.groupby('internal_store_id')['gross_value'].sum().sort_values(ascending=False).head(10)\n",
        "    for store_id, revenue in top_stores.items():\n",
        "        print(f\"   Store {store_id}: ${revenue:,.2f}\")\n",
        "\n",
        "print(f\"\\nüõçÔ∏è Top 10 Products by Total Sales:\")\n",
        "if 'internal_product_id' in df_transactions.columns and 'gross_value' in df_transactions.columns:\n",
        "    top_products = df_transactions.groupby('internal_product_id')['gross_value'].sum().sort_values(ascending=False).head(10)\n",
        "    for product_id, revenue in top_products.items():\n",
        "        print(f\"   Product {product_id}: ${revenue:,.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "7cd05a43",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "üìà TIME SERIES ANALYSIS\n",
            "================================================================================\n",
            "üìä Daily Sales Statistics:\n",
            "   Total Days with Transactions: 365\n",
            "   Average Daily Revenue: $2,206,393.89\n",
            "   Best Day Revenue: $269,828,419.09\n",
            "   Worst Day Revenue: $11,394.54\n",
            "\n",
            "üìÖ Weekly Sales Patterns:\n",
            "   Sunday: $280,198,190.63\n",
            "   Monday: $129,634,657.15\n",
            "   Tuesday: $124,884,143.82\n",
            "   Wednesday: $108,631,312.81\n",
            "   Thursday: $91,117,453.89\n",
            "   Friday: $68,646,346.69\n",
            "   Saturday: $2,221,665.77\n",
            "\n",
            "üóìÔ∏è Monthly Revenue Trends:\n",
            "   2022-01: $31,089,589.20\n",
            "   2022-02: $34,985,233.80\n",
            "   2022-03: $42,767,181.34\n",
            "   2022-04: $39,708,678.19\n",
            "   2022-05: $48,529,123.84\n",
            "   2022-06: $51,197,744.23\n",
            "   2022-07: $41,707,373.43\n",
            "   2022-08: $51,961,556.34\n",
            "   2022-09: $312,855,647.57\n",
            "   2022-10: $47,909,054.74\n",
            "   2022-11: $50,067,765.72\n",
            "   2022-12: $52,554,822.35\n",
            "\n",
            "üåü Seasonality Insights:\n",
            "   Peak Sales Month: 9 ($378.86 avg)\n",
            "   Lowest Sales Month: 1 ($80.98 avg)\n"
          ]
        }
      ],
      "source": [
        "# üìà TIME SERIES ANALYSIS - The Time Machine!\n",
        "print(\"=\"*80)\n",
        "print(\"üìà TIME SERIES ANALYSIS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "if 'transaction_date' in df_transactions.columns:\n",
        "    # Extract time components\n",
        "    df_transactions['year'] = df_transactions['transaction_date'].dt.year\n",
        "    df_transactions['month'] = df_transactions['transaction_date'].dt.month\n",
        "    df_transactions['day'] = df_transactions['transaction_date'].dt.day\n",
        "    df_transactions['weekday'] = df_transactions['transaction_date'].dt.day_name()\n",
        "    df_transactions['week'] = df_transactions['transaction_date'].dt.isocalendar().week\n",
        "    \n",
        "    # Daily sales analysis\n",
        "    daily_sales = df_transactions.groupby('transaction_date').agg({\n",
        "        'gross_value': ['sum', 'mean', 'count'],\n",
        "        'quantity': 'sum'\n",
        "    }).round(2)\n",
        "    \n",
        "    print(f\"üìä Daily Sales Statistics:\")\n",
        "    print(f\"   Total Days with Transactions: {len(daily_sales)}\")\n",
        "    print(f\"   Average Daily Revenue: ${daily_sales[('gross_value', 'sum')].mean():,.2f}\")\n",
        "    print(f\"   Best Day Revenue: ${daily_sales[('gross_value', 'sum')].max():,.2f}\")\n",
        "    print(f\"   Worst Day Revenue: ${daily_sales[('gross_value', 'sum')].min():,.2f}\")\n",
        "    \n",
        "    # Weekly patterns\n",
        "    weekly_patterns = df_transactions.groupby('weekday')['gross_value'].sum().sort_values(ascending=False)\n",
        "    print(f\"\\nüìÖ Weekly Sales Patterns:\")\n",
        "    for day, revenue in weekly_patterns.items():\n",
        "        print(f\"   {day}: ${revenue:,.2f}\")\n",
        "    \n",
        "    # Monthly trends\n",
        "    if 'gross_value' in df_transactions.columns:\n",
        "        monthly_trends = df_transactions.groupby(['year', 'month'])['gross_value'].sum()\n",
        "        print(f\"\\nüóìÔ∏è Monthly Revenue Trends:\")\n",
        "        for (year, month), revenue in monthly_trends.items():\n",
        "            print(f\"   {year}-{month:02d}: ${revenue:,.2f}\")\n",
        "\n",
        "# Seasonality detection\n",
        "print(f\"\\nüåü Seasonality Insights:\")\n",
        "if 'month' in df_transactions.columns:\n",
        "    seasonal_pattern = df_transactions.groupby('month')['gross_value'].mean().round(2)\n",
        "    peak_month = seasonal_pattern.idxmax()\n",
        "    low_month = seasonal_pattern.idxmin()\n",
        "    print(f\"   Peak Sales Month: {peak_month} (${seasonal_pattern[peak_month]:,.2f} avg)\")\n",
        "    print(f\"   Lowest Sales Month: {low_month} (${seasonal_pattern[low_month]:,.2f} avg)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "c572c185",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "üõçÔ∏è PRODUCT PORTFOLIO ANALYSIS\n",
            "================================================================================\n",
            "üì¶ Product Categories Overview:\n",
            "   Total Categories: 7\n",
            "   Top 10 Categories:\n",
            "      Distilled Spirits: 2,202 products\n",
            "      Wine: 1,879 products\n",
            "      Package: 1,403 products\n",
            "      Draft: 918 products\n",
            "      Non-Alcohol: 597 products\n",
            "      ABA Spirits: 91 products\n",
            "      Tobacco: 2 products\n",
            "\n",
            "üè∑Ô∏è Brand Analysis:\n",
            "   Total Brands: 4221\n",
            "   Top 10 Brands:\n",
            "      Barrell Bourbon- Private Label: 60 products\n",
            "      Bud Light: 38 products\n",
            "      Budweiser: 36 products\n",
            "      Barrell Stellum - Private Label: 35 products\n",
            "      Fireball Cinnamon Whiskey: 28 products\n",
            "      Buffalo Trace Kentucky Straight Bourbon Whiskey: 27 products\n",
            "      Yukon Jack Canadian Whiskey Honey: 24 products\n",
            "      Stella Artois: 21 products\n",
            "      Michelob Ultra: 21 products\n",
            "      Chi-Chi's Variety Pack: 20 products\n",
            "\n",
            "üè≠ Manufacturer Analysis:\n",
            "   Total Manufacturers: 343\n",
            "   Top 10 Manufacturers:\n",
            "      Sazerac Spirits: 1,169 products\n",
            "      AB Anheuser Busch Inc: 878 products\n",
            "      Tilray Brands: 311 products\n",
            "      Barrell Craft Spirits: 132 products\n",
            "      Pacific Edge Wine & Spirits: 130 products\n",
            "      Sazerac ABA: 125 products\n",
            "      Small Vineyards: 112 products\n",
            "      National - The Wine Group: 109 products\n",
            "      Monday Night Brewing: 108 products\n",
            "      Scott Levy: 105 products\n",
            "\n",
            "üéØ Product Types Distribution:\n",
            "   Total Types: 22\n",
            "      Distilled Spirits: 1,816 products\n",
            "      Package: 1,384 products\n",
            "      Wine < 14 %: 1,377 products\n",
            "      Draft: 913 products\n",
            "      Wine > 14 %: 555 products\n",
            "      Non Alcohol: 531 products\n",
            "      Allocated Spirits: 201 products\n",
            "      Distilled Spirits-RTD: 103 products\n",
            "      Hispanic: 52 products\n",
            "      Non Alcohol W&S: 47 products\n",
            "      Distilled Spirits-Domest: 44 products\n",
            "      N/A Beer: 17 products\n",
            "      Wine RTD: 14 products\n",
            "      Wine < 14 % - Domestic: 11 products\n",
            "      Cider Pkg: 8 products\n"
          ]
        }
      ],
      "source": [
        "# üõçÔ∏è PRODUCT PORTFOLIO ANALYSIS - The Product Universe!\n",
        "print(\"=\"*80)\n",
        "print(\"üõçÔ∏è PRODUCT PORTFOLIO ANALYSIS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Product categories analysis\n",
        "print(\"üì¶ Product Categories Overview:\")\n",
        "if 'categoria' in df_products.columns:\n",
        "    category_counts = df_products['categoria'].value_counts()\n",
        "    print(f\"   Total Categories: {len(category_counts)}\")\n",
        "    print(\"   Top 10 Categories:\")\n",
        "    for cat, count in category_counts.head(10).items():\n",
        "        print(f\"      {cat}: {count:,} products\")\n",
        "\n",
        "# Brand analysis\n",
        "print(f\"\\nüè∑Ô∏è Brand Analysis:\")\n",
        "if 'marca' in df_products.columns:\n",
        "    brand_counts = df_products['marca'].value_counts()\n",
        "    print(f\"   Total Brands: {len(brand_counts)}\")\n",
        "    print(\"   Top 10 Brands:\")\n",
        "    for brand, count in brand_counts.head(10).items():\n",
        "        print(f\"      {brand}: {count:,} products\")\n",
        "\n",
        "# Manufacturer analysis\n",
        "print(f\"\\nüè≠ Manufacturer Analysis:\")\n",
        "if 'fabricante' in df_products.columns:\n",
        "    mfg_counts = df_products['fabricante'].value_counts()\n",
        "    print(f\"   Total Manufacturers: {len(mfg_counts)}\")\n",
        "    print(\"   Top 10 Manufacturers:\")\n",
        "    for mfg, count in mfg_counts.head(10).items():\n",
        "        print(f\"      {mfg}: {count:,} products\")\n",
        "\n",
        "# Product types analysis\n",
        "print(f\"\\nüéØ Product Types Distribution:\")\n",
        "if 'tipos' in df_products.columns:\n",
        "    type_counts = df_products['tipos'].value_counts()\n",
        "    print(f\"   Total Types: {len(type_counts)}\")\n",
        "    for ptype, count in type_counts.head(15).items():\n",
        "        print(f\"      {ptype}: {count:,} products\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "b2ee36b2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "üó∫Ô∏è GEOGRAPHICAL ANALYSIS\n",
            "================================================================================\n",
            "üìç Zipcode Distribution:\n",
            "   Total Unique Zipcodes: 788\n",
            "   Top 15 Zipcodes by Store Count:\n",
            "      80202: 230 stores\n",
            "      30096: 133 stores\n",
            "      80205: 129 stores\n",
            "      80211: 127 stores\n",
            "      81301: 123 stores\n",
            "      80524: 113 stores\n",
            "      80501: 108 stores\n",
            "      30120: 105 stores\n",
            "      30161: 105 stores\n",
            "      80424: 103 stores\n",
            "      80903: 103 stores\n",
            "      30721: 102 stores\n",
            "      80203: 102 stores\n",
            "      80525: 100 stores\n",
            "      80302: 100 stores\n",
            "\n",
            "üè™ PDV Categories:\n",
            "   Total Categories: 54\n",
            "      Restaurant: 3,316 stores\n",
            "      Convenience: 2,849 stores\n",
            "      Package/Liquor: 2,153 stores\n",
            "      Bar: 1,444 stores\n",
            "      Grocery: 697 stores\n",
            "      Mexican Rest: 623 stores\n",
            "      Other On Premise: 473 stores\n",
            "      Hotel/Motel: 359 stores\n",
            "      Asian: 263 stores\n",
            "      Pizza: 187 stores\n",
            "      Super Center: 181 stores\n",
            "      Golf - Public: 168 stores\n",
            "      Drug: 167 stores\n",
            "      Italian: 144 stores\n",
            "      Service Org: 138 stores\n",
            "      Special Event: 137 stores\n",
            "      Golf - Private: 113 stores\n",
            "      Billiard/Bowling: 91 stores\n",
            "      Sports/Rec Club: 88 stores\n",
            "      Stadium/Concession: 79 stores\n",
            "      Barbeque: 76 stores\n",
            "      Theatre: 75 stores\n",
            "      Club Store: 65 stores\n",
            "      Banquet/Caterer: 55 stores\n",
            "      Night Club: 52 stores\n",
            "      Irish: 46 stores\n",
            "      Church: 43 stores\n",
            "      Sample Room: 35 stores\n",
            "      Music Venue: 33 stores\n",
            "      Coffee House: 33 stores\n",
            "      Other Off Premise: 32 stores\n",
            "      Airline/Airport: 20 stores\n",
            "      Bodega: 19 stores\n",
            "      Korean: 18 stores\n",
            "      Adult Entertainment: 17 stores\n",
            "      All Other N/A Off Premise: 16 stores\n",
            "      All Other N/A On Premise: 16 stores\n",
            "      Gay Bar: 16 stores\n",
            "      Military: 11 stores\n",
            "      French: 11 stores\n",
            "      Winery: 9 stores\n",
            "      Gym/Fitness: 8 stores\n",
            "      Theme Park: 7 stores\n",
            "      Sub Distributor: 6 stores\n",
            "      Health Club: 5 stores\n",
            "      German: 4 stores\n",
            "      Salon/Spa/Tann: 4 stores\n",
            "      Non-Traditional: 3 stores\n",
            "      Race Track: 3 stores\n",
            "      Marina / Lake: 3 stores\n",
            "      Neighborhood Store: 3 stores\n",
            "      Country/Western: 3 stores\n",
            "      Casino: 1 stores\n",
            "      Mass Merch: 1 stores\n",
            "\n",
            "üè¢ Store Premise Types:\n",
            "   Total Premise Types: 2\n",
            "      On Premise: 8,216 stores\n",
            "      Off Premise: 6,203 stores\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# üó∫Ô∏è GEOGRAPHICAL ANALYSIS - The Map Masters!\n",
        "print(\"=\"*80)\n",
        "print(\"üó∫Ô∏è GEOGRAPHICAL ANALYSIS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# PDV location analysis\n",
        "if 'zipcode' in df_pdv.columns:\n",
        "    zipcode_analysis = df_pdv['zipcode'].value_counts()\n",
        "    print(f\"üìç Zipcode Distribution:\")\n",
        "    print(f\"   Total Unique Zipcodes: {len(zipcode_analysis)}\")\n",
        "    print(\"   Top 15 Zipcodes by Store Count:\")\n",
        "    for zip_code, count in zipcode_analysis.head(15).items():\n",
        "        print(f\"      {zip_code}: {count:,} stores\")\n",
        "\n",
        "# PDV category analysis\n",
        "if 'categoria_pdv' in df_pdv.columns:\n",
        "    pdv_categories = df_pdv['categoria_pdv'].value_counts()\n",
        "    print(f\"\\nüè™ PDV Categories:\")\n",
        "    print(f\"   Total Categories: {len(pdv_categories)}\")\n",
        "    for category, count in pdv_categories.items():\n",
        "        print(f\"      {category}: {count:,} stores\")\n",
        "\n",
        "# Store premise analysis\n",
        "if 'premise' in df_pdv.columns:\n",
        "    premise_analysis = df_pdv['premise'].value_counts()\n",
        "    print(f\"\\nüè¢ Store Premise Types:\")\n",
        "    print(f\"   Total Premise Types: {len(premise_analysis)}\")\n",
        "    for premise, count in premise_analysis.head(10).items():\n",
        "        print(f\"      {premise}: {count:,} stores\")\n",
        "\n",
        "print(\"-\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "14eefe09",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "üìà CREATING KILLER VISUALIZATIONS\n",
            "================================================================================\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'make_subplots' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m80\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Create a subplot figure for comprehensive analysis\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m fig = \u001b[43mmake_subplots\u001b[49m(\n\u001b[32m      8\u001b[39m     rows=\u001b[32m2\u001b[39m, cols=\u001b[32m2\u001b[39m,\n\u001b[32m      9\u001b[39m     subplot_titles=(\u001b[33m'\u001b[39m\u001b[33mDaily Sales Trend\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mWeekly Pattern\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mTop Categories\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mRevenue Distribution\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m     10\u001b[39m     specs=[[{\u001b[33m\"\u001b[39m\u001b[33msecondary_y\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m}, {\u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mbar\u001b[39m\u001b[33m\"\u001b[39m}],\n\u001b[32m     11\u001b[39m            [{\u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mpie\u001b[39m\u001b[33m\"\u001b[39m}, {\u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mhistogram\u001b[39m\u001b[33m\"\u001b[39m}]]\n\u001b[32m     12\u001b[39m )\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# 1. Daily sales trend\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mtransaction_date\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m df_transactions.columns \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mgross_value\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m df_transactions.columns:\n",
            "\u001b[31mNameError\u001b[39m: name 'make_subplots' is not defined"
          ]
        }
      ],
      "source": [
        "# üìà ADVANCED VISUALIZATIONS - The Eye Candy!\n",
        "print(\"=\"*80)\n",
        "print(\"üìà CREATING KILLER VISUALIZATIONS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Create a subplot figure for comprehensive analysis\n",
        "fig = make_subplots(\n",
        "    rows=2, cols=2,\n",
        "    subplot_titles=('Daily Sales Trend', 'Weekly Pattern', 'Top Categories', 'Revenue Distribution'),\n",
        "    specs=[[{\"secondary_y\": True}, {\"type\": \"bar\"}],\n",
        "           [{\"type\": \"pie\"}, {\"type\": \"histogram\"}]]\n",
        ")\n",
        "\n",
        "# 1. Daily sales trend\n",
        "if 'transaction_date' in df_transactions.columns and 'gross_value' in df_transactions.columns:\n",
        "    daily_sales = df_transactions.groupby('transaction_date')['gross_value'].sum().reset_index()\n",
        "    fig.add_trace(\n",
        "        go.Scatter(x=daily_sales['transaction_date'], y=daily_sales['gross_value'],\n",
        "                  mode='lines+markers', name='Daily Sales'),\n",
        "        row=1, col=1\n",
        "    )\n",
        "\n",
        "# 2. Weekly patterns\n",
        "if 'weekday' in df_transactions.columns:\n",
        "    weekly_data = df_transactions.groupby('weekday')['gross_value'].sum().reset_index()\n",
        "    weekday_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
        "    weekly_data['weekday'] = pd.Categorical(weekly_data['weekday'], categories=weekday_order, ordered=True)\n",
        "    weekly_data = weekly_data.sort_values('weekday')\n",
        "    \n",
        "    fig.add_trace(\n",
        "        go.Bar(x=weekly_data['weekday'], y=weekly_data['gross_value'],\n",
        "               name='Weekly Sales', marker_color='lightblue'),\n",
        "        row=1, col=2\n",
        "    )\n",
        "\n",
        "# 3. Top product categories (if we can link products to transactions)\n",
        "if 'categoria' in df_products.columns:\n",
        "    top_categories = df_products['categoria'].value_counts().head(8)\n",
        "    fig.add_trace(\n",
        "        go.Pie(labels=top_categories.index, values=top_categories.values,\n",
        "               name=\"Categories\"),\n",
        "        row=2, col=1\n",
        "    )\n",
        "\n",
        "# 4. Revenue distribution\n",
        "if 'gross_value' in df_transactions.columns:\n",
        "    fig.add_trace(\n",
        "        go.Histogram(x=df_transactions['gross_value'], name='Revenue Distribution',\n",
        "                    nbinsx=50, marker_color='orange'),\n",
        "        row=2, col=2\n",
        "    )\n",
        "\n",
        "# Update layout\n",
        "fig.update_layout(height=800, showlegend=True, \n",
        "                  title_text=\"üöÄ Comprehensive Retail Analytics Dashboard\")\n",
        "fig.show()\n",
        "\n",
        "print(\"‚úÖ Interactive dashboard created!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "57bde639",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "üîó CORRELATION ANALYSIS\n",
            "================================================================================\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'plt' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m correlation_matrix = df_transactions[available_financial].corr()\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Create correlation heatmap\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[43mplt\u001b[49m.figure(figsize=(\u001b[32m12\u001b[39m, \u001b[32m8\u001b[39m))\n\u001b[32m     15\u001b[39m sns.heatmap(correlation_matrix, annot=\u001b[38;5;28;01mTrue\u001b[39;00m, cmap=\u001b[33m'\u001b[39m\u001b[33mcoolwarm\u001b[39m\u001b[33m'\u001b[39m, center=\u001b[32m0\u001b[39m, \n\u001b[32m     16\u001b[39m             square=\u001b[38;5;28;01mTrue\u001b[39;00m, linewidths=\u001b[32m0.5\u001b[39m, cbar_kws={\u001b[33m\"\u001b[39m\u001b[33mshrink\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m.8\u001b[39m})\n\u001b[32m     17\u001b[39m plt.title(\u001b[33m'\u001b[39m\u001b[33müí∞ Financial Metrics Correlation Matrix\u001b[39m\u001b[33m'\u001b[39m, fontsize=\u001b[32m16\u001b[39m, fontweight=\u001b[33m'\u001b[39m\u001b[33mbold\u001b[39m\u001b[33m'\u001b[39m)\n",
            "\u001b[31mNameError\u001b[39m: name 'plt' is not defined"
          ]
        }
      ],
      "source": [
        "# üîó CORRELATION ANALYSIS - Finding Hidden Relationships!\n",
        "print(\"=\"*80)\n",
        "print(\"üîó CORRELATION ANALYSIS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Financial metrics correlation\n",
        "financial_cols = ['quantity', 'gross_value', 'net_value', 'gross_profit', 'discount', 'taxes']\n",
        "available_financial = [col for col in financial_cols if col in df_transactions.columns]\n",
        "\n",
        "if len(available_financial) > 1:\n",
        "    correlation_matrix = df_transactions[available_financial].corr()\n",
        "    \n",
        "    # Create correlation heatmap\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
        "                square=True, linewidths=0.5, cbar_kws={\"shrink\": .8})\n",
        "    plt.title('üí∞ Financial Metrics Correlation Matrix', fontsize=16, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"üîç Key Correlations:\")\n",
        "    # Find strongest correlations\n",
        "    for i in range(len(correlation_matrix.columns)):\n",
        "        for j in range(i+1, len(correlation_matrix.columns)):\n",
        "            corr_val = correlation_matrix.iloc[i, j]\n",
        "            if abs(corr_val) > 0.7:  # Strong correlation\n",
        "                col1, col2 = correlation_matrix.columns[i], correlation_matrix.columns[j]\n",
        "                print(f\"   {col1} ‚Üî {col2}: {corr_val:.3f}\")\n",
        "\n",
        "# Distributor performance analysis\n",
        "if 'distributor_id' in df_transactions.columns and 'gross_value' in df_transactions.columns:\n",
        "    distributor_performance = df_transactions.groupby('distributor_id').agg({\n",
        "        'gross_value': ['sum', 'mean', 'count'],\n",
        "        'quantity': 'sum',\n",
        "        'gross_profit': 'sum' if 'gross_profit' in df_transactions.columns else 'mean'\n",
        "    }).round(2)\n",
        "    \n",
        "    print(f\"\\nüöö Top 10 Distributors by Revenue:\")\n",
        "    top_distributors = df_transactions.groupby('distributor_id')['gross_value'].sum().sort_values(ascending=False).head(10)\n",
        "    for dist_id, revenue in top_distributors.items():\n",
        "        transactions_count = df_transactions[df_transactions['distributor_id'] == dist_id].shape[0]\n",
        "        print(f\"   Distributor {dist_id}: ${revenue:,.2f} ({transactions_count:,} transactions)\")\n",
        "\n",
        "print(\"-\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "7dc620f3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- 1. DADOS DAS LOJAS (PDV) ---\n",
            "Shape: (14419, 4)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pdv</th>\n",
              "      <th>premise</th>\n",
              "      <th>categoria_pdv</th>\n",
              "      <th>zipcode</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2204965430669363375</td>\n",
              "      <td>On Premise</td>\n",
              "      <td>Mexican Rest</td>\n",
              "      <td>30741</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5211957289528622910</td>\n",
              "      <td>On Premise</td>\n",
              "      <td>Hotel/Motel</td>\n",
              "      <td>80011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9024493554530757353</td>\n",
              "      <td>Off Premise</td>\n",
              "      <td>Convenience</td>\n",
              "      <td>80751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8659197371382902429</td>\n",
              "      <td>On Premise</td>\n",
              "      <td>Restaurant</td>\n",
              "      <td>80439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1400854873763881130</td>\n",
              "      <td>On Premise</td>\n",
              "      <td>Restaurant</td>\n",
              "      <td>30093</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   pdv      premise categoria_pdv  zipcode\n",
              "0  2204965430669363375   On Premise  Mexican Rest    30741\n",
              "1  5211957289528622910   On Premise   Hotel/Motel    80011\n",
              "2  9024493554530757353  Off Premise   Convenience    80751\n",
              "3  8659197371382902429   On Premise    Restaurant    80439\n",
              "4  1400854873763881130   On Premise    Restaurant    30093"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\\n==================================================\\n\n",
            "--- 2. DADOS DAS TRANSA√á√ïES ---\n",
            "Shape: (6560698, 16)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>internal_store_id</th>\n",
              "      <th>internal_product_id</th>\n",
              "      <th>distributor_id</th>\n",
              "      <th>transaction_date</th>\n",
              "      <th>reference_date</th>\n",
              "      <th>quantity</th>\n",
              "      <th>gross_value</th>\n",
              "      <th>net_value</th>\n",
              "      <th>gross_profit</th>\n",
              "      <th>discount</th>\n",
              "      <th>taxes</th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>weekday</th>\n",
              "      <th>week</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7384367747233276219</td>\n",
              "      <td>328903483604537190</td>\n",
              "      <td>9</td>\n",
              "      <td>2022-07-13</td>\n",
              "      <td>2022-07-01</td>\n",
              "      <td>1.0</td>\n",
              "      <td>38.125000</td>\n",
              "      <td>37.890625</td>\n",
              "      <td>10.042625</td>\n",
              "      <td>3.950000</td>\n",
              "      <td>0.234375</td>\n",
              "      <td>2022</td>\n",
              "      <td>7</td>\n",
              "      <td>13</td>\n",
              "      <td>Wednesday</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3536908514005606262</td>\n",
              "      <td>5418855670645487653</td>\n",
              "      <td>5</td>\n",
              "      <td>2022-03-21</td>\n",
              "      <td>2022-03-01</td>\n",
              "      <td>6.0</td>\n",
              "      <td>107.250000</td>\n",
              "      <td>106.440002</td>\n",
              "      <td>24.732002</td>\n",
              "      <td>17.100000</td>\n",
              "      <td>0.810000</td>\n",
              "      <td>2022</td>\n",
              "      <td>3</td>\n",
              "      <td>21</td>\n",
              "      <td>Monday</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3138231730993449825</td>\n",
              "      <td>1087005562675741887</td>\n",
              "      <td>6</td>\n",
              "      <td>2022-09-06</td>\n",
              "      <td>2022-09-01</td>\n",
              "      <td>3.0</td>\n",
              "      <td>56.625000</td>\n",
              "      <td>56.220001</td>\n",
              "      <td>14.124002</td>\n",
              "      <td>5.250000</td>\n",
              "      <td>0.405000</td>\n",
              "      <td>2022</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>Tuesday</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3681167389484217654</td>\n",
              "      <td>1401422983880045188</td>\n",
              "      <td>5</td>\n",
              "      <td>2022-09-11</td>\n",
              "      <td>2022-09-01</td>\n",
              "      <td>129.0</td>\n",
              "      <td>1037.160023</td>\n",
              "      <td>1037.160023</td>\n",
              "      <td>156.348026</td>\n",
              "      <td>479.880006</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2022</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "      <td>Sunday</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7762413312337359369</td>\n",
              "      <td>6614994347738381720</td>\n",
              "      <td>4</td>\n",
              "      <td>2022-02-18</td>\n",
              "      <td>2022-02-01</td>\n",
              "      <td>1.0</td>\n",
              "      <td>26.230000</td>\n",
              "      <td>23.950241</td>\n",
              "      <td>6.550241</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.279758</td>\n",
              "      <td>2022</td>\n",
              "      <td>2</td>\n",
              "      <td>18</td>\n",
              "      <td>Friday</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     internal_store_id  internal_product_id distributor_id transaction_date  \\\n",
              "0  7384367747233276219   328903483604537190              9       2022-07-13   \n",
              "1  3536908514005606262  5418855670645487653              5       2022-03-21   \n",
              "2  3138231730993449825  1087005562675741887              6       2022-09-06   \n",
              "3  3681167389484217654  1401422983880045188              5       2022-09-11   \n",
              "4  7762413312337359369  6614994347738381720              4       2022-02-18   \n",
              "\n",
              "  reference_date  quantity  gross_value    net_value  gross_profit  \\\n",
              "0     2022-07-01       1.0    38.125000    37.890625     10.042625   \n",
              "1     2022-03-01       6.0   107.250000   106.440002     24.732002   \n",
              "2     2022-09-01       3.0    56.625000    56.220001     14.124002   \n",
              "3     2022-09-01     129.0  1037.160023  1037.160023    156.348026   \n",
              "4     2022-02-01       1.0    26.230000    23.950241      6.550241   \n",
              "\n",
              "     discount     taxes  year  month  day    weekday  week  \n",
              "0    3.950000  0.234375  2022      7   13  Wednesday    28  \n",
              "1   17.100000  0.810000  2022      3   21     Monday    12  \n",
              "2    5.250000  0.405000  2022      9    6    Tuesday    36  \n",
              "3  479.880006  0.000000  2022      9   11     Sunday    36  \n",
              "4    0.000000  2.279758  2022      2   18     Friday     7  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\\n==================================================\\n\n",
            "--- 3. DADOS DOS PRODUTOS ---\n",
            "Shape: (7092, 8)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>produto</th>\n",
              "      <th>categoria</th>\n",
              "      <th>descricao</th>\n",
              "      <th>tipos</th>\n",
              "      <th>label</th>\n",
              "      <th>subcategoria</th>\n",
              "      <th>marca</th>\n",
              "      <th>fabricante</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2282334733936076502</td>\n",
              "      <td>Distilled Spirits</td>\n",
              "      <td>JOSEPH CARTRON CAF√â LIQUEUR</td>\n",
              "      <td>Distilled Spirits</td>\n",
              "      <td>Core</td>\n",
              "      <td>Liqueurs &amp; Cordials</td>\n",
              "      <td>Joseph Cartron Cafe</td>\n",
              "      <td>Spiribam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6091840953834683482</td>\n",
              "      <td>Distilled Spirits</td>\n",
              "      <td>SPRINGBANK 18 YEAR SINGLE MALT 700ML</td>\n",
              "      <td>Distilled Spirits</td>\n",
              "      <td>Specialty</td>\n",
              "      <td>Scotch Whisky</td>\n",
              "      <td>Springbank 18 Year Single Malt</td>\n",
              "      <td>Pacific Edge Wine &amp; Spirits</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1968645851245092408</td>\n",
              "      <td>Distilled Spirits</td>\n",
              "      <td>J BRANDT TRIPLE SEC 12/750ML 30PF</td>\n",
              "      <td>Distilled Spirits</td>\n",
              "      <td>Private Label</td>\n",
              "      <td>Liqueurs &amp; Cordials</td>\n",
              "      <td>J Brandt Triple Sec</td>\n",
              "      <td>Sazerac Spirits</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>994706710729219179</td>\n",
              "      <td>Draft</td>\n",
              "      <td>REFORMATION CASHMERE IPA 1/4 KEG</td>\n",
              "      <td>Draft</td>\n",
              "      <td>In&amp;Out</td>\n",
              "      <td>Other Draft</td>\n",
              "      <td>Reformation Cashmere Fresh Hop IPA</td>\n",
              "      <td>Reformation Brewery</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9209550539540384349</td>\n",
              "      <td>Non-Alcohol</td>\n",
              "      <td>HELLA MOSCOW MULE 750ML</td>\n",
              "      <td>Non Alcohol</td>\n",
              "      <td>Core</td>\n",
              "      <td>Mixers</td>\n",
              "      <td>Hella Bitters Bloody Mary</td>\n",
              "      <td>Hella Bitter Llc</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               produto          categoria  \\\n",
              "0  2282334733936076502  Distilled Spirits   \n",
              "1  6091840953834683482  Distilled Spirits   \n",
              "2  1968645851245092408  Distilled Spirits   \n",
              "3   994706710729219179              Draft   \n",
              "4  9209550539540384349        Non-Alcohol   \n",
              "\n",
              "                              descricao              tipos          label  \\\n",
              "0           JOSEPH CARTRON CAF√â LIQUEUR  Distilled Spirits           Core   \n",
              "1  SPRINGBANK 18 YEAR SINGLE MALT 700ML  Distilled Spirits      Specialty   \n",
              "2     J BRANDT TRIPLE SEC 12/750ML 30PF  Distilled Spirits  Private Label   \n",
              "3      REFORMATION CASHMERE IPA 1/4 KEG              Draft         In&Out   \n",
              "4               HELLA MOSCOW MULE 750ML        Non Alcohol           Core   \n",
              "\n",
              "          subcategoria                               marca  \\\n",
              "0  Liqueurs & Cordials                 Joseph Cartron Cafe   \n",
              "1        Scotch Whisky      Springbank 18 Year Single Malt   \n",
              "2  Liqueurs & Cordials                 J Brandt Triple Sec   \n",
              "3          Other Draft  Reformation Cashmere Fresh Hop IPA   \n",
              "4               Mixers           Hella Bitters Bloody Mary   \n",
              "\n",
              "                    fabricante  \n",
              "0                     Spiribam  \n",
              "1  Pacific Edge Wine & Spirits  \n",
              "2              Sazerac Spirits  \n",
              "3          Reformation Brewery  \n",
              "4             Hella Bitter Llc  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "# --- VERIFICA√á√ÉO ---\n",
        "# Vamos verificar se os arquivos foram carregados corretamente.\n",
        "\n",
        "print(\"--- 1. DADOS DAS LOJAS (PDV) ---\")\n",
        "print(f\"Shape: {df_pdv.shape}\") # Mostra (linhas, colunas)\n",
        "display(df_pdv.head())         # Mostra as 5 primeiras linhas\n",
        "print(\"\\\\n\" + \"=\"*50 + \"\\\\n\")\n",
        "\n",
        "print(\"--- 2. DADOS DAS TRANSA√á√ïES ---\")\n",
        "print(f\"Shape: {df_transactions.shape}\")\n",
        "display(df_transactions.head())\n",
        "print(\"\\\\n\" + \"=\"*50 + \"\\\\n\")\n",
        "\n",
        "print(\"--- 3. DADOS DOS PRODUTOS ---\")\n",
        "print(f\"Shape: {df_products.shape}\")\n",
        "display(df_products.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "de96abf7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iniciando a jun√ß√£o das tabelas...\n",
            "Ap√≥s juntar com produtos, a tabela tem 24 colunas.\n",
            "Ap√≥s juntar com as lojas, a tabela final tem 28 colunas.\n",
            "\\nJun√ß√£o conclu√≠da! Vamos verificar o resultado:\n",
            "Shape da tabela original de transa√ß√µes: (6560698, 16)\n",
            "Shape da tabela final combinada:      (6560698, 28)\n",
            "\\nExemplo da tabela combinada (note as colunas 'marca', 'categoria', 'premise', etc.):\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>internal_store_id</th>\n",
              "      <th>internal_product_id</th>\n",
              "      <th>distributor_id</th>\n",
              "      <th>transaction_date</th>\n",
              "      <th>reference_date</th>\n",
              "      <th>quantity</th>\n",
              "      <th>gross_value</th>\n",
              "      <th>net_value</th>\n",
              "      <th>gross_profit</th>\n",
              "      <th>discount</th>\n",
              "      <th>...</th>\n",
              "      <th>descricao</th>\n",
              "      <th>tipos</th>\n",
              "      <th>label</th>\n",
              "      <th>subcategoria</th>\n",
              "      <th>marca</th>\n",
              "      <th>fabricante</th>\n",
              "      <th>pdv</th>\n",
              "      <th>premise</th>\n",
              "      <th>categoria_pdv</th>\n",
              "      <th>zipcode</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7384367747233276219</td>\n",
              "      <td>328903483604537190</td>\n",
              "      <td>9</td>\n",
              "      <td>2022-07-13</td>\n",
              "      <td>2022-07-01</td>\n",
              "      <td>1.0</td>\n",
              "      <td>38.125000</td>\n",
              "      <td>37.890625</td>\n",
              "      <td>10.042625</td>\n",
              "      <td>3.950000</td>\n",
              "      <td>...</td>\n",
              "      <td>BUD LIGHT CHELADA FUEGO 15/25 CN</td>\n",
              "      <td>Package</td>\n",
              "      <td>Core</td>\n",
              "      <td>Specialty</td>\n",
              "      <td>Bud Light Chelada Fuego</td>\n",
              "      <td>AB Anheuser Busch Inc</td>\n",
              "      <td>7384367747233276219</td>\n",
              "      <td>Off Premise</td>\n",
              "      <td>Package/Liquor</td>\n",
              "      <td>80905.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3536908514005606262</td>\n",
              "      <td>5418855670645487653</td>\n",
              "      <td>5</td>\n",
              "      <td>2022-03-21</td>\n",
              "      <td>2022-03-01</td>\n",
              "      <td>6.0</td>\n",
              "      <td>107.250000</td>\n",
              "      <td>106.440002</td>\n",
              "      <td>24.732002</td>\n",
              "      <td>17.100000</td>\n",
              "      <td>...</td>\n",
              "      <td>MICHELOB ULTRA 18/12 CN</td>\n",
              "      <td>Package</td>\n",
              "      <td>Core</td>\n",
              "      <td>Lager</td>\n",
              "      <td>Michelob Ultra</td>\n",
              "      <td>AB Anheuser Busch Inc</td>\n",
              "      <td>3536908514005606262</td>\n",
              "      <td>Off Premise</td>\n",
              "      <td>Package/Liquor</td>\n",
              "      <td>80239.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3138231730993449825</td>\n",
              "      <td>1087005562675741887</td>\n",
              "      <td>6</td>\n",
              "      <td>2022-09-06</td>\n",
              "      <td>2022-09-01</td>\n",
              "      <td>3.0</td>\n",
              "      <td>56.625000</td>\n",
              "      <td>56.220001</td>\n",
              "      <td>14.124002</td>\n",
              "      <td>5.250000</td>\n",
              "      <td>...</td>\n",
              "      <td>BUD LIGHT LIME 18/12 CN</td>\n",
              "      <td>Package</td>\n",
              "      <td>Core</td>\n",
              "      <td>Lager</td>\n",
              "      <td>Bud Light Lime</td>\n",
              "      <td>AB Anheuser Busch Inc</td>\n",
              "      <td>3138231730993449825</td>\n",
              "      <td>Off Premise</td>\n",
              "      <td>Package/Liquor</td>\n",
              "      <td>80634.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3681167389484217654</td>\n",
              "      <td>1401422983880045188</td>\n",
              "      <td>5</td>\n",
              "      <td>2022-09-11</td>\n",
              "      <td>2022-09-01</td>\n",
              "      <td>129.0</td>\n",
              "      <td>1037.160023</td>\n",
              "      <td>1037.160023</td>\n",
              "      <td>156.348026</td>\n",
              "      <td>479.880006</td>\n",
              "      <td>...</td>\n",
              "      <td>99 BUTTERSCOTCH 12/10/50ML 99PF</td>\n",
              "      <td>Allocated Spirits</td>\n",
              "      <td>None</td>\n",
              "      <td>Liqueurs &amp; Cordials</td>\n",
              "      <td>99 Butterscotch</td>\n",
              "      <td>Sazerac Spirits</td>\n",
              "      <td>3681167389484217654</td>\n",
              "      <td>Off Premise</td>\n",
              "      <td>Package/Liquor</td>\n",
              "      <td>80226.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7762413312337359369</td>\n",
              "      <td>6614994347738381720</td>\n",
              "      <td>4</td>\n",
              "      <td>2022-02-18</td>\n",
              "      <td>2022-02-01</td>\n",
              "      <td>1.0</td>\n",
              "      <td>26.230000</td>\n",
              "      <td>23.950241</td>\n",
              "      <td>6.550241</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>NB VOODOO RANGER IMPERIAL IPA 15/19.2 CN</td>\n",
              "      <td>Package</td>\n",
              "      <td>Core</td>\n",
              "      <td>IPA</td>\n",
              "      <td>New Belgium Voodoo Ranger Imperial IPA</td>\n",
              "      <td>NB New Belgium</td>\n",
              "      <td>7762413312337359369</td>\n",
              "      <td>Off Premise</td>\n",
              "      <td>Convenience</td>\n",
              "      <td>30096.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows √ó 28 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     internal_store_id  internal_product_id distributor_id transaction_date  \\\n",
              "0  7384367747233276219   328903483604537190              9       2022-07-13   \n",
              "1  3536908514005606262  5418855670645487653              5       2022-03-21   \n",
              "2  3138231730993449825  1087005562675741887              6       2022-09-06   \n",
              "3  3681167389484217654  1401422983880045188              5       2022-09-11   \n",
              "4  7762413312337359369  6614994347738381720              4       2022-02-18   \n",
              "\n",
              "  reference_date  quantity  gross_value    net_value  gross_profit  \\\n",
              "0     2022-07-01       1.0    38.125000    37.890625     10.042625   \n",
              "1     2022-03-01       6.0   107.250000   106.440002     24.732002   \n",
              "2     2022-09-01       3.0    56.625000    56.220001     14.124002   \n",
              "3     2022-09-01     129.0  1037.160023  1037.160023    156.348026   \n",
              "4     2022-02-01       1.0    26.230000    23.950241      6.550241   \n",
              "\n",
              "     discount  ...                                 descricao  \\\n",
              "0    3.950000  ...          BUD LIGHT CHELADA FUEGO 15/25 CN   \n",
              "1   17.100000  ...                   MICHELOB ULTRA 18/12 CN   \n",
              "2    5.250000  ...                   BUD LIGHT LIME 18/12 CN   \n",
              "3  479.880006  ...           99 BUTTERSCOTCH 12/10/50ML 99PF   \n",
              "4    0.000000  ...  NB VOODOO RANGER IMPERIAL IPA 15/19.2 CN   \n",
              "\n",
              "               tipos  label         subcategoria  \\\n",
              "0            Package   Core            Specialty   \n",
              "1            Package   Core                Lager   \n",
              "2            Package   Core                Lager   \n",
              "3  Allocated Spirits   None  Liqueurs & Cordials   \n",
              "4            Package   Core                  IPA   \n",
              "\n",
              "                                    marca             fabricante  \\\n",
              "0                 Bud Light Chelada Fuego  AB Anheuser Busch Inc   \n",
              "1                          Michelob Ultra  AB Anheuser Busch Inc   \n",
              "2                          Bud Light Lime  AB Anheuser Busch Inc   \n",
              "3                         99 Butterscotch        Sazerac Spirits   \n",
              "4  New Belgium Voodoo Ranger Imperial IPA         NB New Belgium   \n",
              "\n",
              "                   pdv      premise   categoria_pdv  zipcode  \n",
              "0  7384367747233276219  Off Premise  Package/Liquor  80905.0  \n",
              "1  3536908514005606262  Off Premise  Package/Liquor  80239.0  \n",
              "2  3138231730993449825  Off Premise  Package/Liquor  80634.0  \n",
              "3  3681167389484217654  Off Premise  Package/Liquor  80226.0  \n",
              "4  7762413312337359369  Off Premise     Convenience  30096.0  \n",
              "\n",
              "[5 rows x 28 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# --- PASSO 1: JUNTAR OS DATAFRAMES (MERGE) ---\n",
        "\n",
        "print(\"Iniciando a jun√ß√£o das tabelas...\")\n",
        "\n",
        "# 1. Juntamos as transa√ß√µes com os dados dos produtos\n",
        "# A conex√£o √© feita usando 'internal_product_id' e 'produto' como chaves.\n",
        "df_merged = pd.merge(\n",
        "    df_transactions, \n",
        "    df_products,\n",
        "    left_on='internal_product_id',\n",
        "    right_on='produto',\n",
        "    how='left'  # 'how=left' garante que todas as transa√ß√µes sejam mantidas.\n",
        ")\n",
        "\n",
        "print(f\"Ap√≥s juntar com produtos, a tabela tem {df_merged.shape[1]} colunas.\")\n",
        "\n",
        "\n",
        "# 2. Agora, juntamos o resultado anterior com os dados das lojas (PDV)\n",
        "# A conex√£o √© feita usando 'internal_store_id' e 'pdv' como chaves.\n",
        "df_merged = pd.merge(\n",
        "    df_merged,\n",
        "    df_pdv,\n",
        "    left_on='internal_store_id',\n",
        "    right_on='pdv',\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "print(f\"Ap√≥s juntar com as lojas, a tabela final tem {df_merged.shape[1]} colunas.\")\n",
        "\n",
        "\n",
        "# --- VERIFICA√á√ÉO ---\n",
        "print(\"\\\\nJun√ß√£o conclu√≠da! Vamos verificar o resultado:\")\n",
        "\n",
        "# O n√∫mero de linhas deve ser o mesmo da tabela de transa√ß√µes original\n",
        "print(f\"Shape da tabela original de transa√ß√µes: {df_transactions.shape}\")\n",
        "print(f\"Shape da tabela final combinada:      {df_merged.shape}\")\n",
        "\n",
        "# Verifique que a tabela agora tem colunas das 3 tabelas originais\n",
        "print(\"\\\\nExemplo da tabela combinada (note as colunas 'marca', 'categoria', 'premise', etc.):\")\n",
        "display(df_merged.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "fb944e4f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tipo de dado da coluna 'transaction_date':\n",
            "datetime64[ns]\n"
          ]
        }
      ],
      "source": [
        "# Vamos verificar o tipo de dado (dtype) da coluna transaction_date\n",
        "print(\"Tipo de dado da coluna 'transaction_date':\")\n",
        "print(df_merged['transaction_date'].dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "19a83415",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iniciando diagn√≥stico do dataframe 'df_merged'...\n",
            "==================================================\\n\n",
            "--- 1. Contagem de Valores Nulos por Coluna ---\n",
            "label            526953\n",
            "subcategoria      10312\n",
            "pdv               45582\n",
            "premise           45582\n",
            "categoria_pdv     45582\n",
            "zipcode           45582\n",
            "dtype: int64\n",
            "\\n\n",
            "--- 2. Informa√ß√µes Gerais e Tipos de Dados ---\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6560698 entries, 0 to 6560697\n",
            "Data columns (total 28 columns):\n",
            " #   Column               Dtype         \n",
            "---  ------               -----         \n",
            " 0   internal_store_id    object        \n",
            " 1   internal_product_id  object        \n",
            " 2   distributor_id       object        \n",
            " 3   transaction_date     datetime64[ns]\n",
            " 4   reference_date       datetime64[ns]\n",
            " 5   quantity             float64       \n",
            " 6   gross_value          float64       \n",
            " 7   net_value            float64       \n",
            " 8   gross_profit         float64       \n",
            " 9   discount             float64       \n",
            " 10  taxes                float64       \n",
            " 11  year                 int32         \n",
            " 12  month                int32         \n",
            " 13  day                  int32         \n",
            " 14  weekday              object        \n",
            " 15  week                 UInt32        \n",
            " 16  produto              object        \n",
            " 17  categoria            object        \n",
            " 18  descricao            object        \n",
            " 19  tipos                object        \n",
            " 20  label                object        \n",
            " 21  subcategoria         object        \n",
            " 22  marca                object        \n",
            " 23  fabricante           object        \n",
            " 24  pdv                  object        \n",
            " 25  premise              object        \n",
            " 26  categoria_pdv        object        \n",
            " 27  zipcode              float64       \n",
            "dtypes: UInt32(1), datetime64[ns](2), float64(7), int32(3), object(15)\n",
            "memory usage: 1.3+ GB\n",
            "\\n\n",
            "--- 3. Resumo Estat√≠stico das Colunas Num√©ricas ---\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>quantity</th>\n",
              "      <th>gross_value</th>\n",
              "      <th>net_value</th>\n",
              "      <th>gross_profit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>6.560698e+06</td>\n",
              "      <td>6.560698e+06</td>\n",
              "      <td>6.560698e+06</td>\n",
              "      <td>6.560698e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>8.125893e+00</td>\n",
              "      <td>1.227512e+02</td>\n",
              "      <td>1.191233e+02</td>\n",
              "      <td>2.193092e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>8.049387e+01</td>\n",
              "      <td>8.664265e+02</td>\n",
              "      <td>8.651757e+02</td>\n",
              "      <td>2.326470e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-1.530000e+03</td>\n",
              "      <td>-4.267290e+04</td>\n",
              "      <td>-3.984800e+04</td>\n",
              "      <td>-2.743960e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>2.803500e+01</td>\n",
              "      <td>2.711032e+01</td>\n",
              "      <td>7.140242e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>4.210000e+01</td>\n",
              "      <td>4.077048e+01</td>\n",
              "      <td>1.051024e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>4.000000e+00</td>\n",
              "      <td>9.200000e+01</td>\n",
              "      <td>8.787900e+01</td>\n",
              "      <td>2.173200e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>9.423000e+04</td>\n",
              "      <td>6.041739e+05</td>\n",
              "      <td>6.041739e+05</td>\n",
              "      <td>2.744160e+05</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           quantity   gross_value     net_value  gross_profit\n",
              "count  6.560698e+06  6.560698e+06  6.560698e+06  6.560698e+06\n",
              "mean   8.125893e+00  1.227512e+02  1.191233e+02  2.193092e+01\n",
              "std    8.049387e+01  8.664265e+02  8.651757e+02  2.326470e+02\n",
              "min   -1.530000e+03 -4.267290e+04 -3.984800e+04 -2.743960e+05\n",
              "25%    1.000000e+00  2.803500e+01  2.711032e+01  7.140242e+00\n",
              "50%    2.000000e+00  4.210000e+01  4.077048e+01  1.051024e+01\n",
              "75%    4.000000e+00  9.200000e+01  8.787900e+01  2.173200e+01\n",
              "max    9.423000e+04  6.041739e+05  6.041739e+05  2.744160e+05"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# --- PASSO DE DIAGN√ìSTICO: INVESTIGAR A SA√öDE DOS DADOS ---\n",
        "\n",
        "print(\"Iniciando diagn√≥stico do dataframe 'df_merged'...\")\n",
        "print(\"=\"*50 + \"\\\\n\")\n",
        "\n",
        "\n",
        "# --- Diagn√≥stico 1: Valores Nulos (Buracos nos dados) ---\n",
        "# Vamos contar quantos valores nulos (NaN) existem em cada coluna.\n",
        "print(\"--- 1. Contagem de Valores Nulos por Coluna ---\")\n",
        "missing_values = df_merged.isnull().sum()\n",
        "print(missing_values[missing_values > 0]) # Mostra apenas as colunas que T√äM valores nulos\n",
        "print(\"\\\\n\")\n",
        "\n",
        "\n",
        "# --- Diagn√≥stico 2: Tipos de Dados ---\n",
        "# Vamos verificar se o pandas entendeu cada coluna corretamente (ex: data √© data, n√∫mero √© n√∫mero).\n",
        "print(\"--- 2. Informa√ß√µes Gerais e Tipos de Dados ---\")\n",
        "# O .info() nos d√° um resumo completo, incluindo o tipo (Dtype) e a contagem de valores n√£o-nulos.\n",
        "df_merged.info()\n",
        "print(\"\\\\n\")\n",
        "\n",
        "\n",
        "# --- Diagn√≥stico 3: Estat√≠sticas de Colunas Num√©ricas ---\n",
        "# Vamos olhar um resumo estat√≠stico das colunas com n√∫meros.\n",
        "# Isso ajuda a encontrar coisas estranhas, como valores negativos ou absurdamente altos.\n",
        "print(\"--- 3. Resumo Estat√≠stico das Colunas Num√©ricas ---\")\n",
        "# O .describe() mostra contagem, m√©dia, desvio padr√£o, m√≠nimo, m√°ximo, etc.\n",
        "display(df_merged[['quantity', 'gross_value', 'net_value', 'gross_profit']].describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "9ee92c55",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iniciando diagn√≥stico preciso do dataframe 'df_merged'...\n",
            "==================================================\\n\n",
            "--- 4. Verifica√ß√£o de Linhas Duplicadas ---\n",
            "N√∫mero de linhas completamente duplicadas encontradas: 0\n",
            "\\n\n",
            "--- 5. An√°lise de Conte√∫do (Valores Mais Comuns) ---\n",
            "\\n--- Categoria do Produto ('categoria') ---\n",
            "categoria\n",
            "Package              4625080\n",
            "Non-Alcohol           955097\n",
            "Distilled Spirits     611285\n",
            "Draft                 192300\n",
            "Wine                  124232\n",
            "ABA Spirits            52274\n",
            "Tobacco                  430\n",
            "Name: count, dtype: int64\n",
            "------------------------------\n",
            "\\n--- Tipo de Loja ('premise') ---\n",
            "premise\n",
            "Off Premise    5823678\n",
            "On Premise      691438\n",
            "NaN              45582\n",
            "Name: count, dtype: int64\n",
            "------------------------------\n",
            "\\n--- Categoria da Loja ('categoria_pdv') ---\n",
            "categoria_pdv\n",
            "Convenience         2126380\n",
            "Package/Liquor      2016477\n",
            "Grocery             1276042\n",
            "Super Center         365825\n",
            "Restaurant           261861\n",
            "Bar                  192643\n",
            "NaN                   45582\n",
            "Mexican Rest          43712\n",
            "Hotel/Motel           20827\n",
            "Golf - Public         19807\n",
            "Drug                  19159\n",
            "Service Org           17230\n",
            "Pizza                 14995\n",
            "Billiard/Bowling      14239\n",
            "Golf - Private        13713\n",
            "Name: count, dtype: int64\n",
            "------------------------------\n"
          ]
        }
      ],
      "source": [
        "# --- DIAGN√ìSTICO MAIS PRECISO ---\n",
        "\n",
        "print(\"Iniciando diagn√≥stico preciso do dataframe 'df_merged'...\")\n",
        "print(\"=\"*50 + \"\\\\n\")\n",
        "\n",
        "\n",
        "# --- Diagn√≥stico 4: An√°lise de Linhas Duplicadas ---\n",
        "# Linhas 100% id√™nticas podem indicar erros de registro e inflar os dados.\n",
        "print(\"--- 4. Verifica√ß√£o de Linhas Duplicadas ---\")\n",
        "num_duplicatas = df_merged.duplicated().sum()\n",
        "print(f\"N√∫mero de linhas completamente duplicadas encontradas: {num_duplicatas:,}\")\n",
        "if num_duplicatas > 0:\n",
        "    # Mostra um exemplo das linhas que s√£o duplicadas\n",
        "    print(\"\\\\nExemplo de linhas duplicadas:\")\n",
        "    display(df_merged[df_merged.duplicated(keep=False)].sort_values(by=list(df_merged.columns)).head(10))\n",
        "print(\"\\\\n\")\n",
        "\n",
        "\n",
        "# --- Diagn√≥stico 5: An√°lise de Conte√∫do das Colunas de Texto ---\n",
        "# O comando .value_counts() √© excelente para isso. Ele conta quantas vezes cada valor aparece.\n",
        "# O `dropna=False` nos ajuda a contar os valores nulos (NaN) tamb√©m.\n",
        "\n",
        "print(\"--- 5. An√°lise de Conte√∫do (Valores Mais Comuns) ---\")\n",
        "\n",
        "print(\"\\\\n--- Categoria do Produto ('categoria') ---\")\n",
        "print(df_merged['categoria'].value_counts(dropna=False).head(10))\n",
        "print(\"-\" * 30)\n",
        "\n",
        "print(\"\\\\n--- Tipo de Loja ('premise') ---\")\n",
        "print(df_merged['premise'].value_counts(dropna=False).head(10))\n",
        "print(\"-\" * 30)\n",
        "\n",
        "print(\"\\\\n--- Categoria da Loja ('categoria_pdv') ---\")\n",
        "print(df_merged['categoria_pdv'].value_counts(dropna=False).head(15)) # Mostrando 15 para ter mais detalhes\n",
        "print(\"-\" * 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "f1200f9d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vamos investigar todos os tipos de loja existentes.\n",
            "No total, encontramos 54 tipos diferentes de lojas.\\n\n",
            "Abaixo est√° a lista completa de todas as categorias de loja e o n√∫mero de transa√ß√µes em cada uma:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "categoria_pdv\n",
              "Convenience                  2126380\n",
              "Package/Liquor               2016477\n",
              "Grocery                      1276042\n",
              "Super Center                  365825\n",
              "Restaurant                    261861\n",
              "Bar                           192643\n",
              "NaN                            45582\n",
              "Mexican Rest                   43712\n",
              "Hotel/Motel                    20827\n",
              "Golf - Public                  19807\n",
              "Drug                           19159\n",
              "Service Org                    17230\n",
              "Pizza                          14995\n",
              "Billiard/Bowling               14239\n",
              "Golf - Private                 13713\n",
              "Sports/Rec Club                11223\n",
              "Italian                         9659\n",
              "Irish                           9213\n",
              "Asian                           7922\n",
              "Other On Premise                7026\n",
              "Stadium/Concession              7021\n",
              "Bodega                          5284\n",
              "Barbeque                        4932\n",
              "Club Store                      4798\n",
              "Military                        4724\n",
              "Church                          4696\n",
              "Airline/Airport                 3699\n",
              "Sample Room                     3358\n",
              "Other Off Premise               3272\n",
              "Night Club                      2993\n",
              "Music Venue                     2877\n",
              "Special Event                   2805\n",
              "Theatre                         2741\n",
              "Adult Entertainment             2623\n",
              "Gay Bar                         2084\n",
              "Banquet/Caterer                 1764\n",
              "Coffee House                    1128\n",
              "All Other N/A On Premise         920\n",
              "Neighborhood Store               876\n",
              "Theme Park                       803\n",
              "All Other N/A Off Premise        683\n",
              "Korean                           632\n",
              "Country/Western                  504\n",
              "Winery                           485\n",
              "French                           351\n",
              "Health Club                      266\n",
              "Race Track                       221\n",
              "Gym/Fitness                      201\n",
              "Sub Distributor                  138\n",
              "Marina / Lake                    121\n",
              "Salon/Spa/Tann                   111\n",
              "Non-Traditional                   18\n",
              "German                            16\n",
              "Casino                            16\n",
              "Mass Merch                         2\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# --- An√°lise Completa da Coluna 'categoria_pdv' ---\n",
        "\n",
        "print(\"Vamos investigar todos os tipos de loja existentes.\")\n",
        "\n",
        "# 1. Contar quantos tipos √∫nicos de loja (PDV) existem no total\n",
        "num_categorias_loja = df_merged['categoria_pdv'].nunique()\n",
        "print(f\"No total, encontramos {num_categorias_loja} tipos diferentes de lojas.\\\\n\")\n",
        "\n",
        "# 2. Mostrar a contagem para CADA tipo de loja, ordenado do mais comum para o menos comum\n",
        "print(\"Abaixo est√° a lista completa de todas as categorias de loja e o n√∫mero de transa√ß√µes em cada uma:\")\n",
        "# O display() do jupyter notebook formata a sa√≠da de forma mais leg√≠vel\n",
        "display(df_merged['categoria_pdv'].value_counts(dropna=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "a834d0d3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iniciando a limpeza com a regra customizada para 'premise'...\n",
            "1. Linhas com quantidade inv√°lida e fora de 2022 removidas.\n",
            "2. Nulos em outras colunas de texto preenchidos.\n",
            "3. Aplicando a regra para deduzir 'premise' a partir de 'categoria_pdv'...\n",
            "4. L√≥gica de dedu√ß√£o para 'premise' aplicada com sucesso!\n",
            "\\nLimpeza e dedu√ß√£o de 'premise' conclu√≠das!\n",
            "\\nContagem de valores na coluna 'premise' ANTES da nossa regra (no df_merged):\n",
            "premise\n",
            "Off Premise    5823678\n",
            "On Premise      691438\n",
            "NaN              45582\n",
            "Name: count, dtype: int64\n",
            "\\nContagem de valores na coluna 'premise' DEPOIS da nossa regra (no df_clean):\n",
            "premise\n",
            "Off Premise    5739410\n",
            "On Premise      684470\n",
            "Unknown           6281\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# --- PASSO 2: LIMPEZA (VERS√ÉO AVAN√áADA COM REGRA PARA 'PREMISE') ---\n",
        "\n",
        "print(\"Iniciando a limpeza com a regra customizada para 'premise'...\")\n",
        "\n",
        "df_clean = df_merged.copy()\n",
        "\n",
        "# A√ß√µes preliminares que j√° t√≠nhamos definido:\n",
        "df_clean = df_clean[df_clean['quantity'] > 0]\n",
        "df_clean = df_clean[df_clean['transaction_date'].dt.year == 2022]\n",
        "print(\"1. Linhas com quantidade inv√°lida e fora de 2022 removidas.\")\n",
        "\n",
        "# Preenche nulos nas outras colunas, mas DEIXA 'premise' em paz por enquanto\n",
        "for col in ['categoria', 'marca', 'categoria_pdv']:\n",
        "    if col in df_clean.columns:\n",
        "        df_clean[col] = df_clean[col].fillna('Unknown')\n",
        "print(\"2. Nulos em outras colunas de texto preenchidos.\")\n",
        "\n",
        "\n",
        "# A√ß√£o principal: Implementar a regra para preencher 'premise'\n",
        "print(\"3. Aplicando a regra para deduzir 'premise' a partir de 'categoria_pdv'...\")\n",
        "\n",
        "# Listas de mapeamento baseadas na nossa an√°lise\n",
        "on_premise_categorias = [\n",
        "    'Restaurant', 'Bar', 'Mexican Rest', 'Hotel/Motel', 'Golf - Public', 'Pizza', \n",
        "    'Billiard/Bowling', 'Golf - Private', 'Sports/Rec Club', 'Italian', 'Irish', \n",
        "    'Asian', 'Stadium/Concession', 'Barbeque', 'German', 'Casino', 'Other On Premise'\n",
        "]\n",
        "off_premise_categorias = [\n",
        "    'Convenience', 'Package/Liquor', 'Grocery', 'Super Center', 'Drug', \n",
        "    'Club Store', 'Bodega', 'Mass Merch'\n",
        "]\n",
        "\n",
        "# Fun√ß√£o que cont√©m a nossa l√≥gica\n",
        "def deduzir_premise(row):\n",
        "    # Se 'premise' j√° tem um valor e n√£o √© nulo, mant√©m ele.\n",
        "    if pd.notna(row['premise']):\n",
        "        return row['premise']\n",
        "    \n",
        "    # Se 'premise' for nulo, tentamos deduzir...\n",
        "    if row['categoria_pdv'] in on_premise_categorias:\n",
        "        return 'On Premise'\n",
        "    elif row['categoria_pdv'] in off_premise_categorias:\n",
        "        return 'Off Premise'\n",
        "    \n",
        "    # Se a categoria da loja tamb√©m for desconhecida ou n√£o estiver no nosso mapa,\n",
        "    # ent√£o n√£o conseguimos deduzir.\n",
        "    else:\n",
        "        return 'Unknown'\n",
        "\n",
        "# O comando .apply executa nossa fun√ß√£o em cada linha do dataframe.\n",
        "# O resultado ser√° salvo na pr√≥pria coluna 'premise'.\n",
        "df_clean['premise'] = df_clean.apply(deduzir_premise, axis=1)\n",
        "print(\"4. L√≥gica de dedu√ß√£o para 'premise' aplicada com sucesso!\")\n",
        "\n",
        "\n",
        "# --- VERIFICA√á√ÉO ---\n",
        "print(\"\\\\nLimpeza e dedu√ß√£o de 'premise' conclu√≠das!\")\n",
        "\n",
        "print(\"\\\\nContagem de valores na coluna 'premise' ANTES da nossa regra (no df_merged):\")\n",
        "print(df_merged['premise'].value_counts(dropna=False))\n",
        "\n",
        "print(\"\\\\nContagem de valores na coluna 'premise' DEPOIS da nossa regra (no df_clean):\")\n",
        "print(df_clean['premise'].value_counts(dropna=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "4bd6e12d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Instalando/Verificando a biblioteca pgeocode...\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Preparando para mapear CEPs para estado e cidade...\n",
            "Mapeando...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\danie\\AppData\\Local\\Temp\\ipykernel_27404\\3386771597.py:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_clean['state'].fillna('Unknown', inplace=True)\n",
            "C:\\Users\\danie\\AppData\\Local\\Temp\\ipykernel_27404\\3386771597.py:28: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_clean['city'].fillna('Unknown', inplace=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\\nMAPEAMENTO CONCLU√çDO!\n",
            "Colunas 'state' e 'city' criadas.\n"
          ]
        }
      ],
      "source": [
        "# --- PASSO 3 (VERS√ÉO FINAL): CRIAR FEATURES DE ESTADO E CIDADE ---\n",
        "\n",
        "print(\"Instalando/Verificando a biblioteca pgeocode...\")\n",
        "%pip install pgeocode -q\n",
        "\n",
        "import pgeocode\n",
        "import pandas as pd\n",
        "\n",
        "print(\"Preparando para mapear CEPs para estado e cidade...\")\n",
        "nomi = pgeocode.Nominatim('us')\n",
        "df_clean['zipcode_str'] = df_clean['zipcode'].astype(str).str.slice(0, 5)\n",
        "\n",
        "print(\"Mapeando...\")\n",
        "zip_codes = df_clean['zipcode_str'].unique()\n",
        "state_info = nomi.query_postal_code(zip_codes)\n",
        "\n",
        "# Dicion√°rio para mapear CEP -> Estado\n",
        "zip_to_state = pd.Series(state_info.state_code.values, index=state_info.postal_code).to_dict()\n",
        "# Dicion√°rio para mapear CEP -> Cidade\n",
        "zip_to_city = pd.Series(state_info.place_name.values, index=state_info.postal_code).to_dict()\n",
        "\n",
        "# Mapear as novas colunas\n",
        "df_clean['state'] = df_clean['zipcode_str'].map(zip_to_state)\n",
        "df_clean['city'] = df_clean['zipcode_str'].map(zip_to_city)\n",
        "\n",
        "# Preencher o que n√£o foi encontrado\n",
        "df_clean['state'].fillna('Unknown', inplace=True)\n",
        "df_clean['city'].fillna('Unknown', inplace=True)\n",
        "\n",
        "print(\"\\\\nMAPEAMENTO CONCLU√çDO!\")\n",
        "print(\"Colunas 'state' e 'city' criadas.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "d0a21575",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filtrando o dataframe para mostrar apenas as linhas onde o estado √© 'Unknown'...\n",
            "Encontramos 21 CEPs √∫nicos que n√£o foram mapeados.\\n\n",
            "Abaixo est√£o os valores √∫nicos da coluna ORIGINAL 'zipcode' que falharam:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([   nan, 30136., 30221., 30211., 30155., 30640., 30245., 30202.,\n",
              "       30201., 30020., 30190., 80039., 90920., 90132.,  8107., 80328.,\n",
              "       80147., 31972., 81153., 80029., 90919.])"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\\nE aqui est√£o esses mesmos valores depois da nossa limpeza para 5 d√≠gitos ('zipcode_str'):\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array(['nan', '30136', '30221', '30211', '30155', '30640', '30245',\n",
              "       '30202', '30201', '30020', '30190', '80039', '90920', '90132',\n",
              "       '8107.', '80328', '80147', '31972', '81153', '80029', '90919'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# --- Investigando os CEPs n√£o encontrados ---\n",
        "\n",
        "print(\"Filtrando o dataframe para mostrar apenas as linhas onde o estado √© 'Unknown'...\")\n",
        "\n",
        "# Cria um novo dataframe apenas com as linhas problem√°ticas\n",
        "ceps_problematicos_df = df_clean[df_clean['state'] == 'Unknown']\n",
        "\n",
        "print(f\"Encontramos {len(ceps_problematicos_df['zipcode'].unique())} CEPs √∫nicos que n√£o foram mapeados.\\\\n\")\n",
        "\n",
        "print(\"Abaixo est√£o os valores √∫nicos da coluna ORIGINAL 'zipcode' que falharam:\")\n",
        "# O .unique() nos mostra todos os valores diferentes que existem na coluna\n",
        "display(ceps_problematicos_df['zipcode'].unique())\n",
        "\n",
        "print(\"\\\\nE aqui est√£o esses mesmos valores depois da nossa limpeza para 5 d√≠gitos ('zipcode_str'):\")\n",
        "display(ceps_problematicos_df['zipcode_str'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "020d548b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- PASSO 3.1: CORRE√á√ÉO MANUAL DE ESTADO E CIDADE ---\n",
        "print(\"Aplicando corre√ß√£o manual para estado e cidade...\")\n",
        "\n",
        "correction_map = {\n",
        "    '30221': {'state': 'GA', 'city': 'Grayson'},\n",
        "    '30211': {'state': 'GA', 'city': 'Dacula'},\n",
        "    '30245': {'state': 'GA', 'city': 'Lawrenceville'},\n",
        "    '30020': {'state': 'GA', 'city': 'Clarkdale'},\n",
        "    '90132': {'state': 'CA', 'city': 'Los Angeles'},\n",
        "    '80328': {'state': 'CO', 'city': 'Boulder'},\n",
        "    '81153': {'state': 'CO', 'city': 'San Pablo'}\n",
        "}\n",
        "\n",
        "def corrigir_local(row):\n",
        "    if row['zipcode_str'] in correction_map:\n",
        "        # Pega os dados do nosso mapa de corre√ß√£o\n",
        "        info = correction_map[row['zipcode_str']]\n",
        "        row['state'] = info.get('state', 'Unknown')\n",
        "        row['city'] = info.get('city', 'Unknown')\n",
        "    return row\n",
        "\n",
        "df_clean = df_clean.apply(corrigir_local, axis=1)\n",
        "\n",
        "print(\"Corre√ß√£o manual conclu√≠da!\")\n",
        "print(\"\\\\nContagem de 'Unknown' em 'state' ap√≥s corre√ß√£o:\")\n",
        "print(df_clean['state'].value_counts().get('Unknown', 0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "2acfb567",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Aplicando corre√ß√£o manual para estado e cidade...\n",
            "N√∫mero de 'Unknowns' antes da corre√ß√£o: 24165\n",
            "\\nCorre√ß√£o manual conclu√≠da!\n",
            "N√∫mero de 'Unknowns' DEPOIS da corre√ß√£o: 17592\n",
            "\\nExemplo de uma das corre√ß√µes feitas:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>zipcode_str</th>\n",
              "      <th>state</th>\n",
              "      <th>city</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3650</th>\n",
              "      <td>30221</td>\n",
              "      <td>GA</td>\n",
              "      <td>Grayson</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     zipcode_str state     city\n",
              "3650       30221    GA  Grayson"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# --- PASSO 3.1 (VERS√ÉO REVISADA E CORRIGIDA) ---\n",
        "\n",
        "print(\"Aplicando corre√ß√£o manual para estado e cidade...\")\n",
        "\n",
        "# 1. Dicion√°rio de corre√ß√£o (com a chave 'state' corrigida para 81153)\n",
        "correction_map = {\n",
        "    '30221': {'state': 'GA', 'city': 'Grayson'},\n",
        "    '30211': {'state': 'GA', 'city': 'Dacula'},\n",
        "    '30245': {'state': 'GA', 'city': 'Lawrenceville'},\n",
        "    '30020': {'state': 'GA', 'city': 'Clarkdale'},\n",
        "    '90132': {'state': 'CA', 'city': 'Los Angeles'},\n",
        "    '80328': {'state': 'CO', 'city': 'Boulder'},\n",
        "    '81153': {'state': 'CO', 'city': 'San Pablo'}  # Erro corrigido aqui\n",
        "}\n",
        "\n",
        "# 2. Contar 'Unknowns' ANTES da corre√ß√£o para podermos comparar\n",
        "unknowns_antes = df_clean['state'].value_counts().get('Unknown', 0)\n",
        "print(f\"N√∫mero de 'Unknowns' antes da corre√ß√£o: {unknowns_antes}\")\n",
        "\n",
        "# 3. Iterar pelo mapa e aplicar as corre√ß√µes de forma segura usando .loc\n",
        "# .loc √© uma forma eficiente de selecionar e alterar dados espec√≠ficos\n",
        "for zip_code, info in correction_map.items():\n",
        "    # Criamos uma \"m√°scara\" para encontrar as linhas exatas que queremos alterar:\n",
        "    # Onde o CEP √© o que queremos corrigir E o estado atual √© 'Unknown'\n",
        "    mask = (df_clean['zipcode_str'] == zip_code) & (df_clean['state'] == 'Unknown')\n",
        "    \n",
        "    # Usamos a m√°scara para atualizar 'state' e 'city' apenas nessas linhas\n",
        "    df_clean.loc[mask, 'state'] = info['state']\n",
        "    df_clean.loc[mask, 'city'] = info['city']\n",
        "\n",
        "# --- VERIFICA√á√ÉO ---\n",
        "print(\"\\\\nCorre√ß√£o manual conclu√≠da!\")\n",
        "unknowns_depois = df_clean['state'].value_counts().get('Unknown', 0)\n",
        "print(f\"N√∫mero de 'Unknowns' DEPOIS da corre√ß√£o: {unknowns_depois}\")\n",
        "\n",
        "# Verificando se a cidade tamb√©m foi preenchida\n",
        "print(\"\\\\nExemplo de uma das corre√ß√µes feitas:\")\n",
        "display(df_clean[df_clean['zipcode_str'] == '30221'][['zipcode_str', 'state', 'city']].head(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "a1ec5604",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iniciando agrega√ß√£o de dados por semana (incluindo estado e cidade)...\n",
            "\\nAgrega√ß√£o conclu√≠da! De 6,430,161 transa√ß√µes, criamos 6,140,206 linhas de dados semanais.\n",
            "Cada linha agora representa o total vendido de um produto em uma loja/cidade em uma semana.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>week</th>\n",
              "      <th>internal_store_id</th>\n",
              "      <th>internal_product_id</th>\n",
              "      <th>categoria</th>\n",
              "      <th>marca</th>\n",
              "      <th>premise</th>\n",
              "      <th>categoria_pdv</th>\n",
              "      <th>state</th>\n",
              "      <th>city</th>\n",
              "      <th>total_quantity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1001371918471115422</td>\n",
              "      <td>1029370090212151375</td>\n",
              "      <td>Package</td>\n",
              "      <td>Michelob Ultra</td>\n",
              "      <td>Off Premise</td>\n",
              "      <td>Convenience</td>\n",
              "      <td>GA</td>\n",
              "      <td>Talking Rock</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1001371918471115422</td>\n",
              "      <td>1120490062981954254</td>\n",
              "      <td>Package</td>\n",
              "      <td>Bud Light</td>\n",
              "      <td>Off Premise</td>\n",
              "      <td>Convenience</td>\n",
              "      <td>GA</td>\n",
              "      <td>Talking Rock</td>\n",
              "      <td>18.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1001371918471115422</td>\n",
              "      <td>2239307647969388381</td>\n",
              "      <td>Package</td>\n",
              "      <td>Natural Light</td>\n",
              "      <td>Off Premise</td>\n",
              "      <td>Convenience</td>\n",
              "      <td>GA</td>\n",
              "      <td>Talking Rock</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1001371918471115422</td>\n",
              "      <td>4353552881410365573</td>\n",
              "      <td>Package</td>\n",
              "      <td>Natural Light</td>\n",
              "      <td>Off Premise</td>\n",
              "      <td>Convenience</td>\n",
              "      <td>GA</td>\n",
              "      <td>Talking Rock</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1001371918471115422</td>\n",
              "      <td>4797439216678436447</td>\n",
              "      <td>Package</td>\n",
              "      <td>Bud Light Lime</td>\n",
              "      <td>Off Premise</td>\n",
              "      <td>Convenience</td>\n",
              "      <td>GA</td>\n",
              "      <td>Talking Rock</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   week    internal_store_id  internal_product_id categoria           marca  \\\n",
              "0     1  1001371918471115422  1029370090212151375   Package  Michelob Ultra   \n",
              "1     1  1001371918471115422  1120490062981954254   Package       Bud Light   \n",
              "2     1  1001371918471115422  2239307647969388381   Package   Natural Light   \n",
              "3     1  1001371918471115422  4353552881410365573   Package   Natural Light   \n",
              "4     1  1001371918471115422  4797439216678436447   Package  Bud Light Lime   \n",
              "\n",
              "       premise categoria_pdv state          city  total_quantity  \n",
              "0  Off Premise   Convenience    GA  Talking Rock             3.0  \n",
              "1  Off Premise   Convenience    GA  Talking Rock            18.0  \n",
              "2  Off Premise   Convenience    GA  Talking Rock             2.0  \n",
              "3  Off Premise   Convenience    GA  Talking Rock             7.0  \n",
              "4  Off Premise   Convenience    GA  Talking Rock             1.0  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# --- PASSO 4: AGREGA√á√ÉO SEMANAL COM CIDADE ---\n",
        "\n",
        "print(\"Iniciando agrega√ß√£o de dados por semana (incluindo estado e cidade)...\")\n",
        "\n",
        "# Cria a coluna 'week' para podermos agrupar por ela\n",
        "df_clean['week'] = df_clean['transaction_date'].dt.isocalendar().week\n",
        "\n",
        "# Define todas as colunas que queremos manter ap√≥s o agrupamento.\n",
        "# Note que 'state' e 'city' est√£o na lista.\n",
        "grouping_keys = [\n",
        "    'week', \n",
        "    'internal_store_id', \n",
        "    'internal_product_id', \n",
        "    'categoria', \n",
        "    'marca', \n",
        "    'premise', \n",
        "    'categoria_pdv',\n",
        "    'state',\n",
        "    'city'\n",
        "]\n",
        "\n",
        "# Agrupa os dados usando as chaves definidas e soma a quantidade de vendas para cada grupo\n",
        "weekly_data = df_clean.groupby(grouping_keys).agg(\n",
        "    total_quantity=('quantity', 'sum')\n",
        ").reset_index()\n",
        "\n",
        "\n",
        "# --- VERIFICA√á√ÉO ---\n",
        "print(f\"\\\\nAgrega√ß√£o conclu√≠da! De {len(df_clean):,} transa√ß√µes, criamos {len(weekly_data):,} linhas de dados semanais.\")\n",
        "print(\"Cada linha agora representa o total vendido de um produto em uma loja/cidade em uma semana.\")\n",
        "display(weekly_data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "e19a0121",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Criando features de lag e m√©dia m√≥vel no 'weekly_data'...\n",
            "\\nCria√ß√£o de features conclu√≠da!\n",
            "Nosso dataset est√° 100% pronto para o treinamento do modelo.\n",
            "Note as novas colunas 'quantity_lag_...' e 'quantity_rolling_avg_...':\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>week</th>\n",
              "      <th>internal_store_id</th>\n",
              "      <th>internal_product_id</th>\n",
              "      <th>categoria</th>\n",
              "      <th>marca</th>\n",
              "      <th>premise</th>\n",
              "      <th>categoria_pdv</th>\n",
              "      <th>state</th>\n",
              "      <th>city</th>\n",
              "      <th>total_quantity</th>\n",
              "      <th>quantity_lag_1</th>\n",
              "      <th>quantity_lag_2</th>\n",
              "      <th>quantity_lag_3</th>\n",
              "      <th>quantity_lag_4</th>\n",
              "      <th>quantity_rolling_avg_2</th>\n",
              "      <th>quantity_rolling_avg_4</th>\n",
              "      <th>quantity_rolling_avg_8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>433888</th>\n",
              "      <td>6</td>\n",
              "      <td>1000237487041964405</td>\n",
              "      <td>1837429607327399565</td>\n",
              "      <td>Package</td>\n",
              "      <td>Fire Maker Perfect Match IPA</td>\n",
              "      <td>On Premise</td>\n",
              "      <td>Winery</td>\n",
              "      <td>GA</td>\n",
              "      <td>Talking Rock</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>529002</th>\n",
              "      <td>7</td>\n",
              "      <td>1000237487041964405</td>\n",
              "      <td>1837429607327399565</td>\n",
              "      <td>Package</td>\n",
              "      <td>Fire Maker Perfect Match IPA</td>\n",
              "      <td>On Premise</td>\n",
              "      <td>Winery</td>\n",
              "      <td>GA</td>\n",
              "      <td>Talking Rock</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2042472</th>\n",
              "      <td>21</td>\n",
              "      <td>1000237487041964405</td>\n",
              "      <td>1837429607327399565</td>\n",
              "      <td>Package</td>\n",
              "      <td>Fire Maker Perfect Match IPA</td>\n",
              "      <td>On Premise</td>\n",
              "      <td>Winery</td>\n",
              "      <td>GA</td>\n",
              "      <td>Talking Rock</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>1.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2521528</th>\n",
              "      <td>25</td>\n",
              "      <td>1000237487041964405</td>\n",
              "      <td>1837429607327399565</td>\n",
              "      <td>Package</td>\n",
              "      <td>Fire Maker Perfect Match IPA</td>\n",
              "      <td>On Premise</td>\n",
              "      <td>Winery</td>\n",
              "      <td>GA</td>\n",
              "      <td>Talking Rock</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1.333333</td>\n",
              "      <td>1.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2891177</th>\n",
              "      <td>28</td>\n",
              "      <td>1000237487041964405</td>\n",
              "      <td>1837429607327399565</td>\n",
              "      <td>Package</td>\n",
              "      <td>Fire Maker Perfect Match IPA</td>\n",
              "      <td>On Premise</td>\n",
              "      <td>Winery</td>\n",
              "      <td>GA</td>\n",
              "      <td>Talking Rock</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>1.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3599754</th>\n",
              "      <td>34</td>\n",
              "      <td>1000237487041964405</td>\n",
              "      <td>1837429607327399565</td>\n",
              "      <td>Package</td>\n",
              "      <td>Fire Maker Perfect Match IPA</td>\n",
              "      <td>On Premise</td>\n",
              "      <td>Winery</td>\n",
              "      <td>GA</td>\n",
              "      <td>Talking Rock</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.750000</td>\n",
              "      <td>1.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4481600</th>\n",
              "      <td>39</td>\n",
              "      <td>1000237487041964405</td>\n",
              "      <td>1837429607327399565</td>\n",
              "      <td>Package</td>\n",
              "      <td>Fire Maker Perfect Match IPA</td>\n",
              "      <td>On Premise</td>\n",
              "      <td>Winery</td>\n",
              "      <td>GA</td>\n",
              "      <td>Talking Rock</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.750000</td>\n",
              "      <td>1.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5321037</th>\n",
              "      <td>46</td>\n",
              "      <td>1000237487041964405</td>\n",
              "      <td>1837429607327399565</td>\n",
              "      <td>Package</td>\n",
              "      <td>Fire Maker Perfect Match IPA</td>\n",
              "      <td>On Premise</td>\n",
              "      <td>Winery</td>\n",
              "      <td>GA</td>\n",
              "      <td>Talking Rock</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1.750000</td>\n",
              "      <td>1.571429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1565795</th>\n",
              "      <td>17</td>\n",
              "      <td>1000237487041964405</td>\n",
              "      <td>4038588102284338370</td>\n",
              "      <td>Package</td>\n",
              "      <td>Jekyll Cooter Brown</td>\n",
              "      <td>On Premise</td>\n",
              "      <td>Winery</td>\n",
              "      <td>GA</td>\n",
              "      <td>Talking Rock</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.666667</td>\n",
              "      <td>1.571429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>433889</th>\n",
              "      <td>6</td>\n",
              "      <td>1000237487041964405</td>\n",
              "      <td>5429216175252037173</td>\n",
              "      <td>Package</td>\n",
              "      <td>Jekyll Southern Juice IPA</td>\n",
              "      <td>On Premise</td>\n",
              "      <td>Winery</td>\n",
              "      <td>GA</td>\n",
              "      <td>Talking Rock</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>1.666667</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         week    internal_store_id  internal_product_id categoria  \\\n",
              "433888      6  1000237487041964405  1837429607327399565   Package   \n",
              "529002      7  1000237487041964405  1837429607327399565   Package   \n",
              "2042472    21  1000237487041964405  1837429607327399565   Package   \n",
              "2521528    25  1000237487041964405  1837429607327399565   Package   \n",
              "2891177    28  1000237487041964405  1837429607327399565   Package   \n",
              "3599754    34  1000237487041964405  1837429607327399565   Package   \n",
              "4481600    39  1000237487041964405  1837429607327399565   Package   \n",
              "5321037    46  1000237487041964405  1837429607327399565   Package   \n",
              "1565795    17  1000237487041964405  4038588102284338370   Package   \n",
              "433889      6  1000237487041964405  5429216175252037173   Package   \n",
              "\n",
              "                                marca     premise categoria_pdv state  \\\n",
              "433888   Fire Maker Perfect Match IPA  On Premise        Winery    GA   \n",
              "529002   Fire Maker Perfect Match IPA  On Premise        Winery    GA   \n",
              "2042472  Fire Maker Perfect Match IPA  On Premise        Winery    GA   \n",
              "2521528  Fire Maker Perfect Match IPA  On Premise        Winery    GA   \n",
              "2891177  Fire Maker Perfect Match IPA  On Premise        Winery    GA   \n",
              "3599754  Fire Maker Perfect Match IPA  On Premise        Winery    GA   \n",
              "4481600  Fire Maker Perfect Match IPA  On Premise        Winery    GA   \n",
              "5321037  Fire Maker Perfect Match IPA  On Premise        Winery    GA   \n",
              "1565795           Jekyll Cooter Brown  On Premise        Winery    GA   \n",
              "433889      Jekyll Southern Juice IPA  On Premise        Winery    GA   \n",
              "\n",
              "                 city  total_quantity  quantity_lag_1  quantity_lag_2  \\\n",
              "433888   Talking Rock             1.0             0.0             0.0   \n",
              "529002   Talking Rock             2.0             1.0             0.0   \n",
              "2042472  Talking Rock             1.0             2.0             1.0   \n",
              "2521528  Talking Rock             2.0             1.0             2.0   \n",
              "2891177  Talking Rock             2.0             2.0             1.0   \n",
              "3599754  Talking Rock             2.0             2.0             2.0   \n",
              "4481600  Talking Rock             1.0             2.0             2.0   \n",
              "5321037  Talking Rock             2.0             1.0             2.0   \n",
              "1565795  Talking Rock             1.0             0.0             0.0   \n",
              "433889   Talking Rock             2.0             0.0             0.0   \n",
              "\n",
              "         quantity_lag_3  quantity_lag_4  quantity_rolling_avg_2  \\\n",
              "433888              0.0             0.0                     0.0   \n",
              "529002              0.0             0.0                     1.0   \n",
              "2042472             0.0             0.0                     1.5   \n",
              "2521528             1.0             0.0                     1.5   \n",
              "2891177             2.0             1.0                     1.5   \n",
              "3599754             1.0             2.0                     2.0   \n",
              "4481600             2.0             1.0                     2.0   \n",
              "5321037             2.0             2.0                     1.5   \n",
              "1565795             0.0             0.0                     1.0   \n",
              "433889              0.0             0.0                     0.0   \n",
              "\n",
              "         quantity_rolling_avg_4  quantity_rolling_avg_8  \n",
              "433888                 0.000000                0.000000  \n",
              "529002                 1.000000                1.000000  \n",
              "2042472                1.500000                1.500000  \n",
              "2521528                1.333333                1.333333  \n",
              "2891177                1.500000                1.500000  \n",
              "3599754                1.750000                1.600000  \n",
              "4481600                1.750000                1.666667  \n",
              "5321037                1.750000                1.571429  \n",
              "1565795                1.666667                1.571429  \n",
              "433889                 1.500000                1.666667  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# --- PASSO 5: CRIA√á√ÉO DE FEATURES DE S√âRIES TEMPORAIS ---\n",
        "\n",
        "print(\"Criando features de lag e m√©dia m√≥vel no 'weekly_data'...\")\n",
        "\n",
        "# 1. Ordenar os dados √© crucial para que a sequ√™ncia de semanas esteja correta para cada produto\n",
        "weekly_data = weekly_data.sort_values(by=['internal_store_id', 'internal_product_id', 'week'])\n",
        "\n",
        "# 2. Criar \"Lag Features\": a venda da semana passada, retrasada, etc.\n",
        "# O groupby garante que o .shift() seja calculado para cada produto/loja separadamente, sem misturar os hist√≥ricos.\n",
        "for lag in [1, 2, 3, 4]:\n",
        "    weekly_data[f'quantity_lag_{lag}'] = weekly_data.groupby(['internal_store_id', 'internal_product_id'])['total_quantity'].shift(lag)\n",
        "\n",
        "# 3. Criar \"Rolling Features\": a m√©dia de vendas das √∫ltimas semanas.\n",
        "# Isso ajuda a suavizar ru√≠dos e capturar tend√™ncias. Usamos .shift(1) para n√£o usar a venda da semana atual no c√°lculo da m√©dia do passado.\n",
        "for window in [2, 4, 8]:\n",
        "    weekly_data[f'quantity_rolling_avg_{window}'] = weekly_data.groupby(['internal_store_id', 'internal_product_id'])['total_quantity'].shift(1).rolling(window=window, min_periods=1).mean()\n",
        "\n",
        "# 4. Preencher os valores nulos (NaN) que foram criados com zero.\n",
        "# Isso acontece nas primeiras semanas do hist√≥rico de cada produto, onde n√£o h√° dados passados para calcular lag/m√©dia.\n",
        "weekly_data.fillna(0, inplace=True)\n",
        "\n",
        "\n",
        "# --- VERIFICA√á√ÉO ---\n",
        "print(\"\\\\nCria√ß√£o de features conclu√≠da!\")\n",
        "print(\"Nosso dataset est√° 100% pronto para o treinamento do modelo.\")\n",
        "print(\"Note as novas colunas 'quantity_lag_...' e 'quantity_rolling_avg_...':\")\n",
        "display(weekly_data.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "963d9082",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gerando a lista de todos os estados e cidades √∫nicos no nosso conjunto de dados...\n",
            "======================================================================\n",
            "\\nEncontramos 4 estados √∫nicos em nossos dados:\n",
            "['CA', 'CO', 'GA', 'Unknown']\n",
            "----------------------------------------------------------------------\n",
            "\\nEncontramos 500 cidades √∫nicas.\n",
            "----------------------------------------------------------------------\n",
            "\\nPara refer√™ncia, aqui est√£o as cidades que temos em cada estado:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "state\n",
              "CA                                             [Los Angeles]\n",
              "CO         [Grand Junction, Denver, Arvada, Longmont, Lit...\n",
              "GA         [Talking Rock, Atlanta, Brunswick, Canton, Alp...\n",
              "Unknown                                            [Unknown]\n",
              "Name: city, dtype: object"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# --- LISTANDO ESTADOS E CIDADES PRESENTES NOS DADOS ---\n",
        "\n",
        "print(\"Gerando a lista de todos os estados e cidades √∫nicos no nosso conjunto de dados...\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# 1. Contar e listar os estados √∫nicos\n",
        "# .unique() pega todos os valores diferentes e .tolist() transforma em uma lista python\n",
        "estados_unicos = sorted(weekly_data['state'].unique())\n",
        "print(f\"\\\\nEncontramos {len(estados_unicos)} estados √∫nicos em nossos dados:\")\n",
        "print(estados_unicos)\n",
        "print(\"-\" * 70)\n",
        "\n",
        "# 2. Contar as cidades √∫nicas\n",
        "cidades_unicas = weekly_data['city'].unique()\n",
        "print(f\"\\\\nEncontramos {len(cidades_unicas)} cidades √∫nicas.\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "\n",
        "# 3. Mostrar as cidades agrupadas por estado (para melhor organiza√ß√£o)\n",
        "print(\"\\\\nPara refer√™ncia, aqui est√£o as cidades que temos em cada estado:\")\n",
        "cidades_por_estado = weekly_data.groupby('state')['city'].unique()\n",
        "# Usamos display para uma formata√ß√£o mais amig√°vel no notebook\n",
        "display(cidades_por_estado)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "205717bd",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Criando features de feriado com base na sua sugest√£o...\n",
            "\\nCria√ß√£o das features de feriado conclu√≠da!\n",
            "Semanas marcadas como feriado: 1,360,715\n",
            "Semanas de feriado em locais On Premise: 183,862\n",
            "Semanas de feriado em locais Off Premise: 1,170,572\n",
            "\\nExemplo das novas colunas em uma semana de feriado (semana 3):\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>week</th>\n",
              "      <th>internal_store_id</th>\n",
              "      <th>internal_product_id</th>\n",
              "      <th>categoria</th>\n",
              "      <th>marca</th>\n",
              "      <th>premise</th>\n",
              "      <th>categoria_pdv</th>\n",
              "      <th>state</th>\n",
              "      <th>city</th>\n",
              "      <th>total_quantity</th>\n",
              "      <th>quantity_lag_1</th>\n",
              "      <th>quantity_lag_2</th>\n",
              "      <th>quantity_lag_3</th>\n",
              "      <th>quantity_lag_4</th>\n",
              "      <th>quantity_rolling_avg_2</th>\n",
              "      <th>quantity_rolling_avg_4</th>\n",
              "      <th>quantity_rolling_avg_8</th>\n",
              "      <th>is_holiday_week</th>\n",
              "      <th>holiday_on_premise</th>\n",
              "      <th>holiday_off_premise</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>158456</th>\n",
              "      <td>3</td>\n",
              "      <td>1001371918471115422</td>\n",
              "      <td>1120490062981954254</td>\n",
              "      <td>Package</td>\n",
              "      <td>Bud Light</td>\n",
              "      <td>Off Premise</td>\n",
              "      <td>Convenience</td>\n",
              "      <td>GA</td>\n",
              "      <td>Talking Rock</td>\n",
              "      <td>18.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>9.5</td>\n",
              "      <td>5.800000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>158457</th>\n",
              "      <td>3</td>\n",
              "      <td>1001371918471115422</td>\n",
              "      <td>1394381856358939027</td>\n",
              "      <td>Package</td>\n",
              "      <td>Budweiser</td>\n",
              "      <td>Off Premise</td>\n",
              "      <td>Convenience</td>\n",
              "      <td>GA</td>\n",
              "      <td>Talking Rock</td>\n",
              "      <td>13.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.571429</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>158458</th>\n",
              "      <td>3</td>\n",
              "      <td>1001371918471115422</td>\n",
              "      <td>2626864159264988174</td>\n",
              "      <td>Package</td>\n",
              "      <td>Bud Ice</td>\n",
              "      <td>Off Premise</td>\n",
              "      <td>Convenience</td>\n",
              "      <td>GA</td>\n",
              "      <td>Talking Rock</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>158459</th>\n",
              "      <td>3</td>\n",
              "      <td>1001371918471115422</td>\n",
              "      <td>4353552881410365573</td>\n",
              "      <td>Package</td>\n",
              "      <td>Natural Light</td>\n",
              "      <td>Off Premise</td>\n",
              "      <td>Convenience</td>\n",
              "      <td>GA</td>\n",
              "      <td>Talking Rock</td>\n",
              "      <td>4.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.200000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>158460</th>\n",
              "      <td>3</td>\n",
              "      <td>1001371918471115422</td>\n",
              "      <td>4974205226846185245</td>\n",
              "      <td>Package</td>\n",
              "      <td>Natural Ice</td>\n",
              "      <td>Off Premise</td>\n",
              "      <td>Convenience</td>\n",
              "      <td>GA</td>\n",
              "      <td>Talking Rock</td>\n",
              "      <td>3.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        week    internal_store_id  internal_product_id categoria  \\\n",
              "158456     3  1001371918471115422  1120490062981954254   Package   \n",
              "158457     3  1001371918471115422  1394381856358939027   Package   \n",
              "158458     3  1001371918471115422  2626864159264988174   Package   \n",
              "158459     3  1001371918471115422  4353552881410365573   Package   \n",
              "158460     3  1001371918471115422  4974205226846185245   Package   \n",
              "\n",
              "                marca      premise categoria_pdv state          city  \\\n",
              "158456      Bud Light  Off Premise   Convenience    GA  Talking Rock   \n",
              "158457      Budweiser  Off Premise   Convenience    GA  Talking Rock   \n",
              "158458        Bud Ice  Off Premise   Convenience    GA  Talking Rock   \n",
              "158459  Natural Light  Off Premise   Convenience    GA  Talking Rock   \n",
              "158460    Natural Ice  Off Premise   Convenience    GA  Talking Rock   \n",
              "\n",
              "        total_quantity  quantity_lag_1  quantity_lag_2  quantity_lag_3  \\\n",
              "158456            18.0            18.0             0.0             0.0   \n",
              "158457            13.0             0.0             0.0             0.0   \n",
              "158458             2.0             0.0             0.0             0.0   \n",
              "158459             4.0             7.0             0.0             0.0   \n",
              "158460             3.0             7.0             0.0             0.0   \n",
              "\n",
              "        quantity_lag_4  quantity_rolling_avg_2  quantity_rolling_avg_4  \\\n",
              "158456             0.0                    18.0                     9.5   \n",
              "158457             0.0                    10.0                    10.0   \n",
              "158458             0.0                     1.0                     4.0   \n",
              "158459             0.0                     7.0                     4.0   \n",
              "158460             0.0                     7.0                     3.0   \n",
              "\n",
              "        quantity_rolling_avg_8  is_holiday_week  holiday_on_premise  \\\n",
              "158456                5.800000                1                   0   \n",
              "158457               10.571429                1                   0   \n",
              "158458                5.000000                1                   0   \n",
              "158459                2.200000                1                   0   \n",
              "158460                2.000000                1                   0   \n",
              "\n",
              "        holiday_off_premise  \n",
              "158456                    1  \n",
              "158457                    1  \n",
              "158458                    1  \n",
              "158459                    1  \n",
              "158460                    1  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# --- PASSO 6: CRIAR FEATURES DE FERIADO E INTERA√á√ÉO ---\n",
        "\n",
        "print(\"Criando features de feriado com base na sua sugest√£o...\")\n",
        "import numpy as np\n",
        "\n",
        "# 1. Lista das semanas de 2022 que cont√™m feriados importantes nos EUA\n",
        "# (Ex: MLK Day, Memorial Day, 4th of July, Labor Day, Thanksgiving, Christmas)\n",
        "holiday_weeks = [3, 8, 22, 25, 27, 36, 41, 45, 47, 52]\n",
        "\n",
        "# 2. Criar uma feature bin√°ria simples para marcar se a semana tem feriado ou n√£o\n",
        "# Usamos .isin() para verificar se o valor da coluna 'week' est√° na nossa lista\n",
        "weekly_data['is_holiday_week'] = weekly_data['week'].isin(holiday_weeks).astype(int)\n",
        "\n",
        "\n",
        "# 3. Criar as \"Features de Intera√ß√£o\" que voc√™ idealizou\n",
        "# Elas combinam a informa√ß√£o do feriado com o tipo de local (premise)\n",
        "# O modelo agora pode aprender pesos diferentes para cada uma dessas condi√ß√µes\n",
        "\n",
        "# Feature para feriado em locais On-Premise\n",
        "weekly_data['holiday_on_premise'] = np.where(\n",
        "    (weekly_data['is_holiday_week'] == 1) & (weekly_data['premise'] == 'On Premise'), 1, 0\n",
        ")\n",
        "\n",
        "# Feature para feriado em locais Off-Premise\n",
        "weekly_data['holiday_off_premise'] = np.where(\n",
        "    (weekly_data['is_holiday_week'] == 1) & (weekly_data['premise'] == 'Off Premise'), 1, 0\n",
        ")\n",
        "\n",
        "\n",
        "# --- VERIFICA√á√ÉO ---\n",
        "print(\"\\\\nCria√ß√£o das features de feriado conclu√≠da!\")\n",
        "\n",
        "# Vamos verificar a contagem de cada nova feature\n",
        "print(f\"Semanas marcadas como feriado: {weekly_data['is_holiday_week'].sum():,}\")\n",
        "print(f\"Semanas de feriado em locais On Premise: {weekly_data['holiday_on_premise'].sum():,}\")\n",
        "print(f\"Semanas de feriado em locais Off Premise: {weekly_data['holiday_off_premise'].sum():,}\")\n",
        "\n",
        "# Mostra as novas colunas no dataframe\n",
        "print(\"\\\\nExemplo das novas colunas em uma semana de feriado (semana 3):\")\n",
        "display(weekly_data[weekly_data['week'] == 3].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "0bbc99a9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Criando features para feriados estaduais espec√≠ficos (CA, CO, GA)...\n",
            "\\nCria√ß√£o das features de feriados estaduais conclu√≠da!\n",
            "Semanas marcadas como feriado da Calif√≥rnia: 0\n",
            "Semanas marcadas como feriado do Colorado: 122,948\n",
            "Semanas marcadas como feriado da Ge√≥rgia: 88,852\n",
            "\\nExemplo de feriado da Ge√≥rgia (semana 15 ou 51):\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>week</th>\n",
              "      <th>internal_store_id</th>\n",
              "      <th>internal_product_id</th>\n",
              "      <th>categoria</th>\n",
              "      <th>marca</th>\n",
              "      <th>premise</th>\n",
              "      <th>categoria_pdv</th>\n",
              "      <th>state</th>\n",
              "      <th>city</th>\n",
              "      <th>total_quantity</th>\n",
              "      <th>...</th>\n",
              "      <th>quantity_lag_4</th>\n",
              "      <th>quantity_rolling_avg_2</th>\n",
              "      <th>quantity_rolling_avg_4</th>\n",
              "      <th>quantity_rolling_avg_8</th>\n",
              "      <th>is_holiday_week</th>\n",
              "      <th>holiday_on_premise</th>\n",
              "      <th>holiday_off_premise</th>\n",
              "      <th>is_holiday_ca</th>\n",
              "      <th>is_holiday_co</th>\n",
              "      <th>is_holiday_ga</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5915415</th>\n",
              "      <td>51</td>\n",
              "      <td>1001371918471115422</td>\n",
              "      <td>1009179103632945474</td>\n",
              "      <td>Package</td>\n",
              "      <td>Busch</td>\n",
              "      <td>Off Premise</td>\n",
              "      <td>Convenience</td>\n",
              "      <td>GA</td>\n",
              "      <td>Talking Rock</td>\n",
              "      <td>2.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1.25</td>\n",
              "      <td>1.125000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5915416</th>\n",
              "      <td>51</td>\n",
              "      <td>1001371918471115422</td>\n",
              "      <td>1120490062981954254</td>\n",
              "      <td>Package</td>\n",
              "      <td>Bud Light</td>\n",
              "      <td>Off Premise</td>\n",
              "      <td>Convenience</td>\n",
              "      <td>GA</td>\n",
              "      <td>Talking Rock</td>\n",
              "      <td>10.0</td>\n",
              "      <td>...</td>\n",
              "      <td>10.0</td>\n",
              "      <td>12.5</td>\n",
              "      <td>11.25</td>\n",
              "      <td>14.500000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1356600</th>\n",
              "      <td>15</td>\n",
              "      <td>1001371918471115422</td>\n",
              "      <td>1394381856358939027</td>\n",
              "      <td>Package</td>\n",
              "      <td>Budweiser</td>\n",
              "      <td>Off Premise</td>\n",
              "      <td>Convenience</td>\n",
              "      <td>GA</td>\n",
              "      <td>Talking Rock</td>\n",
              "      <td>13.0</td>\n",
              "      <td>...</td>\n",
              "      <td>20.0</td>\n",
              "      <td>12.5</td>\n",
              "      <td>15.25</td>\n",
              "      <td>13.857143</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5915417</th>\n",
              "      <td>51</td>\n",
              "      <td>1001371918471115422</td>\n",
              "      <td>1394381856358939027</td>\n",
              "      <td>Package</td>\n",
              "      <td>Budweiser</td>\n",
              "      <td>Off Premise</td>\n",
              "      <td>Convenience</td>\n",
              "      <td>GA</td>\n",
              "      <td>Talking Rock</td>\n",
              "      <td>13.0</td>\n",
              "      <td>...</td>\n",
              "      <td>9.0</td>\n",
              "      <td>19.5</td>\n",
              "      <td>14.50</td>\n",
              "      <td>13.250000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1356601</th>\n",
              "      <td>15</td>\n",
              "      <td>1001371918471115422</td>\n",
              "      <td>1454838625590783593</td>\n",
              "      <td>Package</td>\n",
              "      <td>Bud Ice</td>\n",
              "      <td>Off Premise</td>\n",
              "      <td>Convenience</td>\n",
              "      <td>GA</td>\n",
              "      <td>Talking Rock</td>\n",
              "      <td>3.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19.50</td>\n",
              "      <td>12.500000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows √ó 23 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         week    internal_store_id  internal_product_id categoria      marca  \\\n",
              "5915415    51  1001371918471115422  1009179103632945474   Package      Busch   \n",
              "5915416    51  1001371918471115422  1120490062981954254   Package  Bud Light   \n",
              "1356600    15  1001371918471115422  1394381856358939027   Package  Budweiser   \n",
              "5915417    51  1001371918471115422  1394381856358939027   Package  Budweiser   \n",
              "1356601    15  1001371918471115422  1454838625590783593   Package    Bud Ice   \n",
              "\n",
              "             premise categoria_pdv state          city  total_quantity  ...  \\\n",
              "5915415  Off Premise   Convenience    GA  Talking Rock             2.0  ...   \n",
              "5915416  Off Premise   Convenience    GA  Talking Rock            10.0  ...   \n",
              "1356600  Off Premise   Convenience    GA  Talking Rock            13.0  ...   \n",
              "5915417  Off Premise   Convenience    GA  Talking Rock            13.0  ...   \n",
              "1356601  Off Premise   Convenience    GA  Talking Rock             3.0  ...   \n",
              "\n",
              "         quantity_lag_4  quantity_rolling_avg_2  quantity_rolling_avg_4  \\\n",
              "5915415             1.0                     1.5                    1.25   \n",
              "5915416            10.0                    12.5                   11.25   \n",
              "1356600            20.0                    12.5                   15.25   \n",
              "5915417             9.0                    19.5                   14.50   \n",
              "1356601             0.0                     0.0                   19.50   \n",
              "\n",
              "         quantity_rolling_avg_8  is_holiday_week  holiday_on_premise  \\\n",
              "5915415                1.125000                0                   0   \n",
              "5915416               14.500000                0                   0   \n",
              "1356600               13.857143                0                   0   \n",
              "5915417               13.250000                0                   0   \n",
              "1356601               12.500000                0                   0   \n",
              "\n",
              "         holiday_off_premise  is_holiday_ca  is_holiday_co  is_holiday_ga  \n",
              "5915415                    0              0              0              1  \n",
              "5915416                    0              0              0              1  \n",
              "1356600                    0              0              0              1  \n",
              "5915417                    0              0              0              1  \n",
              "1356601                    0              0              0              1  \n",
              "\n",
              "[5 rows x 23 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# --- PASSO 7: CRIAR FEATURES DE FERIADOS ESTADUAIS ---\n",
        "\n",
        "print(\"Criando features para feriados estaduais espec√≠ficos (CA, CO, GA)...\")\n",
        "import numpy as np\n",
        "\n",
        "# 1. Definir as semanas dos feriados √∫nicos para cada estado, com base na nossa pesquisa\n",
        "# (Converti as datas dos feriados para o n√∫mero da semana em 2022)\n",
        "ca_holiday_weeks = [13]  # Cesar Chavez Day\n",
        "co_holiday_weeks = [13, 40] # Cesar Chavez Day, Frances Xavier Cabrini Day\n",
        "ga_holiday_weeks = [15, 51] # Good Friday, State Holiday (Dec 23)\n",
        "\n",
        "# 2. Criar a feature para feriados da Calif√≥rnia (CA)\n",
        "weekly_data['is_holiday_ca'] = np.where(\n",
        "    (weekly_data['state'] == 'CA') & (weekly_data['week'].isin(ca_holiday_weeks)), 1, 0\n",
        ")\n",
        "\n",
        "# 3. Criar a feature para feriados do Colorado (CO)\n",
        "weekly_data['is_holiday_co'] = np.where(\n",
        "    (weekly_data['state'] == 'CO') & (weekly_data['week'].isin(co_holiday_weeks)), 1, 0\n",
        ")\n",
        "\n",
        "# 4. Criar a feature para feriados da Ge√≥rgia (GA)\n",
        "weekly_data['is_holiday_ga'] = np.where(\n",
        "    (weekly_data['state'] == 'GA') & (weekly_data['week'].isin(ga_holiday_weeks)), 1, 0\n",
        ")\n",
        "\n",
        "\n",
        "# --- VERIFICA√á√ÉO ---\n",
        "print(\"\\\\nCria√ß√£o das features de feriados estaduais conclu√≠da!\")\n",
        "\n",
        "# Verificar se as colunas foram criadas e quantas marca√ß√µes cada uma tem\n",
        "ca_count = weekly_data['is_holiday_ca'].sum()\n",
        "co_count = weekly_data['is_holiday_co'].sum()\n",
        "ga_count = weekly_data['is_holiday_ga'].sum()\n",
        "\n",
        "print(f\"Semanas marcadas como feriado da Calif√≥rnia: {ca_count:,}\")\n",
        "print(f\"Semanas marcadas como feriado do Colorado: {co_count:,}\")\n",
        "print(f\"Semanas marcadas como feriado da Ge√≥rgia: {ga_count:,}\")\n",
        "\n",
        "# Se houver marca√ß√µes, mostrar um exemplo\n",
        "if ga_count > 0:\n",
        "    print(\"\\\\nExemplo de feriado da Ge√≥rgia (semana 15 ou 51):\")\n",
        "    display(weekly_data[weekly_data['is_holiday_ga'] == 1].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "1af26e13",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Investigando os dados da Calif√≥rnia e da semana 13...\n",
            "============================================================\n",
            "N√∫mero total de linhas de vendas semanais da Calif√≥rnia: 432\n",
            "N√∫mero total de linhas de vendas semanais da semana 13 (de todos os estados): 107,262\n",
            "\\nN√∫mero de linhas que s√£o da Calif√≥rnia E da semana 13: 0\n",
            "\\nConclus√£o: Como suspeitado, n√£o h√° registros de vendas em nosso dataset para a Calif√≥rnia durante a semana 13 de 2022.\n"
          ]
        }
      ],
      "source": [
        "# --- DIAGN√ìSTICO: POR QUE O FERIADO DA CALIF√ìRNIA N√ÉO APARECE? ---\n",
        "\n",
        "print(\"Investigando os dados da Calif√≥rnia e da semana 13...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# 1. Temos dados da Calif√≥rnia no geral?\n",
        "ca_total_rows = len(weekly_data[weekly_data['state'] == 'CA'])\n",
        "print(f\"N√∫mero total de linhas de vendas semanais da Calif√≥rnia: {ca_total_rows:,}\")\n",
        "\n",
        "# 2. Temos dados da semana 13 no geral?\n",
        "week_13_total_rows = len(weekly_data[weekly_data['week'] == 13])\n",
        "print(f\"N√∫mero total de linhas de vendas semanais da semana 13 (de todos os estados): {week_13_total_rows:,}\")\n",
        "\n",
        "# 3. A verifica√ß√£o final: Temos dados que s√£o da CA E da semana 13 ao mesmo tempo?\n",
        "combinacao_df = weekly_data[(weekly_data['state'] == 'CA') & (weekly_data['week'] == 13)]\n",
        "num_combinacao = len(combinacao_df)\n",
        "print(f\"\\\\nN√∫mero de linhas que s√£o da Calif√≥rnia E da semana 13: {num_combinacao}\")\n",
        "\n",
        "if num_combinacao == 0:\n",
        "    print(\"\\\\nConclus√£o: Como suspeitado, n√£o h√° registros de vendas em nosso dataset para a Calif√≥rnia durante a semana 13 de 2022.\")\n",
        "else:\n",
        "    print(\"\\\\nConclus√£o: Encontramos dados para a CA na semana 13. Pode haver outro problema.\")\n",
        "    display(combinacao_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af2cad95",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A biblioteca 'scikit-learn' n√£o foi encontrada. Instalando agora...\n",
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.7.2-cp313-cp313-win_amd64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\danie\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (2.3.2)\n",
            "Collecting scipy>=1.8.0 (from scikit-learn)\n",
            "  Downloading scipy-1.16.2-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
            "Collecting joblib>=1.2.0 (from scikit-learn)\n",
            "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
            "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
            "Downloading scikit_learn-1.7.2-cp313-cp313-win_amd64.whl (8.7 MB)\n",
            "   ---------------------------------------- 0.0/8.7 MB ? eta -:--:--\n",
            "   ---------------------------------------- 8.7/8.7 MB 62.3 MB/s  0:00:00\n",
            "Downloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
            "Downloading scipy-1.16.2-cp313-cp313-win_amd64.whl (38.5 MB)\n",
            "   ---------------------------------------- 0.0/38.5 MB ? eta -:--:--\n",
            "   --------------------- ------------------ 20.4/38.5 MB 97.6 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 34.6/38.5 MB 93.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 38.5/38.5 MB 62.4 MB/s  0:00:00\n",
            "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
            "\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   ---------- ----------------------------- 1/4 [scipy]\n",
            "   -------------------- ------------------- 2/4 [joblib]\n",
            "   -------------------- ------------------- 2/4 [joblib]\n",
            "   -------------------- ------------------- 2/4 [joblib]\n",
            "   -------------------- ------------------- 2/4 [joblib]\n",
            "   -------------------- ------------------- 2/4 [joblib]\n",
            "   -------------------- ------------------- 2/4 [joblib]\n",
            "   -------------------- ------------------- 2/4 [joblib]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ------------------------------ --------- 3/4 [scikit-learn]\n",
            "   ---------------------------------------- 4/4 [scikit-learn]\n",
            "\n",
            "Successfully installed joblib-1.5.2 scikit-learn-1.7.2 scipy-1.16.2 threadpoolctl-3.6.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "7839982e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iniciando a prepara√ß√£o dos dados para o treinamento...\n",
            "Colunas de texto convertidas para n√∫meros.\n",
            "\\nDados prontos para o modelo!\n",
            "Nosso 'alvo' (y - o que queremos prever) tem 6,140,206 linhas.\n",
            "Nossas 'features' (X - as pistas) t√™m 6,140,206 linhas e 20 colunas.\n",
            "\\nExemplo das features (X) que o modelo vai usar:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>week</th>\n",
              "      <th>quantity_lag_1</th>\n",
              "      <th>quantity_lag_2</th>\n",
              "      <th>quantity_lag_3</th>\n",
              "      <th>quantity_lag_4</th>\n",
              "      <th>quantity_rolling_avg_2</th>\n",
              "      <th>quantity_rolling_avg_4</th>\n",
              "      <th>quantity_rolling_avg_8</th>\n",
              "      <th>is_holiday_week</th>\n",
              "      <th>holiday_on_premise</th>\n",
              "      <th>holiday_off_premise</th>\n",
              "      <th>is_holiday_ca</th>\n",
              "      <th>is_holiday_co</th>\n",
              "      <th>is_holiday_ga</th>\n",
              "      <th>categoria_encoded</th>\n",
              "      <th>marca_encoded</th>\n",
              "      <th>premise_encoded</th>\n",
              "      <th>categoria_pdv_encoded</th>\n",
              "      <th>state_encoded</th>\n",
              "      <th>city_encoded</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>433888</th>\n",
              "      <td>6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1449</td>\n",
              "      <td>1</td>\n",
              "      <td>54</td>\n",
              "      <td>2</td>\n",
              "      <td>442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>529002</th>\n",
              "      <td>7</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1449</td>\n",
              "      <td>1</td>\n",
              "      <td>54</td>\n",
              "      <td>2</td>\n",
              "      <td>442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2042472</th>\n",
              "      <td>21</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1449</td>\n",
              "      <td>1</td>\n",
              "      <td>54</td>\n",
              "      <td>2</td>\n",
              "      <td>442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2521528</th>\n",
              "      <td>25</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1.333333</td>\n",
              "      <td>1.333333</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1449</td>\n",
              "      <td>1</td>\n",
              "      <td>54</td>\n",
              "      <td>2</td>\n",
              "      <td>442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2891177</th>\n",
              "      <td>28</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1449</td>\n",
              "      <td>1</td>\n",
              "      <td>54</td>\n",
              "      <td>2</td>\n",
              "      <td>442</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         week  quantity_lag_1  quantity_lag_2  quantity_lag_3  quantity_lag_4  \\\n",
              "433888      6             0.0             0.0             0.0             0.0   \n",
              "529002      7             1.0             0.0             0.0             0.0   \n",
              "2042472    21             2.0             1.0             0.0             0.0   \n",
              "2521528    25             1.0             2.0             1.0             0.0   \n",
              "2891177    28             2.0             1.0             2.0             1.0   \n",
              "\n",
              "         quantity_rolling_avg_2  quantity_rolling_avg_4  \\\n",
              "433888                      0.0                0.000000   \n",
              "529002                      1.0                1.000000   \n",
              "2042472                     1.5                1.500000   \n",
              "2521528                     1.5                1.333333   \n",
              "2891177                     1.5                1.500000   \n",
              "\n",
              "         quantity_rolling_avg_8  is_holiday_week  holiday_on_premise  \\\n",
              "433888                 0.000000                0                   0   \n",
              "529002                 1.000000                0                   0   \n",
              "2042472                1.500000                0                   0   \n",
              "2521528                1.333333                1                   1   \n",
              "2891177                1.500000                0                   0   \n",
              "\n",
              "         holiday_off_premise  is_holiday_ca  is_holiday_co  is_holiday_ga  \\\n",
              "433888                     0              0              0              0   \n",
              "529002                     0              0              0              0   \n",
              "2042472                    0              0              0              0   \n",
              "2521528                    0              0              0              0   \n",
              "2891177                    0              0              0              0   \n",
              "\n",
              "         categoria_encoded  marca_encoded  premise_encoded  \\\n",
              "433888                   4           1449                1   \n",
              "529002                   4           1449                1   \n",
              "2042472                  4           1449                1   \n",
              "2521528                  4           1449                1   \n",
              "2891177                  4           1449                1   \n",
              "\n",
              "         categoria_pdv_encoded  state_encoded  city_encoded  \n",
              "433888                      54              2           442  \n",
              "529002                      54              2           442  \n",
              "2042472                     54              2           442  \n",
              "2521528                     54              2           442  \n",
              "2891177                     54              2           442  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# --- PASSO 8: PREPARAR DADOS PARA O MODELO ---\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "print(\"Iniciando a prepara√ß√£o dos dados para o treinamento...\")\n",
        "\n",
        "# 1. Lidar com colunas categ√≥ricas (texto)\n",
        "# O LabelEncoder transforma cada categoria √∫nica em um n√∫mero. Ex: 'CA' -> 0, 'CO' -> 1, 'GA' -> 2\n",
        "categorical_features = [\n",
        "    'categoria', 'marca', 'premise', 'categoria_pdv', 'state', 'city'\n",
        "]\n",
        "\n",
        "# Copiamos para n√£o alterar o weekly_data original\n",
        "data_for_training = weekly_data.copy()\n",
        "\n",
        "for feature in categorical_features:\n",
        "    encoder = LabelEncoder()\n",
        "    # Cria uma nova coluna com o sufixo '_encoded' com os valores num√©ricos\n",
        "    data_for_training[f'{feature}_encoded'] = encoder.fit_transform(data_for_training[feature])\n",
        "\n",
        "print(\"Colunas de texto convertidas para n√∫meros.\")\n",
        "\n",
        "\n",
        "# 2. Definir as 'features' (X) e o 'alvo' (y)\n",
        "# O alvo (y) √© o que queremos prever: 'total_quantity'\n",
        "y = data_for_training['total_quantity']\n",
        "\n",
        "# As features (X) s√£o todas as pistas que preparamos\n",
        "feature_columns = [\n",
        "    'week',\n",
        "    # Lags e Rolling Averages\n",
        "    'quantity_lag_1', 'quantity_lag_2', 'quantity_lag_3', 'quantity_lag_4',\n",
        "    'quantity_rolling_avg_2', 'quantity_rolling_avg_4', 'quantity_rolling_avg_8',\n",
        "    # Features de Feriado (Federais e Estaduais)\n",
        "    'is_holiday_week', 'holiday_on_premise', 'holiday_off_premise',\n",
        "    'is_holiday_ca', 'is_holiday_co', 'is_holiday_ga',\n",
        "    # Features Categ√≥ricas que acabamos de codificar\n",
        "    'categoria_encoded', 'marca_encoded', 'premise_encoded',\n",
        "    'categoria_pdv_encoded', 'state_encoded', 'city_encoded'\n",
        "]\n",
        "X = data_for_training[feature_columns]\n",
        "\n",
        "\n",
        "# --- VERIFICA√á√ÉO ---\n",
        "print(\"\\\\nDados prontos para o modelo!\")\n",
        "print(f\"Nosso 'alvo' (y - o que queremos prever) tem {len(y):,} linhas.\")\n",
        "print(f\"Nossas 'features' (X - as pistas) t√™m {X.shape[0]:,} linhas e {X.shape[1]} colunas.\")\n",
        "print(\"\\\\nExemplo das features (X) que o modelo vai usar:\")\n",
        "display(X.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "ba5edbd0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dividindo os dados em conjuntos de treino e valida√ß√£o (80/20)...\n",
            "\\nDivis√£o conclu√≠da!\n",
            "Tamanho do conjunto de treino (X_train): 4,912,164 linhas\n",
            "Tamanho do conjunto de valida√ß√£o (X_val): 1,228,042 linhas\n"
          ]
        }
      ],
      "source": [
        "# --- PASSO 9: DIVIDIR DADOS EM TREINO E VALIDA√á√ÉO ---\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "print(\"Dividindo os dados em conjuntos de treino e valida√ß√£o (80/20)...\")\n",
        "\n",
        "# A fun√ß√£o train_test_split faz a divis√£o de forma aleat√≥ria e estratificada\n",
        "# test_size=0.2 significa que 20% dos dados ir√£o para valida√ß√£o\n",
        "# random_state=42 garante que a divis√£o seja sempre a mesma se rodarmos o c√≥digo de novo\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y, \n",
        "    test_size=0.2, \n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# --- VERIFICA√á√ÉO ---\n",
        "print(\"\\\\nDivis√£o conclu√≠da!\")\n",
        "print(f\"Tamanho do conjunto de treino (X_train): {len(X_train):,} linhas\")\n",
        "print(f\"Tamanho do conjunto de valida√ß√£o (X_val): {len(X_val):,} linhas\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "ba01b25f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Instalando/Verificando a biblioteca 'catboost'...\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "\\nBiblioteca CatBoost pronta.\n",
            "\\nIniciando o treinamento do modelo... (Isso pode levar alguns minutos)\n",
            "0:\tlearn: 85.9999628\ttest: 66.5104908\tbest: 66.5104908 (0)\ttotal: 607ms\tremaining: 10m 6s\n",
            "Stopped by overfitting detector  (50 iterations wait)\n",
            "\n",
            "bestTest = 62.60593379\n",
            "bestIteration = 34\n",
            "\n",
            "Shrink model to first 35 iterations.\n",
            "\\n--- TREINAMENTO CONCLU√çDO! ---\n",
            "Seu modelo de previs√£o de vendas foi treinado com sucesso.\n"
          ]
        }
      ],
      "source": [
        "# --- PASSO 10: TREINAR O MODELO CATBOOST ---\n",
        "\n",
        "# 1. Instalar a biblioteca catboost, caso ainda n√£o tenha\n",
        "print(\"Instalando/Verificando a biblioteca 'catboost'...\")\n",
        "%pip install catboost -q\n",
        "\n",
        "from catboost import CatBoostRegressor\n",
        "print(\"\\\\nBiblioteca CatBoost pronta.\")\n",
        "\n",
        "\n",
        "# 2. Inicializar o modelo com alguns par√¢metros\n",
        "# iterations: O n√∫mero m√°ximo de \"rodadas\" de aprendizado.\n",
        "# learning_rate: O qu√£o r√°pido o modelo aprende.\n",
        "# depth: A profundidade das \"√°rvores de decis√£o\" que o modelo constr√≥i.\n",
        "model = CatBoostRegressor(\n",
        "    iterations=1000,\n",
        "    learning_rate=0.05,\n",
        "    depth=10,\n",
        "    loss_function='RMSE', # M√©trica de erro que o modelo tentar√° minimizar\n",
        "    random_seed=42,\n",
        "    verbose=100  # Mostra o progresso do treino a cada 100 rodadas\n",
        ")\n",
        "\n",
        "print(\"\\\\nIniciando o treinamento do modelo... (Isso pode levar alguns minutos)\")\n",
        "\n",
        "# 3. Treinar o modelo!\n",
        "# Passamos os dados de treino (X_train, y_train) para ele aprender.\n",
        "# Passamos os dados de valida√ß√£o (eval_set) para ele monitorar a pr√≥pria performance e evitar \"decoreba\".\n",
        "model.fit(\n",
        "    X_train, y_train,\n",
        "    eval_set=(X_val, y_val),\n",
        "    early_stopping_rounds=50, # Para de treinar se a performance na valida√ß√£o n√£o melhorar por 50 rodadas\n",
        "    verbose=100\n",
        ")\n",
        "\n",
        "print(\"\\\\n--- TREINAMENTO CONCLU√çDO! ---\")\n",
        "print(\"Seu modelo de previs√£o de vendas foi treinado com sucesso.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "238e0977",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iniciando a gera√ß√£o das previs√µes para as 5 primeiras semanas de 2023...\n",
            "Prevendo a semana 1 de 2023...\n",
            "Prevendo a semana 2 de 2023...\n",
            "Prevendo a semana 3 de 2023...\n",
            "Prevendo a semana 4 de 2023...\n",
            "Prevendo a semana 5 de 2023...\n",
            "\\nPREVIS√ïES GERADAS COM SUCESSO!\n",
            "Total de previs√µes geradas: 5,114,685\n",
            "Amostra do arquivo final de previs√£o:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>semana</th>\n",
              "      <th>pdv</th>\n",
              "      <th>produto</th>\n",
              "      <th>quantidade_prevista</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1000237487041964405</td>\n",
              "      <td>1837429607327399565</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1000237487041964405</td>\n",
              "      <td>4038588102284338370</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1000237487041964405</td>\n",
              "      <td>5429216175252037173</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1000237487041964405</td>\n",
              "      <td>596381974901127871</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1000237487041964405</td>\n",
              "      <td>7270233133454638680</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>1000237487041964405</td>\n",
              "      <td>7370044109082767116</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>1000237487041964405</td>\n",
              "      <td>7405304019373961901</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>1000237487041964405</td>\n",
              "      <td>777251454728290683</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>1000237487041964405</td>\n",
              "      <td>8313805606242965556</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>1000275275922029725</td>\n",
              "      <td>1735457469340543861</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   semana                  pdv              produto  quantidade_prevista\n",
              "0       1  1000237487041964405  1837429607327399565                    3\n",
              "1       1  1000237487041964405  4038588102284338370                    4\n",
              "2       1  1000237487041964405  5429216175252037173                    3\n",
              "3       1  1000237487041964405   596381974901127871                    3\n",
              "4       1  1000237487041964405  7270233133454638680                    3\n",
              "5       1  1000237487041964405  7370044109082767116                    3\n",
              "6       1  1000237487041964405  7405304019373961901                    3\n",
              "7       1  1000237487041964405   777251454728290683                    3\n",
              "8       1  1000237487041964405  8313805606242965556                    3\n",
              "9       1  1000275275922029725  1735457469340543861                   32"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\\nArquivo 'previsoes_vendas_2023.csv' salvo com sucesso no seu diret√≥rio!\n"
          ]
        }
      ],
      "source": [
        "# --- PASSO 11: GERAR AS PREVIS√ïES PARA 2023 ---\n",
        "\n",
        "print(\"Iniciando a gera√ß√£o das previs√µes para as 5 primeiras semanas de 2023...\")\n",
        "\n",
        "# 1. Pegar o √∫ltimo registro de cada combina√ß√£o loja/produto de 2022\n",
        "# Isso nos dar√° as informa√ß√µes mais recentes para basear nossas previs√µes\n",
        "latest_records = data_for_training.loc[data_for_training.groupby(['internal_store_id', 'internal_product_id'])['week'].idxmax()]\n",
        "\n",
        "# 2. Loop para prever cada uma das 5 semanas\n",
        "all_predictions = []\n",
        "current_features = latest_records.copy()\n",
        "\n",
        "for week_num in range(1, 6):\n",
        "    print(f\"Prevendo a semana {week_num} de 2023...\")\n",
        "    \n",
        "    # Atualizar a feature 'week' para a semana que queremos prever\n",
        "    current_features['week'] = week_num\n",
        "    \n",
        "    # Garantir que as features est√£o na ordem correta que o modelo espera\n",
        "    X_future = current_features[feature_columns]\n",
        "    \n",
        "    # Fazer a previs√£o!\n",
        "    predictions = model.predict(X_future)\n",
        "    \n",
        "    # Garantir que n√£o teremos previs√µes negativas\n",
        "    predictions = np.maximum(0, predictions).round().astype(int)\n",
        "    \n",
        "    # Guardar as previs√µes em um formato amig√°vel\n",
        "    week_predictions = pd.DataFrame({\n",
        "        'semana': week_num,\n",
        "        'pdv': current_features['internal_store_id'],\n",
        "        'produto': current_features['internal_product_id'],\n",
        "        'quantidade_prevista': predictions\n",
        "    })\n",
        "    all_predictions.append(week_predictions)\n",
        "    \n",
        "    # ATUALIZA√á√ÉO PARA A PR√ìXIMA SEMANA:\n",
        "    # As previs√µes desta semana se tornam o 'lag_1' da pr√≥xima semana, e os outros lags s√£o deslocados.\n",
        "    # Esta √© a parte mais complexa, que simula o tempo passando.\n",
        "    current_features['quantity_lag_4'] = current_features['quantity_lag_3']\n",
        "    current_features['quantity_lag_3'] = current_features['quantity_lag_2']\n",
        "    current_features['quantity_lag_2'] = current_features['quantity_lag_1']\n",
        "    current_features['quantity_lag_1'] = predictions\n",
        "\n",
        "# 3. Juntar todas as previs√µes em um √∫nico dataframe\n",
        "predictions_df = pd.concat(all_predictions, ignore_index=True)\n",
        "\n",
        "\n",
        "# --- VERIFICA√á√ÉO ---\n",
        "print(\"\\\\nPREVIS√ïES GERADAS COM SUCESSO!\")\n",
        "print(f\"Total de previs√µes geradas: {len(predictions_df):,}\")\n",
        "print(\"Amostra do arquivo final de previs√£o:\")\n",
        "display(predictions_df.head(10))\n",
        "\n",
        "# Salvar as previs√µes em um arquivo CSV\n",
        "predictions_df.to_csv(\"previsoes_vendas_2023.csv\", index=False, sep=';')\n",
        "print(\"\\\\nArquivo 'previsoes_vendas_2023.csv' salvo com sucesso no seu diret√≥rio!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "d106741e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculando m√©tricas de avalia√ß√£o detalhadas no conjunto de valida√ß√£o...\n",
            "\\n========================================\n",
            "--- Relat√≥rio de Avalia√ß√£o do Modelo ---\n",
            "========================================\n",
            "RMSE (Root Mean Squared Error): 62.61\n",
            "  -> Interpreta√ß√£o: Em m√©dia, as previs√µes erraram em ~63 unidades.\n",
            "\\nMAE (Mean Absolute Error): 8.15\n",
            "  -> Interpreta√ß√£o: Na m√©dia, o erro absoluto de cada previs√£o foi de 8 unidades.\n",
            "\\nMAPE (Mean Absolute Percentage Error): 202201.39%\n",
            "  -> Interpreta√ß√£o: Na m√©dia, as previs√µes tiveram um desvio de 202201.4% em rela√ß√£o ao valor real.\n",
            "\\nR¬≤ (R-squared): 0.13\n",
            "  -> Interpreta√ß√£o: Nosso modelo consegue explicar 12.5% da varia√ß√£o nas vendas.\n",
            "========================================\n"
          ]
        }
      ],
      "source": [
        "# --- PASSO 12: AVALIA√á√ÉO DETALHADA DO MODELO (O SEU \"EVAL\") ---\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "print(\"Calculando m√©tricas de avalia√ß√£o detalhadas no conjunto de valida√ß√£o...\")\n",
        "\n",
        "# 1. Usar o modelo para fazer previs√µes nos dados de valida√ß√£o que separamos\n",
        "y_pred = model.predict(X_val)\n",
        "\n",
        "# 2. Calcular as m√©tricas de erro comparando o real (y_val) com o previsto (y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
        "mae = mean_absolute_error(y_val, y_pred)\n",
        "r2 = r2_score(y_val, y_pred)\n",
        "\n",
        "# Calcular MAPE (Erro Percentual Absoluto M√©dio) com cuidado para n√£o dividir por zero\n",
        "epsilon = 1e-10 # Um n√∫mero muito pequeno para evitar divis√£o por zero\n",
        "mape = np.mean(np.abs((y_val - y_pred) / (y_val + epsilon))) * 100\n",
        "\n",
        "\n",
        "# --- APRESENTA√á√ÉO DOS RESULTADOS (O SEU \"EVAL\") ---\n",
        "print(\"\\\\n\" + \"=\"*40)\n",
        "print(\"--- Relat√≥rio de Avalia√ß√£o do Modelo ---\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "print(f\"RMSE (Root Mean Squared Error): {rmse:.2f}\")\n",
        "print(f\"  -> Interpreta√ß√£o: Em m√©dia, as previs√µes erraram em ~{rmse:.0f} unidades.\")\n",
        "\n",
        "print(f\"\\\\nMAE (Mean Absolute Error): {mae:.2f}\")\n",
        "print(f\"  -> Interpreta√ß√£o: Na m√©dia, o erro absoluto de cada previs√£o foi de {mae:.0f} unidades.\")\n",
        "\n",
        "print(f\"\\\\nMAPE (Mean Absolute Percentage Error): {mape:.2f}%\")\n",
        "print(f\"  -> Interpreta√ß√£o: Na m√©dia, as previs√µes tiveram um desvio de {mape:.1f}% em rela√ß√£o ao valor real.\")\n",
        "\n",
        "print(f\"\\\\nR¬≤ (R-squared): {r2:.2f}\")\n",
        "print(f\"  -> Interpreta√ß√£o: Nosso modelo consegue explicar {r2:.1%} da varia√ß√£o nas vendas.\")\n",
        "print(\"=\"*40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "2264c821",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculando o WMAPE (a m√©trica mais importante para este problema)...\n",
            "\\n=======================================================\n",
            "--- M√©trica WMAPE (Weighted Mean Absolute Percentage Error) ---\n",
            "=======================================================\n",
            "WMAPE: 94.22%\n",
            "\\n  -> Interpreta√ß√£o: O erro total do nosso modelo corresponde a 94.2% do volume total de vendas no per√≠odo de valida√ß√£o.\n",
            "=======================================================\n"
          ]
        }
      ],
      "source": [
        "# --- C√ÅLCULO DO WMAPE ---\n",
        "\n",
        "print(\"Calculando o WMAPE (a m√©trica mais importante para este problema)...\")\n",
        "\n",
        "# Relembrando, y_val s√£o as vendas reais e y_pred s√£o as previs√µes do modelo para o conjunto de valida√ß√£o.\n",
        "\n",
        "# A f√≥rmula √©: Soma dos erros absolutos / Soma dos valores reais\n",
        "wmape = np.sum(np.abs(y_val - y_pred)) / np.sum(np.abs(y_val)) * 100\n",
        "\n",
        "\n",
        "# --- RESULTADO ---\n",
        "print(\"\\\\n\" + \"=\"*55)\n",
        "print(\"--- M√©trica WMAPE (Weighted Mean Absolute Percentage Error) ---\")\n",
        "print(\"=\"*55)\n",
        "print(f\"WMAPE: {wmape:.2f}%\")\n",
        "print(\"\\\\n  -> Interpreta√ß√£o: O erro total do nosso modelo corresponde a \" \\\n",
        "      f\"{wmape:.1f}% do volume total de vendas no per√≠odo de valida√ß√£o.\")\n",
        "print(\"=\"*55)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "42ad324c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Refazendo o processo com uma divis√£o de dados baseada no tempo...\n",
            "Divis√£o temporal conclu√≠da: 4,952,155 linhas de treino, 1,188,051 linhas de valida√ß√£o.\n",
            "\\nInicializando um novo modelo com par√¢metros mais seguros...\n",
            "Iniciando o retreinamento...\n",
            "0:\tlearn: 91.8266380\ttest: 14.8056012\tbest: 14.8056012 (0)\ttotal: 419ms\tremaining: 13m 57s\n",
            "Stopped by overfitting detector  (100 iterations wait)\n",
            "\n",
            "bestTest = 13.62186428\n",
            "bestIteration = 32\n",
            "\n",
            "Shrink model to first 33 iterations.\n",
            "\\n--- Reavaliando o Modelo v2 ---\n",
            "Novo WMAPE: 94.34%\n"
          ]
        }
      ],
      "source": [
        "# --- PASSO 9 e 10 (VERS√ÉO CORRIGIDA): DIVIS√ÉO TEMPORAL E RETREINAMENTO ---\n",
        "\n",
        "print(\"Refazendo o processo com uma divis√£o de dados baseada no tempo...\")\n",
        "\n",
        "# 1. Ordenar os dados por semana\n",
        "data_for_training = data_for_training.sort_values(by='week')\n",
        "\n",
        "# 2. Fazer a divis√£o temporal\n",
        "# Vamos usar as semanas at√© a semana 42 para treino, e o resto para valida√ß√£o.\n",
        "split_week = 42 \n",
        "train_data = data_for_training[data_for_training['week'] <= split_week]\n",
        "val_data = data_for_training[data_for_training['week'] > split_week]\n",
        "\n",
        "# Separar features (X) e alvo (y) para cada conjunto\n",
        "X_train = train_data[feature_columns]\n",
        "y_train = train_data['total_quantity']\n",
        "X_val = val_data[feature_columns]\n",
        "y_val = val_data['total_quantity']\n",
        "\n",
        "print(f\"Divis√£o temporal conclu√≠da: {len(X_train):,} linhas de treino, {len(X_val):,} linhas de valida√ß√£o.\")\n",
        "\n",
        "\n",
        "# 3. Inicializar um novo modelo com par√¢metros mais seguros\n",
        "print(\"\\\\nInicializando um novo modelo com par√¢metros mais seguros...\")\n",
        "model_v2 = CatBoostRegressor(\n",
        "    iterations=2000, # Aumentamos as itera√ß√µes pois esperamos que demore mais para convergir\n",
        "    learning_rate=0.05,\n",
        "    depth=7, # Profundidade menor para evitar overfitting\n",
        "    loss_function='RMSE',\n",
        "    random_seed=42,\n",
        "    verbose=200\n",
        ")\n",
        "\n",
        "# 4. Retreinar o modelo com os dados corretamente divididos\n",
        "print(\"Iniciando o retreinamento...\")\n",
        "model_v2.fit(\n",
        "    X_train, y_train,\n",
        "    eval_set=(X_val, y_val),\n",
        "    early_stopping_rounds=100 # Aumentamos a paci√™ncia do early stopping\n",
        ")\n",
        "\n",
        "\n",
        "# 5. Reavaliar o WMAPE\n",
        "print(\"\\\\n--- Reavaliando o Modelo v2 ---\")\n",
        "y_pred_v2 = model_v2.predict(X_val)\n",
        "\n",
        "wmape_v2 = np.sum(np.abs(y_val - y_pred_v2)) / np.sum(np.abs(y_val)) * 100\n",
        "\n",
        "print(f\"Novo WMAPE: {wmape_v2:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "36364d54",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Investigando o conjunto de valida√ß√£o (y_val) para entender o WMAPE...\n",
            "N√∫mero total de linhas no y_val: 1,188,051\n",
            "N√∫mero de vendas zero no y_val: 0\n",
            "Porcentagem de vendas zero no y_val: 0.00%\n",
            "Soma total das vendas no y_val (denominador do WMAPE): 6,004,308.94\n",
            "\\nEstat√≠sticas descritivas de y_val:\n",
            "count    1.188051e+06\n",
            "mean     5.053915e+00\n",
            "std      1.426702e+01\n",
            "min      4.166700e-02\n",
            "25%      1.000000e+00\n",
            "50%      2.000000e+00\n",
            "75%      4.000000e+00\n",
            "max      2.472000e+03\n",
            "Name: total_quantity, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# --- INVESTIGANDO O CONJUNTO DE VALIDA√á√ÉO (y_val) ---\n",
        "\n",
        "print(\"Investigando o conjunto de valida√ß√£o (y_val) para entender o WMAPE...\")\n",
        "print(f\"N√∫mero total de linhas no y_val: {len(y_val):,}\")\n",
        "\n",
        "# Contar quantas vendas s√£o zero no conjunto de valida√ß√£o\n",
        "num_vendas_zero = (y_val == 0).sum()\n",
        "print(f\"N√∫mero de vendas zero no y_val: {num_vendas_zero:,}\")\n",
        "\n",
        "# Calcular a porcentagem de vendas zero\n",
        "porcentagem_vendas_zero = (num_vendas_zero / len(y_val)) * 100\n",
        "print(f\"Porcentagem de vendas zero no y_val: {porcentagem_vendas_zero:.2f}%\")\n",
        "\n",
        "# Calcular a soma total das vendas no y_val (o denominador do WMAPE)\n",
        "soma_total_vendas = y_val.sum()\n",
        "print(f\"Soma total das vendas no y_val (denominador do WMAPE): {soma_total_vendas:,.2f}\")\n",
        "\n",
        "# Mostrar algumas estat√≠sticas de y_val\n",
        "print(\"\\\\nEstat√≠sticas descritivas de y_val:\")\n",
        "print(y_val.describe())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
